{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5cb165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewroberts/Desktop/git-repos/bip-surrogates-paper/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from jax import config\n",
    "config.update('jax_enable_x64', True)\n",
    "\n",
    "from flax import nnx\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gpjax import Dataset\n",
    "from gpjax.gps import Prior as GPPrior\n",
    "from gpjax.kernels.approximations import RFF\n",
    "from gpjax.kernels import RBF\n",
    "from gpjax.parameters import transform\n",
    "\n",
    "from uncprop.utils.gpjax_models import construct_gp, train_gp_hyperpars\n",
    "from uncprop.core.surrogate import GPJaxSurrogate\n",
    "from uncprop.utils.gpjax_multioutput import (\n",
    "    BatchIndependentGP,\n",
    "    get_batch_gp_from_template,\n",
    "    fit_batch_independent_gp,\n",
    "    _make_batched_loss_and_grad,\n",
    "    _get_single_output_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent functions\n",
    "f1 = lambda x: jnp.sin(x) + 0.3 * jnp.cos(10*x)\n",
    "f2 = lambda x: -0.5 * x**2\n",
    "\n",
    "# design data\n",
    "x = jnp.linspace(0, 10, 5).reshape(-1, 1)\n",
    "xgrid = jnp.linspace(0, 10, 100).reshape(-1, 1)\n",
    "\n",
    "y = jnp.hstack([f1(x), f2(x)])\n",
    "ygrid = jnp.hstack([f1(xgrid), f2(xgrid)])\n",
    "\n",
    "design = Dataset(x, y)\n",
    "testdata = Dataset(xgrid, ygrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a24e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax\n",
    "import gpjax as gpx\n",
    "from gpjax.parameters import DEFAULT_BIJECTION\n",
    "\n",
    "opt = optax.adam(1e-1)\n",
    "objective = lambda p, d: -gpx.objectives.conjugate_mll(p, d)\n",
    "\n",
    "def gp_factory(dataset):\n",
    "    return construct_gp(dataset, set_bounds=False)[0]\n",
    "\n",
    "batchgp = get_batch_gp_from_template(gp_factory, design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da50e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline for testing: computing loss/gradient one at a time (not vectorized)\n",
    "\n",
    "def _print_tree_vals(param):\n",
    "    l = param.prior.kernel.lengthscale.get_value()\n",
    "    v = param.prior.kernel.variance.get_value()\n",
    "    sd = param.likelihood.obs_stddev.get_value()\n",
    "    m = param.prior.mean_function.constant.get_value()\n",
    "\n",
    "    print(l, v, sd, m)\n",
    "\n",
    "\n",
    "def single_losses_grads(i):\n",
    "    D = _get_single_output_dataset(design, i)\n",
    "    g, p, s = nnx.split(batchgp.posterior_list[i], gpx.parameters.Parameter, ...)\n",
    "    phi = transform(p, DEFAULT_BIJECTION, inverse=True)\n",
    "\n",
    "    def l(phi):\n",
    "        params = transform(phi, DEFAULT_BIJECTION)\n",
    "        model = nnx.merge(g, params, s)\n",
    "        return objective(model, D)\n",
    "\n",
    "    loss = l(phi)\n",
    "    gradient = jax.grad(l)(phi)\n",
    "\n",
    "    print(f'loss: {loss}')\n",
    "    print('gradient:')\n",
    "    _print_tree_vals(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6221f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized computations\n",
    "\n",
    "loss_and_grad_vect = _make_batched_loss_and_grad(batchgp, objective, DEFAULT_BIJECTION, design)\n",
    "def vectorized_losses_grads():\n",
    "    phi = transform(batchgp.params, DEFAULT_BIJECTION, inverse=True)\n",
    "    loss, gradient = loss_and_grad_vect(phi)\n",
    "\n",
    "    print(f'loss: {loss}')\n",
    "    print('gradient:')\n",
    "    _print_tree_vals(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b0bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GP 1:')\n",
    "single_losses_grads(0)\n",
    "\n",
    "print('\\nGP 2:')\n",
    "single_losses_grads(1)\n",
    "\n",
    "print('\\nVectorized:')\n",
    "vectorized_losses_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f352e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = transform(batchgp.params, DEFAULT_BIJECTION, inverse=True)\n",
    "print(f'Starting loss: {loss_and_grad_vect(phi)[0]}')\n",
    "\n",
    "new_batchgp, history = fit_batch_independent_gp(\n",
    "    batch_gp=batchgp,\n",
    "    objective=objective,\n",
    "    optim=opt,\n",
    "    num_iters=1000\n",
    ")\n",
    "\n",
    "phi_final = transform(new_batchgp.params, DEFAULT_BIJECTION, inverse=True)\n",
    "print(f'Final loss: {loss_and_grad_vect(phi_final)[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721701cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew = jnp.array([3, 5, 6, 8]).reshape(-1, 1)\n",
    "gp = new_batchgp.batch_posterior\n",
    "ker = gp.prior.kernel\n",
    "meanf = gp.prior.mean_function\n",
    "\n",
    "surrogate = GPJaxSurrogate(gp=new_batchgp.batch_posterior,\n",
    "                           design=design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94603e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gps(design, testdata, gp: GPJaxSurrogate, pred=None):\n",
    "    fig, axs = plt.subplots(1, gp.output_dim)\n",
    "    if gp.output_dim > 1:\n",
    "        axs = axs.ravel()\n",
    "    else:\n",
    "        axs = [axs]\n",
    "\n",
    "    xgrid = testdata.X.ravel()\n",
    "    if pred is None:\n",
    "        pred = gp(testdata.X)\n",
    "    \n",
    "    for i, ax in enumerate(axs):\n",
    "        m = jnp.atleast_2d(pred.mean)[i]\n",
    "        sd = jnp.atleast_2d(pred.stdev)[i]\n",
    "\n",
    "        ax.fill_between(xgrid, m-2*sd, m+2*sd, alpha=0.4, color='lightblue')\n",
    "        ax.plot(xgrid, testdata.y[:,i], color='black', label='true')    \n",
    "        ax.plot(xgrid, m, color='blue', label='mean')\n",
    "        ax.plot(design.X.ravel(), design.y[:,i], 'ro')\n",
    "        ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01578c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gps(design, testdata, surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d79578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single output case still works as expected\n",
    "idx = 0\n",
    "design_single = _get_single_output_dataset(design, idx)\n",
    "testdata_single = _get_single_output_dataset(testdata, idx)\n",
    "\n",
    "single_gp, bijection = construct_gp(design_single, set_bounds=False)\n",
    "single_gp, _ = train_gp_hyperpars(single_gp, bijection, design_single)\n",
    "single_surr = GPJaxSurrogate(single_gp, design_single)\n",
    "\n",
    "fig, ax = plot_gps(design_single, testdata_single, single_surr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9909ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditioning methods currently only work for single-output\n",
    "xnew = jnp.array([[6.0]])\n",
    "ynew = f1(xnew)\n",
    "newdata = Dataset(xnew, ynew)\n",
    "conditional_pred = single_surr.condition_then_predict(testdata_single.X, given=(xnew, ynew))\n",
    "\n",
    "plot_gps(design_single + newdata, testdata_single, single_surr, pred=conditional_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6de09",
   "metadata": {},
   "source": [
    "### Validating batch vs single output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f99c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch_gp(surrogate, batchgp, train_data, test_inputs):\n",
    "    test_batch_gp_hyperpars(surrogate, batchgp)\n",
    "    test_batch_gp_meanf(surrogate, batchgp, test_inputs)\n",
    "    test_batch_gp_gram(surrogate, batchgp, test_inputs)\n",
    "    test_batch_gp_cross_cov(surrogate, batchgp, test_inputs)\n",
    "    # test_batch_gp_pred(surrogate, batchgp, train_data, test_inputs)\n",
    "\n",
    "def test_batch_gp_hyperpars(surrogate, batchgp):\n",
    "    posts = batchgp.posterior_list\n",
    "\n",
    "    # hyperparameters\n",
    "    l_surr = surrogate.gp.prior.kernel.lengthscale.get_value()\n",
    "    l_posts = jnp.array([post.prior.kernel.lengthscale.get_value() for post in posts])\n",
    "\n",
    "    v_surr = surrogate.gp.prior.kernel.variance\n",
    "    v_posts = jnp.array([post.prior.kernel.variance.get_value() for post in posts])\n",
    "\n",
    "    obs_sd_surr = surrogate.gp.likelihood.obs_stddev.get_value()\n",
    "    obs_sd_posts = jnp.array([post.likelihood.obs_stddev.get_value() for post in posts])\n",
    "\n",
    "    m_surr = surrogate.gp.prior.mean_function.constant.get_value()\n",
    "    m_posts = jnp.array([post.prior.mean_function.constant.get_value() for post in posts])\n",
    "\n",
    "    print('lengthscales equal:', jnp.array_equal(l_surr, l_posts))\n",
    "    print('variances equal:', jnp.array_equal(v_surr, v_posts))\n",
    "    print('obs stdevs equal:', jnp.array_equal(obs_sd_surr, obs_sd_posts))\n",
    "    print('obs stdevs equal:', jnp.array_equal(m_surr, m_posts))\n",
    "\n",
    "\n",
    "def test_batch_gp_meanf(surrogate, batchgp, test_inputs):\n",
    "    post_list = batchgp.posterior_list\n",
    "    mean_surr = surrogate.gp.prior.mean_function(test_inputs)\n",
    "    mean_posts = jnp.hstack([post.prior.mean_function(test_inputs) for post in post_list])\n",
    "    print(f'prior means equal: {jnp.array_equal(mean_surr, mean_posts)}')\n",
    "\n",
    "def test_batch_gp_gram(surrogate, batchgp, test_inputs):\n",
    "    post_list = batchgp.posterior_list\n",
    "    gram_surr = surrogate.prior_gram(test_inputs)\n",
    "    gram_posts = jnp.stack([post.prior.kernel.gram(test_inputs).to_dense() for post in post_list])\n",
    "    print(f'prior grams equal: {jnp.array_equal(gram_surr, gram_posts)}')\n",
    "\n",
    "def test_batch_gp_cross_cov(surrogate, batchgp, test_inputs):\n",
    "    post_list = batchgp.posterior_list\n",
    "    cross_surr = surrogate.prior_cross_covariance(test_inputs, test_inputs)\n",
    "    cross_posts = jnp.stack([post.prior.kernel.cross_covariance(test_inputs, test_inputs) for post in post_list])\n",
    "    print(f'prior cross covs equal: {jnp.array_equal(cross_surr, cross_posts)}')\n",
    "\n",
    "def test_batch_gp_pred(surrogate, batchgp, train_data, test_inputs):\n",
    "    post_list = batchgp.posterior_list\n",
    "    pred_surr = surrogate(test_inputs)\n",
    "    surr_mean = pred_surr.mean\n",
    "    surr_var = pred_surr.variance\n",
    "\n",
    "    for i in range(batchgp.dim_out):\n",
    "        pred_post_latent = post_list[i](test_inputs, train_data)\n",
    "        pred_post = post_list[i].likelihood(pred_post_latent)\n",
    "\n",
    "        print(f'output {i+1} predictions:')\n",
    "        print(f'\\tpred means equal: {jnp.array_equal(surr_mean[i], pred_post.mean)}')\n",
    "        print(f'\\tpred variances equal: {jnp.array_equal(surr_var[i], pred_post.variance)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and train \n",
    "batchgp = get_batch_gp_from_template(gp_factory, design)\n",
    "\n",
    "batchgp, history = fit_batch_independent_gp(\n",
    "    batch_gp=batchgp,\n",
    "    objective=objective,\n",
    "    optim=opt,\n",
    "    num_iters=1000\n",
    ")\n",
    "surrogate = GPJaxSurrogate(gp=batchgp.batch_posterior,\n",
    "                           design=design)\n",
    "\n",
    " # run tests\n",
    "test_batch_gp(surrogate, batchgp, surrogate.design, testdata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "\n",
    "single_design = Dataset(surrogate.design.X, surrogate.design.y[:,[idx]])\n",
    "pred = surrogate(testdata.X)\n",
    "pred_baseline_latent = batchgp.posterior_list[idx](testdata.X, single_design)\n",
    "pred_baseline = batchgp.posterior_list[idx].likelihood(pred_baseline_latent)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs = axs.ravel()\n",
    "ax = axs[0]\n",
    "ax.scatter(pred_baseline.mean, pred.mean[idx])\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ymin, ymax = ax.get_ylim()\n",
    "grid = jnp.linspace(xmin, xmax, 100)\n",
    "ax.plot(grid, grid, color='gray', linewidth=1, linestyle='--', label='y = x')\n",
    "ax.set_title('mean')\n",
    "\n",
    "ax = axs[1]\n",
    "ax.scatter(pred_baseline.variance, pred.variance[idx])\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ymin, ymax = ax.get_ylim()\n",
    "grid = jnp.linspace(xmin, xmax, 100)\n",
    "ax.plot(grid, grid, color='gray', linewidth=1, linestyle='--', label='y = x')\n",
    "ax.set_title('variance')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = testdata.X[:2]\n",
    "\n",
    "idx = 1\n",
    "gram_surr = surrogate.prior_gram(U)\n",
    "gram2 = surrogate.gp.prior.kernel.gram(U).to_dense()\n",
    "gram_baseline = batchgp.posterior_list[idx].prior.kernel.gram(U).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b254a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gram_surr[idx]) # equal\n",
    "print(gram2[..., idx]) # equal\n",
    "print(gram_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = batchgp.posterior_list[0].prior.mean_function(U)\n",
    "b = batchgp.posterior_list[1].prior.mean_function(U)\n",
    "\n",
    "jnp.hstack([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab7d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __call__(self, x: Float[Array, \" D\"], y: Float[Array, \" D\"]) -> ScalarFloat:\n",
    "    x = self.slice_input(x) / self.lengthscale.value \n",
    "    y = self.slice_input(y) / self.lengthscale.value\n",
    "    K = self.variance.value * jnp.exp(-0.5 * squared_distance(x, y))\n",
    "    return K.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = U[0]\n",
    "v = U[1]\n",
    "\n",
    "kernel = surrogate.gp.prior.kernel\n",
    "\n",
    "kernel(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchgp.posterior_list[1].prior.kernel(u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7a908",
   "metadata": {},
   "source": [
    "# NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "648385ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpjax.kernels.stationary import RBF\n",
    "\n",
    "from uncprop.utils.gpjax_multioutput import (\n",
    "    BatchDenseKernelComputation,\n",
    "    BatchedStationaryKernel,\n",
    "    BatchedRBF,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_case_one(key):\n",
    "    d, q = 1, 3\n",
    "    x = jnp.array([1, 2, 3])\n",
    "    y = jnp.array([4, 5])\n",
    "    z = jnp.array(6)\n",
    "\n",
    "    lengthscales = jnp.array([1, 2, 3])[:, None]\n",
    "    variances = jnp.array([1, 2, 3])\n",
    "\n",
    "    return d, q, x, y, z, lengthscales, variances\n",
    "\n",
    "def setup_case_two(key):\n",
    "    d, q = 2, 2\n",
    "    kx, ky, kz = jr.split(key, 3)\n",
    "\n",
    "    x = jr.uniform(kx, (3, 2))\n",
    "    y = jr.uniform(ky, (2, 2))\n",
    "    z = jr.uniform(kz, (2,))\n",
    "\n",
    "    lengthscales = jnp.array([[0.5, 0.1], [0.4, 0.3]]) # (q, d)\n",
    "    variances = 1.0\n",
    "\n",
    "    return d, q, x, y, z, lengthscales, variances\n",
    "\n",
    "def kernel_list_to_batch(kers, x, y):\n",
    "    return jnp.stack([ker.cross_covariance(x, y) for ker in kers])\n",
    "\n",
    "def test_kernel(key, test_fn):\n",
    "    d, q, x, y, z, l, v = test_fn(key)\n",
    "    kernel = BatchedRBF(batch_dim=q, input_dim=d, lengthscale=l, variance=v)\n",
    "\n",
    "    x = x.reshape(-1, d)\n",
    "    y = y.reshape(-1, d)\n",
    "    z = z.reshape(-1, d)\n",
    "\n",
    "    l = kernel.lengthscale\n",
    "    v = kernel.variance\n",
    "\n",
    "    kers = [RBF(lengthscale=l[i], variance=v[i], n_dims=d) for i in range(q)]\n",
    "\n",
    "    def k0(x, y):\n",
    "        return kernel_list_to_batch(kers, x, y)\n",
    "\n",
    "    def k1(x, y):\n",
    "        return kernel.cross_covariance(x, y)\n",
    "\n",
    "    assert jnp.array_equal(k0(x, y), k1(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f47e72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test batched kernel\n",
    "d, q, x, y, z, lengthscales, variances = setup_case_one(_)\n",
    "\n",
    "kernel = BatchedRBF(batch_dim=q,\n",
    "                    input_dim=d,\n",
    "                    lengthscale=lengthscales, \n",
    "                    variance=variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7d1610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.key(325234)\n",
    "test_keys = jr.split(key, 2)\n",
    "\n",
    "test_kernel(test_keys[0], setup_case_one)\n",
    "test_kernel(test_keys[1], setup_case_two)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
