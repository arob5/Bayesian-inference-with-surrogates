\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode} % Note that this also loads algorithmicx
\usepackage{cleveref}
\usepackage{natbib}
\usepackage{bbm}
\usepackage{fancyvrb} % For writing using verbatim font inline. 
% \usepackage[demo]{graphicx}

% Figures
\usepackage{caption, subcaption} % Captions and sub-figures. 

% For tables
\usepackage{array}
\usepackage{booktabs}

% Bibliography
\bibliographystyle{plainnat}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Tables. 
\usepackage{multirow}

% Boxes
\usepackage[most]{tcolorbox}

% Local custom commands. 
\input{../shared/macros_general.tex}
\input{macros.tex}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{{./figures/}}

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{rmk}{Remark}

\newtheorem{ex}{Example}

% \newtheorem{ex}{Example}
% \crefname{ex}{example}{examples}
% \Crefname{ex}{Example}{Examples}

\newenvironment{examplebox}[1]{%
  \begin{tcolorbox}[title={#1}, colback=blue!5!white, colframe=blue!80!black]
  \begin{ex}
}{%
  \end{ex}
  \end{tcolorbox}
}

% Ensure cleverref knows how to handle citing of multiple subsubsections
\crefname{subsubsection}{Section}{Sections}
\Crefname{subsubsection}{Section}{Sections}
\crefname{ex}{Example}{Examples}
\Crefname{ex}{Example}{Examples}

% Title and author
\title{Uncertainty Propagation in Surrogate-Based Bayesian Inference}
\author{Andrew Roberts, Jonathan Huggins, Michael Dietze}

\begin{document}
\maketitle

\begin{abstract}
Standard Bayesian inference schemes are infeasible for inverse problems 
with computationally expensive forward models. A common solution is to 
replace the model with a cheaper surrogate. To avoid overconfident 
conclusions, it is essential to acknowledge the surrogate approximation by propagating 
its uncertainty. However, at present there is no standard method for uncertainty 
propagation in this context. To fill this gap, we propose a particular uncertainty-aware 
posterior approximation as the baseline, which is justified by Bayesian decision theoretic
arguments. \todo{unfinished}
\end{abstract}

\section{Introduction}
Simulation-based computer models are key tools for studying complex systems within 
the physical, biological, and engineering sciences. Such models often have 
uncertain parameters that must be estimated (i.e., calibrated) using observational data.
Quantifying the uncertainty in these estimated values is crucial for downstream 
decision making. While Bayesian methods are particularly well-suited to this task, 
standard Bayesian inference algorithms such as Markov chain Monte Carlo (MCMC) 
are hindered by the computational cost of the simulation model. A popular solution 
is to use a small set of expensive simulations to train a statistical approximation 
of the simulator. This emulator (i.e., surrogate) is then used as a drop-in replacement 
for the true computer model, enabling the application of algorithms like MCMC. 
This modular surrogate-based Bayesian workflow has seen widespread use across
a variety of applications \citep{FerEmulation,FadikarAgentBased,idealizedGCM,
trainDynamics,FATES_CES,CLMBayesianCalibration}.

Despite significant advances in surrogate modeling, fitting a 
highly accurate emulator under a limited computational budget remains a challenging task,
invariably implying the presence of errors in the surrogate-based posterior approximation.
Ignoring these errors can lead to overconfident results 
with miscalibrated uncertainties \citep{BilionisBayesSurrogates,BurknerSurrogate}.
It is thus crucial to acknowledge and propagate this additional source of uncertainty in 
surrogate-based Bayesian workflows. 
Probabilistic surrogates such as Gaussian processes (GPs; \citet{gpML,gramacy2020surrogates}) 
and probabilistic neural networks \citep{deepEnsembles,BayesOptNN} provide a notion of 
predictive uncertainty that be can utilized to this end.

While in principle surrogate and calibration parameters can be learned 
jointly (e.g., \citet{KOH}), in practice it is more common to conduct inference 
for these quantities in two distinct stages \citep{modularization,PlummerCut}.
Such decoupling has several practical benefits, but leaves open the 
question as to the ``correct'' approach for propagating surrogate uncertainty 
within the posterior approximation in the second stage.
A variety of uncertainty-aware posterior 
approximations have been proposed, but little guidance exists on choosing a particular 
method \citep{reviewPaper,BilionisBayesSurrogates,StuartTeck1,VehtariParallelGP,
BurknerSurrogate,BurknerTwoStep,FerEmulation}. Moreover, previous studies have 
explicitly cited computational challenges as a key factor in determining their 
approach \citep{VehtariParallelGP,StuartTeck2}. In this paper, we start by setting 
aside the computational considerations in order to identify a theoretically-justified 
baseline posterior approximation. While in general computation for this distribution 
is difficult, one can consider (1) exactly targeting a non-optimal distribution using standard
inference methods, or (2) approximately targeting the optimal baseline using
approximate inference methods.
We show that existing uncertainty propagation schemes can be viewed as 
implementations of the former approach. We then adopt the latter perspective,
introducing a new approximate MCMC algorithm that is shown to outperform 
competing approaches.
 
\subsection{Contributions}
\todo[inline]{update this section; maybe remove bullets to save space}
\begin{itemize}
\item We adopt a Bayesian decision theoretic viewpoint to formalize the question of 
choosing the correct uncertainty propagation method. We show that, with respect 
to common loss functions, the Bayes' estimator is given by a mixture distribution 
termed the \textit{expected posterior (EP)}.
\item We analyze an existing alternative, the \textit{expected unnormalized posterior (EUP)},
as an approximation to the EP. We clarify when this approximation is reasonable and 
when it can deviate significantly from the EP baseline.
\item We provide additional insights tailored to two popular modeling setups: 
(i.) emulating the log-likelihood or log-posterior with a GP, and (ii.) emulating an 
underlying forward model with a GP under an additive Gaussian error structure. 
We show that the EUP is generally a robust approximation to the EP in 
the latter case, but can suffer pathological behavior in the former.
\item We introduce an approximate MCMC algorithm that directly 
targets the EP, and numerically demonstrate favorable performance compared 
to the EUP approximation. In the case that the surrogate is a function of a 
GP, we highlight connections with correlated pseudo-marginal and 
preconditioned Crank-Nicholson algorithms. 
\end{itemize}

\subsection{Outline}
\Cref{sec:surrogates-intro} introduces the surrogate-based Bayesian workflow.
In \Cref{sec:EP} we derive the EP as a Bayes' estimator, and discuss connections 
with the so-called cut posterior distribution. In \Cref{sec:approximating-ep}
we analyze the EUP as an EP approximation and highlight practical 
takeaways for common applications in which GPs are used to emulate 
forward models or log-densities.
\Cref{sec:computation} presents an approximate MCMC scheme directly 
targeting the EP, and describes connections with alternative inference algorithms. 
\Cref{sec:experiments} contains numerical experiments, and 
\Cref{sec:conclusion} concludes. Proofs are given in the appendix.

% Surrogates for Bayesian Inverse Problems
\section{Surrogates for Bayesian Inference} \label{sec:surrogates-intro}
We begin by introducing the Bayesian inference setting, including the challenges
associated with Bayesian inverse problems involving expensive forward models. 
We then describe the common two-stage surrogate modeling pipeline, and highlight 
several different strategies for integrating surrogates within a Bayesian analysis.

\subsection{Bayesian Inference Setting}
We consider the general goal of estimating parameters $\Par \in \parSpace \subseteq \R^{\dimPar}$ given 
observations $\obs \in \obsSpace \subseteq \R^{\dimObs}$ within a Bayesian framework.
A Bayesian model consists of a joint probability distribution $p(\Par, \obs)$, defined by 
specifying a prior density $\priorDens(\Par)$ and likelihood function $\lik(\Par; \obs)$.
The goal is then to summarize the posterior distribution 
\begin{align}
&\postDensNorm(\Par) \Def p(\Par \given \obs) = \frac{1}{\normCst} \priorDens(\Par) \lik(\Par; \obs), 
&&\normCst = \int_{\parSpace} \priorDens(\Par) \lik(\Par; \obs) d\Par. \label{eq:post_dens_generic}
\end{align}
While closed-form characterizations are typically thwarted by the intractable normalizing constant
$\normCst$, posterior samples can be simulated using MCMC algorithms, which only require 
access to pointwise evaluations of the unnormalized density 
$\postDens(\Par) \Def \priorDens(\Par) \lik(\Par; \obs)$.
However, such methods commonly require $10^5 - 10^7$ iterations, with each iteration 
involving a query to the density $\postDens(\Par)$.
In various engineering and scientific applications, computing $\lik(\Par; \obs)$ (and thus
$\postDens(\Par)$) requires running an expensive computer simulation. 
This renders MCMC infeasible in this setting, motivating the need for inference schemes
that use only a small set of evaluations of $\postDens(\Par)$.
 
\subsection{Bayesian Inverse Problems} \label{sec:bip}
The challenge posed by computationally expensive density evaluations $\postDens(\Par)$ commonly 
arises in the Bayesian approach to inverse problems \citep{Stuart_BIP}. In this setting, 
the likelihood often takes the form $\obs = \fwd(\Par) + \noise$ for some forward model
$\fwd: \parSpace \to \obsSpace$. For a concrete example, we consider the problem of estimating the 
parameters in a system of ordinary differential equations (ODEs)
\begin{align}
\frac{d}{d\Time} \state(\Time, \Par) &= \odeRHS(\state(\Time, \Par), \Par), &&x(\timeStart) = \stateIC, \label{ode_ivp}
\end{align}
where the dynamics depend on parameters $\Par$. Each value for $\Par$ implies a different solution trajectory
$[\state(\Time, \Par)]_{\timeStart \leq \Time \leq \timeEnd}$, which we encode by the
map $\solutionOp: \Par \mapsto [\state(\Time, \Par)]_{\timeStart \leq \Time \leq \timeEnd.}$. The goal is then 
to identify the parameters that yield trajectories in agreement with observed data 
$\obs$, which is assumed to be some noise-corrupted function $\obsOp$ of the true trajectory. Thus, the 
likelihood is of the form 
\begin{align}
&\obs = \fwd(\Par) + \noise, &&\fwd \Def \obsOp \circ \solutionOp. \label{eq:additive-noise}
\end{align}
In practice, the ODE is solved numerically so $\solutionOp$ represents the map induced by a numerical 
solver. Therefore, in this setting the computational cost of computing $\postDens(\Par)$ stems from the 
dependence of the likelihood on $\fwd(\Par)$, and in particular on the solver $\solutionOp(\Par)$.

\subsection{Surrogate Targets for Bayesian Inference} \label{sec:surrogates-Bayes}
Given the cost of computing $\postDens(\Par)$, we seek to approximate
the posterior using a small set of queries to the posterior density. 
The surrogate modeling approach to this problem consists of constructing 
a regression-based approximation of the density $\postDens$. This surrogate density is typically 
induced indirectly by the approximation of some underlying quantity 
on which $\postDens(\Par)$ depends. To make this explicit, let 
$\target: \parSpace \to \targetRange$ be the underlying map targeted for emulation. 
We write $\postDens(\Par; \target)$ and $\normCst(\target)$ to indicate the dependence of the posterior 
density and normalizing constant on $\target$, and assume throughout that $\postDens(\Par; \target)$ 
is dependent on $\Par$ only through $\target(\Par)$. In the common case that the target appears 
only through the likelihood, we similarly write $\lik(\Par; \target, \obs)$.
Two common classes of target maps are detailed in \Cref{ex:fwd-em, ex:ldens-em}.

In many applications, computational constraints impose a budget of 
$\Ndesign$ evaluations of $\target$, where 
$\Ndesign$ is typically much smaller than that required by standard posterior
inference algorithms. The surrogate approach uses the limited set of queries
$\{(\Par_n, \target(\Par_n))\}_{n=1}^{\Ndesign}$
to fit a regression model $\targetEm$ such that 
$\targetEm(\Par)$ provides a prediction of $\target(\Par)$ at new inputs $\Par$.
In order to quantify the uncertainty introduced via this approximation, we consider 
emulators that provide predictions in the form of a probability distribution; 
i.e., $\targetEm(\Par)$ is random and thus $\targetEm$ is a random function. 
The randomness in $\targetEm$ may be derived from any probabilistic
model (e.g., Gaussian processes, BART, Bayesian neural networks, deep ensembles).
Let $\emDist(\cdot \given \Par)$ and $\emDist$ denote the distributions of 
$\targetEm(\Par)$ and $\targetEm$, respectively, 
and $\emE$ the expectation with respect to $\emDist$.
Using $\targetEm$ as a drop-in replacement for 
$\target$ implies that $\postDens(\Par; \targetEm)$ and $\normCst(\targetEm)$
are univariate random variables, while $\postDens(\cdot; \targetEm)$
is a random function.

The manner in which the uncertainty in $\targetEm$ propagates to 
$\postDens(\cdot; \targetEm)$ depends on the target $\target$,
the predictive distribution $\emDist$, and the particular form of the 
density $\postDens$. Below, we highlight two general choices 
of $\target$ common in the literature. This categorization has also 
been explored in \citet{StuartTeck1,StuartTeck2,GP_PDE_priors}. 

% TODO: add this back in when review paper is ready
% See
% \citet{reviewPaper} for a discussion of practical considerations in choosing 
% the emulator target. 

\begin{examplebox}{Forward Model GP Surrogate}
\label{ex:fwd-em}
In the Bayesian inverse problem setting from \Cref{sec:bip},
a natural approach is to target the underlying forward model 
$\Par \mapsto \fwd(\Par)$ (i.e., choose $\target \Def \fwd$), a strategy 
we refer to as \textbf{forward model emulation}.
This method consists of fitting a surrogate $\targetEm$ to the design 
$\{(\Par_n, \fwd(\Par_n))\}_{n=1}^{\Ndesign}$ and then using $\targetEm$
in place of $\fwd$. Much previous work has considered this strategy 
in the context of the additive noise model in \Cref{eq:additive-noise},
under the Gaussian noise assumption $\noise \sim \Gaussian(0, \likPar)$
\citep{StuartTeck1,GP_PDE_priors,hydrologicalModel,hydrologicalModel2,
Surer2023sequential,VillaniAdaptiveGP,weightedIVAR,idealizedGCM,CES}.
In this special case, the induced (unnormalized) posterior density surrogate takes the form
\begin{align}
\postDens(\Par; \targetEm) &= \priorDens(\Par) \Gaussian(\obs \given \targetEm(\Par), \likPar). \label{eq:post-em-fwd-Gaussian}
\end{align}
\end{examplebox}

\begin{examplebox}{Log-Density GP Surrogate}
\label{ex:ldens-em}
Another popular strategy is to choose $\target$ as the map induced by the log-likelihood
$\Par \mapsto \log \lik(\Par; \obs)$
\citep{VehtariParallelGP,FATES_CES,trainDynamics,quantileApprox,
ActiveLearningMCMC,FerEmulation,StuartTeck1,random_fwd_models,
GP_PDE_priors,OakleyllikEm,JosephMinEnergy,AlawiehIterativeGP,gpEmMCMC}
or (unnormalized) log-posterior
$\Par \mapsto \log \left\{\priorDens(\Par)\lik(\Par; \obs)\right\}$
\citep{emPostDens,Kandasamy_2017,llikRBF,gp_surrogates_random_exploration,
landslideCalibration}.

We collectively refer to these strategies as \textbf{log-density emulation}. In the 
log-likelihood case, an emulator $\targetEm$ is fit to a design 
$\{(\Par_n, \log \lik(\Par_n; \obs)\}_{n=1}^{\Ndesign}$
and induces a posterior density surrogate 
\begin{align}
\postDens(\Par; \targetEm) &= \priorDens(\Par) \Exp{\targetEm(\Par)}. \label{eq:post-em-llik}
\end{align}
The log-posterior case is similar, except that the effect of the prior is also 
approximated by the emulator, so the induced posterior surrogate takes 
the form $\postEm(\Par) = \Exp{\targetEm(\Par)}$.
\end{examplebox}

% The Expected Posterior
\section{The Expected Posterior} \label{sec:EP}
The second stage in the modular surrogate workflow consists of using the 
trained emulator $\targetEm$ to approximate the posterior $\postDensNorm$.
A simple approximation may be constructed by plugging in the surrogate mean
\begin{equation}
\postApproxNormMean(\Par) \Def \postDens(\Par; \emE[\targetEm]) / \normCst(\emE[\targetEm]),
\label{eq:mean-approx}
\end{equation}
but this ignores the emulator uncertainty, resulting in overconfident 
posterior inference. This poses the question of defining a posterior approximation 
that correctly propagates the uncertainty in $\targetEm$.
Given the lack of a unifying probabilistic model across the two inference stages, 
proper uncertainty quantification is not automatically given by standard Bayesian 
conditioning. Consequently, various uncertainty propagation methods have been 
proposed, each resulting in different posterior inferences 
\citep{BilionisBayesSurrogates,StuartTeck1,VehtariParallelGP,BurknerSurrogate,
FerEmulation}.
We identify and justify a mixture distribution termed the 
\textit{expected posterior (EP)} as the correct distribution to target in 
modular surrogate-based inference. 

\subsection{Decision Theoretic Derivation} \label{sec:decision-theoretic}
Irrespective of the underlying target $\target$, the probabilistic emulator $\targetEm$ 
induces a random approximation of the posterior defined by plugging $\targetEm$
in place of $\target$; this yields
\begin{align}
\postDensNorm(\Par; \targetEm) 
&= \frac{\postDens(\Par; \targetEm)}{\normCst(\targetEm)},
&&\normCst(\targetEm) \Def \int_{\parSpace} \postDens(\Par; \targetEm) \d\Par, \label{eq:random-post}
\end{align}
which is referred to as the ``sample approximation'' in \citet{StuartTeck1}. For brevity, we write
 $\postEm(\cdot) \Def \postDens(\cdot; \targetEm)$, 
$\postNormEm(\cdot) \Def \postDensNorm(\cdot; \targetEm)$, and 
$\normCstEm \Def \normCst(\targetEm)$ when explicit reference to the underlying 
emulator is not necessary.

We view the challenge of uncertainty propagation as that of constructing a deterministic 
probability distribution that summarizes the uncertainty encoded in $\postNormEm$.
To identify such a distribution, we adopt a Bayesian decision theoretic viewpoint and consider
the Bayes' estimator
\begin{equation}
\qDensOpt \in \argmin_{\qDens \in \qSpace} \emE[\loss(\postNormEm, q)],
\label{eq:variational-opt}
\end{equation}
for a loss function $\loss$ and space of densities $\qSpace$ over $\parSpace$. The following 
result provides the unique minimizer $\qDensOpt$ with respect to two common losses.

\begin{prop} \label{prop:EP-variational}
If the loss $\loss(\postNormEm, q)$ is chosen as the forward Kullback-Leibler (KL) divergence 
$\KL{\postNormEm}{q}$ or squared $L_2$ error $\norm{\postNormEm - q}_{L_2(\parSpace)}^2$
then the optimization problem in \Cref{eq:variational-opt} is solved uniquely by 
\begin{equation}
\qDensOpt(\Par) = 
\emE \left[\postNormEm(\Par) \right]
= \int \postDensNorm(\Par; \targetTraj) \emDist(d\targetTraj).
\label{eq:ep-approx}
\end{equation}
\end{prop}

We thus take $\qDensOpt$ as the baseline for surrogate-based uncertainty propagation. 
This distribution has been considered previously in various 
contexts, but is not widely used in the surrogate modeling literature
\citep{trainDynamics,BurknerSurrogate,garegnani2021NoisyMCMC}.
This is likely due in part to computational difficulties, which we address in \Cref{sec:computation}.
Following \citet{BurknerSurrogate}, we refer to $\qDensOpt$ as the \textit{expected posterior (EP)},
denoted by $\postApproxEP \Def \qDensOpt$.

\subsection{Hierarchical Formulation}
The EP arises as the marginal of the 
joint distribution $\emDist(d\targetTraj) \postDensNorm(\Par; \targetTraj) d\Par$, which 
can be understood via the hierarchical model 
\begin{align}
&\targetTraj  \sim \emDist, 
&&\Par \given \targetTraj \sim \postDensNorm(\d\Par; \targetTraj).
\label{eq:ep-prob-model}
\end{align}
This perspective highlights the interpretation of the EP as a $\emDist$-weighted mixture of posteriors 
$\postDensNorm(\Par; \targetTraj)$, each induced by a particular emulator realization $\targetTraj$.
We assume throughout that $\targetEm$ is constructed such that 
trajectories of $\postNormEm$ are almost surely integrable, implying the sampling procedure
in \Cref{eq:ep-prob-model} is well-defined. See 
\citet{StuartTeck1,StuartTeck2,random_fwd_models,garegnani2021NoisyMCMC} for additional
technical conditions ensuring existence.

The EP also admits a marginal likelihood interpretation under the hierarchical model
\begin{equation}
 \targetTraj  \sim \emDist, \qquad \Par \sim \priorDens, \qquad 
\obs \given \targetTraj, \Par \sim \lik(\Par; \targetTraj, \d\obs)/\normCst(\targetTraj),
\end{equation}
yielding the equivalent characterization
\footnote{For clarity of exposition, we assume here that the prior $\priorDens$ is not part of the surrogate model.
A slight modification generalizes this expression to the general case, which encompasses log-posterior emulators.}
\begin{align}
&\postApproxEP(\Par) \propto \priorDens(\Par) \likApproxEP(\Par; \obs),
&&\likApproxEP(\Par; \obs) \Def \int \frac{\lik(\Par; \targetTraj, \obs)}{\normCst(\targetTraj)} \emDist(\d\targetTraj). 
\label{eq:lik-approx-EP}
\end{align}
Observe that the exact likelihood is replaced with an approximation averaged over $\targetTraj$ and 
weighted both by the surrogate predictive distribution and the marginal likelihood $\normCst(\targetTraj)$.

\subsection{Cut Posterior} \label{sec:cut}
In this section, we consider the case where the two-stage surrogate workflow 
arises as an approximation to a coherent joint Bayesian model, in which case
 the EP can be viewed as a so-called cut posterior distribution
\citep{PlummerCut,cutInference,moduleModels,cutVar,cutVar2}.
In particular, suppose that the surrogate model is defined by specifying 
a prior $\targetTraj \sim \emDistPrior$ and likelihood $\emLik(\targetTraj; \emObs)$,
where $\emObs \Def \{(\Par_n, \target(\Par_n))\}_{n=1}^{\Ndesign}$ denotes
the emulator training data. The common example of a conjugate GP model 
corresponds to $\emDistPrior = \GP(\gpMean[0], \gpKer[0])$ and 
$\emLik(\targetTraj; \emObs) = \Gaussian(\target(\Par_{1:\Ndesign}) \given \targetTraj(\Par_{1:\Ndesign}), \tau^2 I)$.
This setup encompasses standard parametric Bayesian models as well.
We can thus consider the joint Bayesian model 
\begin{equation}
\jointKOH(\d\Par, \d\targetTraj, \d\obs, \d\emObs) \Def
\priorDens(\Par) \lik(\Par; \targetTraj, \obs) \emLik(\targetTraj; \emObs) 
\emDistPrior(\d\targetTraj) \, \d\Par \, \d\obs \, \d\emObs
\label{eq:koh-joint}
\end{equation}
over all unknowns $(\targetTraj, \Par)$. This fully Bayesian (non-modular) model 
is akin to the framework proposed in the seminal work of \citet{KOH}. Unfortunately, the joint model 
can produce counterintuitive results when $\lik(\Par; \target, \obs)$ is misspecified, stemming from 
the fact that both the simulated $\emObs$ and observational data $\obs$ inform inference
for the emulator \citep{modularization}. The following result shows that 
the EP can be viewed as an optimal approximation to the fully Bayesian model, 
subject to the constraint that $\obs$ is not allowed to inform $\targetTraj$.

\begin{prop} \label{prop:kl-cut-op}
Let $\postKOH$ denote the distribution of $(\Par, \targetTraj)$
given $(\obs, \emObs)$ under the joint $\jointKOH$. Also, let $\emDist$ denote 
the distribution of $\targetTraj$ given $\emObs$ under the joint 
$\emDistPrior(\d\targetTraj) \emLik(\targetTraj; \emObs) \d\emObs$. Then, 
\begin{equation}
\emDist(\d\targetTraj) \postDensNorm(\Par; \targetTraj)\d\Par
= \argmin_{\qMeas \in \qSpaceCut}} \KL{\qMeas}{\postKOH},
\label{eq:kl-cut-opt}
\end{equation}
where 
\begin{equation}
\qSpaceCut \Def 
\left\{\qMeas(\d\Par, \d\targetTraj) : \int \qMeas(\d\Par, \cdot) = \emDist(\cdot) \right\}.
\label{eq:cut-dists}
\end{equation}
\end{prop} 
The optimum in \Cref{eq:kl-cut-opt} is precisely the joint distribution noted in the previous 
section, and also corresponds to the cut posterior with respect to the fully Bayesian model.
This gives a second variational justification for the EP, complementing the result in 
\Cref{prop:EP-variational}.

\paragraph{Related work.} In the surrogate modeling literature the EP has been considered 
in \citet{trainDynamics,BurknerSurrogate,garegnani2021NoisyMCMC}. In 
\citet{StuartTeck2,VehtariParallelGP}, the EP is briefly noted but deemed computationally impractical. 
This difference of opinion can be explained by the fact that these latter two papers are focused 
on GP surrogates, which present additional challenges stemming from the inability to exactly 
sample surrogate trajectories $\targetTraj \sim \emDist$. On the other hand, 
\citet{BurknerSurrogate,garegnani2021NoisyMCMC} appear to implicitly assume the use of 
finite-dimensional surrogate models for which sampling trajectories is straightforward.
See \Cref{sec:computation} for additional computational details.

In the modular Bayes literature, there is a wide body of work 
on the cut posterior, which is equivalent to the EP 
when a fully Bayesian reference model is considered (\Cref{sec:cut})
\citep{PlummerCut,cutInference,moduleModels}.
Various papers have justified the cut posterior as a reverse KL divergence minimizer, 
akin to \Cref{prop:kl-cut-op} \citep{cutVar,cutVar2,moduleModels}. 

The hierarchical sampling view of the EP in \Cref{eq:ep-prob-model} also 
corresponds to a Bayesian multiple imputation algorithm, typically applied
in missing data problems \citep{multipleImputationMedical,missingData}.
The notion of aggregating multiple posterior distributions is also used in 
contexts other than modular inference, including for robustness to model 
misspecification \citep{BayesBag,BayesBag2}.

\section{Approximating the Expected Posterior} \label{sec:approximating-ep}
Having justified the EP as the baseline target distribution for modular uncertainty 
propagation, we now turn to the practical question of conducting EP-based
inference. While exact inference is typically infeasible, two 
natural strategies are to
(1) target an alternative distribution that approximates the EP but is more amenable
to standard inference algorithms, and (2) employ an approximate 
inference algorithm directly targeting the EP (see \Cref{sec:computation} for the latter). 
Previous studies have adopted the former approach, eschewing the EP in favor 
of approximations of the \textit{unnormalized} density surrogate $\postEm$
\citep{StuartTeck1,StuartTeck2,VehtariParallelGP}.
However, these works stop short of studying how this approximation
relates to the EP. In this section we build an understanding of this approximation,
termed the \textit{expected unnormalized posterior (EUP)}, and provide analytical results 
illustrating how the EP and EUP can differ.

\subsection{The Expected Unnormalized Posterior} \label{sec:eup}
Notice that, unlike $\postNormEm(\Par)$, the unnormalized density surrogate
$\postEm(\Par)$ depends only on the single-point prediction $\targetEm(\Par)$
rather than the full emulator $\targetEm$. The EUP is defined by computing
a pointwise expectation of $\postEm(\Par)$ and then normalizing post-hoc:
\begin{equation}
\postApproxEUPNorm(\Par) \Def 
\frac{\emE \left[\postEm(\Par) \right]}{\int_{\parSpace} \emE\left[\postEm(\Par) \right] d\Par}
= \frac{\emE\left[\postEm(\Par) \right]}{\emE[\normCstEm]}. \label{eq:post-approx-EUP} 
\end{equation}
The equality in \Cref{eq:post-approx-EUP} follows from
changing the order of integration, courtesy of Tonelli's theorem \citep{StuartTeck1}. The EUP
is a marginal of the joint distribution 
$\emDist(d\targetTraj) \postDens(\Par; \targetTraj) / \emE[\normCst(\targetEm)] d\Par$. 
As compared to the analogous EP joint
$\emDist(d\targetTraj) \postDens(\Par; \targetTraj) / \normCst(\targetTraj) d\Par$,
we see that the EUP replaces the normalizing function $\normCst(\targetTraj)$ with
the global point estimate $\emE[\normCst(\targetEm)]$. The $\targetTraj$-marginal of
this joint is proportional to $\emDist(\d\targetTraj) \normCst(\targetTraj)$, implying the
joint is not an element of $\qSpaceCut$, the space of cut distributions defined in \Cref{eq:cut-dists}.
In other words, the EUP allows the observational data $\obs$ to inform the manner in which 
the surrogate uncertainty is propagated.

Like the EP, the EUP admits
both posterior mixture and marginal likelihood interpretations. Starting with the latter, 
the EUP arises as the marginal posterior $p(\Par \given \obs)$ under the hierarchical model
\begin{equation}
\targetTraj  \sim \emDist, \qquad 
\Par \sim \priorDens, \qquad
\obs \given \targetTraj, \Par \sim \lik(\Par; \targetTraj, \d\obs).
\label{eq:eup-prob-model}
\end{equation}
This yields 
\begin{align*}
&\postApproxEUPNorm(\Par) \propto \priorDens(\Par) \likApproxEUP(\Par; \obs),
&&\likApproxEUP(\Par; \obs) \Def \int \lik(\Par; \targetTraj, \obs) \emDist(\d\targetTraj), 
\end{align*}
providing an analog to the EP characterization in \Cref{eq:lik-approx-EP}. In contrast
with $\likApproxEP(\Par; \obs)$, the EUP marginal likelihood does not include 
$\normCst(\targetTraj)$ in the integrand. Analogous to \Cref{eq:ep-approx}, the EUP can also be 
written as a posterior mixture
\begin{equation}
\postApproxEUPNorm(\Par) = \int \postDensNorm(\Par; \targetTraj) \emDist(d\targetTraj \given \obs),
\label{eq:eup-mixture} 
\end{equation}
where $\emDist(d\targetTraj \given \obs) \propto \normCst(\targetTraj) \emDist(d\targetTraj)$.

\subsection{Comparison of the EP and EUP}
Notice in \Cref{eq:post-approx-EUP} that the EUP is a ratio estimator, and differs from 
the EP due to the nonlinearity of the normalization operation. The EUP can thus 
be derived from the EP by invoking two approximations: 
(i.) treating $\postEm(\Par)$ and $\normCstEm^{-1}$ as independent; and 
(ii.) assuming $\emE[\normCstEm^{-1}] \approx \emE[\normCstEm]^{-1}$.
The below result quantifies the effect of these two approximations.

\begin{prop} \label{prop:ep-eup-pw-err}
The pointwise difference between the EP and EUP is given by
\begin{equation}
\postApproxEP(\Par) - \postApproxEUPNorm(\Par)
= \emE[\postEm(\Par)] \jgap + \Cov[\postEm(\Par), \normCstEm^{-1}],
\label{eq:ep-eup-pw-err}
\end{equation}
where $\jgap \Def \emE[\normCstEm^{-1}] - \emE[\normCstEm]^{-1}$
is the ``Jensen gap.''
\end{prop}

By Jensen's inequality $\jgap \geq 0$, implying that the Jensen gap represents a 
$\Par$-independent positive bias in the difference between EP and EUP, modulated by the magnitude of 
$\emE[\postEm(\Par)]$. Since both distributions integrate to one, any positive 
biases must be balanced by negative biases at other values of $\Par$.
The second term in \Cref{eq:ep-eup-pw-err} will be negative for ``influential'' $\Par$ values, 
those with larger realizations of $\postEm(\Par)$ highly correlated with larger values of 
$\normCstEm$. The influence of a parameter value will typically increase when 
$\postEm(\Par)$ is large on average, highly variable, and is positively correlated with other 
$\postEm(\Par^\prime)$. The latter property may be satisfied, for example, when using 
a GP emulator with a long lengthscale. Based on this logic, we expect the EUP to inflate 
influential regions and depress non-influential regions, relative to the EP. As we will see 
in experiments, this can manifest as the EUP being highly peaked in regions with 
significant surrogate uncertainty. The pointwise error in 
\Cref{prop:ep-eup-pw-err} can be integrated to obtain the following $L_1$ bound 
between $\postApproxEP$ and $\postApproxEUPNorm$.

\begin{prop} \label{prop:ep-eup-TV-err}
Let $\jgap$ be defined as in \Cref{prop:ep-eup-pw-err}. Then,
\begin{equation}
\norm{\postApproxEP - \postApproxEUPNorm}_{L_1(\parSpace)}
\leq \emE[\normCstEm] \jgap + \int \abs{\Cov[\postEm(\Par), \normCstEm^{-1}]} d\Par
\label{eq:ep-eup-TV-err}
\end{equation}
\end{prop}

Decreasing the variance of $\normCstEm$ will shrink both terms in 
\Cref{eq:ep-eup-TV-err}. This may occur when there is little 
uncertainty in $\targetEm$, the unnormalized posterior $\postDens(\cdot; \targetTraj)$
is insensitive to $\targetTraj$, or $\normCstEm$ is insensitive to the variability 
in $\postEm$. In the first case, note that if $\targetEm$ is heavily 
concentrated around its mean, then both the EP and EUP will closely resemble
the plug-in mean approximation in \Cref{eq:mean-approx}.
In special cases, the two terms in \Cref{eq:ep-eup-TV-err} perfectly balance so that 
the EP and EUP agree. For example, this occurs when 
$\postEm(\Par) = \omega g(\Par)$, where $\omega$ is a random constant and 
$g(\Par)$ a deterministic function. 

\subsubsection{Conceptual Considerations} \label{sec:conceptual}
It should be emphasized that the correct choice of uncertainty propagation method  
may be problem-dependent. We view the variational justification for the EP provided by
\Cref{prop:EP-variational} as a general guide, but particular conceptual considerations
may take precedence in certain situations. The EUP is a natural choice when $\targetEm$
is viewed as a latent variable that forms part of the data-generating process for the observational
data $\obs$, leading to the hierarchical model in \Cref{eq:eup-prob-model}. Our focus is 
on situations where the randomness in $\targetEm$ is primarily epistemic---in principle it could be 
reduced via further evaluations of the simulator. The EP effectively follows from the view that this 
epistemic uncertainty is external to the data-generating process. Another important consideration
is that the EP is a true cut posterior distribution, while the EUP incorporates the data $\obs$ into
the uncertainty propagation method. This is perhaps most clearly illustrated by the posterior 
mixture formulations in \Cref{eq:ep-mixture,eq:eup-mixture}, where we see that the EUP mixture 
weights depend on $\obs$.

\subsection{EUP Examples}

\begin{examplebox}{Forward Model GP Surrogate}[continued]
\label{ex:fwd-em-cont}
We return to \Cref{ex:fwd-em}, with surrogate density 
$\postEm(\Par) = \priorDens(\Par)\Gaussian(\obs \mid \targetEm(\Par), \likPar)$ 
derived from a (potentially multi-output) GP emulator $\targetEm \sim \GP(\gpMean, \gpKer)$
replacing the true forward model $\fwd$. This setup is commonly considered in the Bayesian 
inverse problem literature \citep{Surer2023sequential,weightedIVAR,StuartTeck2,GP_PDE_priors,CES,
idealizedGCM,villani2024posteriorsamplingadaptivegaussian,hydrologicalModel,hydrologicalModel2}.
Under these assumptions, the EUP assumes the form
\begin{equation}
\postApproxEUPNorm(\Par) \propto \priorDens(\Par) \Gaussian(\obs \mid \gpMean(\Par), \likPar + \gpKer(\Par)),
\label{eq:EUP-Gaussian-fwd}
\end{equation}
following from the formula for the convolution of two Gaussians \citep{StuartTeck2}.
In this context, the uncertainty propagation admits a data space interpretation, with
$\gpKer(\Par)$ inflating the observation covariance.
This does not imply that the EUP strictly induces larger posterior inflation in regions with larger uncertainty.
Since the Gaussian likelihood is bounded above,
when $\gpMean(\Par)$ and $\obs$ are close, then an increase in $\gpKer(\Par)$ may actually 
deflate the density at $\Par$. In regions where $\gpMean(\Par)$ and $\obs$ significantly differ,
then the surrogate uncertainty typically has the effect of inflating the density, relative to the 
plug-in mean approximation.
\todo[inline]{Finish this section once experiment 3 is complete}
\todo[inline]{Fix example numbering}
\end{examplebox}

\begin{examplebox}{Log-Density GP Surrogate}[continued]
\label{ex:ldens-em-cont}
We return to \Cref{ex:ldens-em} where $\postEm(\Par) = \Exp{\targetEm(\Par)}$,
and consider a GP emulator $\targetEm \sim \GP(\gpMean, \gpKer)$. 
In particular, this implies the pointwise predictions $\targetEm(\Par)$ are Gaussian, with 
$\E[\targetEm(\Par)] = \gpMean(\Par)$ and 
$\Cov[\targetEm(\Par),\targetEm(\Par^\prime)] = \gpKer(\Par, \Par^\prime)$. We use the shorthand 
$\gpKer(\Par) \Def \gpKer(\Par, \Par)$ for the predictive variance. This setup,
encompassing both the log-likelihood and log-posterior emulation settings, has been 
considered in several applications 
\citep{VehtariParallelGP,FATES_CES,trainDynamics,quantileApprox,
ActiveLearningMCMC,FerEmulation,StuartTeck1,StuartTeck2,random_fwd_models,
GP_PDE_priors,OakleyllikEm,JosephMinEnergy,AlawiehIterativeGP,gpEmMCMC}.

In this setting, $\postEm$ is a log-normal process, implying the pointwise predictive 
distributions $\postEm(\Par) \sim \LN(\gpMean(\Par), \gpKer(\Par))$, as well as
\begin{equation}
\postApproxEUPNorm(\Par) 
\propto \Exp{\gpMean(\Par) + \frac{1}{2}\gpKer(\Par)}
= \postApproxMean(\Par) \Exp{\frac{1}{2}\gpKer(\Par)}.
\label{eq:EUP-Gaussian-ldens}
\end{equation} 
\Cref{eq:EUP-Gaussian-ldens} illustrates that the EUP inflates the plug-in mean approximation 
in regions with high surrogate uncertainty. 
At two points with equal predictive mean $\gpMean$, the 
EUP always assigns higher density to the more uncertain location 
(unlike in \Cref{ex:fwd-em-cont}). Notably, the magnitude of the
uncertainty inflation scales with the exponentiated variance of the GP, potentially leading to extreme 
concentration in the most uncertain regions. For example, if $\gpKer(\Par) = 4$,
$\gpMean(\Par^\prime) = \gpMean(\Par)$, and 
$\gpKer(\Par^\prime) = 4 \gpKer(\Par)$, then 
$\{\postApproxEUPNorm(\Par^\prime)/\postApproxEUPNorm(\Par)\} / 
\{\postApproxNormMean(\Par^\prime)/\postApproxNormMean(\Par)\} \approx 400$. 
The $2\times$ difference in surrogate standard deviation translates to a $400\times$ difference in 
density approximation, relative to the plug-in mean. This undesirable behavior, also noted by 
\citet{VehtariParallelGP}, can be viewed partially as a consequence of the dominating effect
of the second term in \Cref{eq:ep-eup-pw-err} at points where the distribution of 
$\postEm(\Par)$ is heavy-tailed.
As illustrated in the experiment in \Cref{sec:vsem}, the EP tends to be more robust, though not immune, to the 
sensitivity exhibited by posterior estimates under GP log-density surrogates.
\todo[inline]{Cite \citet{StuartTeck2,GP_PDE_priors} or \citet{quantileApprox} here?}
\todo[inline]{Fix example numbering}
\end{examplebox}

\paragraph{Related work.} The EUP is proposed in the forward model emulator setting 
in \citet{BilionisBayesSurrogates}, motivated by the extended parameter space viewpoint
in \Cref{eq:eup-prob-model}. \citet{StuartTeck2,CES} also note this perspective
in the particular Gaussian setting of \Cref{eq:EUP-Gaussian-fwd}.
In \citet{SinsbeckNowak}, the EUP is justified as the distribution 
$q$ that minimizes $\emE\left[\norm{\postEm - q}_{L_2(\parSpace)}^2 \right]$.
\citet{StuartTeck1,StuartTeck2,VehtariParallelGP} also highlight this Bayesian 
decision theoretic justification. 
In contrast with the EP, the optimality is only guaranteed for the estimate of the 
\textit{unnormalized} posterior.
As shown in \Cref{prop:EP-variational}, the EP is the minimizer when the loss
is defined with respect to the normalized distributions.
The EUP is referred to as the ``marginal'' approximation in 
\citet{StuartTeck1,StuartTeck2,random_fwd_models,TeckHyperpar},
in which it is analyzed theoretically for both log-likelihood and forward 
model emulators. \citet{VehtariParallelGP} highlight pathological 
behavior of the EUP for GP log-density emulators, and recommend 
against its use in this setting. To our knowledge, \citet{BurknerSurrogate}
is the only previous work to directly compare the EP and EUP (which 
they call the ``expected likelihood''). Their comparison is limited to 
numerical results in case studies involving forward model emulators.
The closed-form EUP expressions in 
\Cref{eq:EUP-Gaussian-ldens,eq:EUP-Gaussian-fwd} have been 
noted in a variety of works 
\citep{StuartTeck1,StuartTeck2,VehtariParallelGP,weightedIVAR,
GP_PDE_priors,Surer2023sequential,Takhtaganov2018AdaptiveBayesianGP}. 
The EUP has seen 
use in various applications involving both forward model 
and log-density emulators 
\citep{weightedIVAR,GP_PDE_priors,CES,idealizedGCM,
villani2024posteriorsamplingadaptivegaussian,hydrologicalModel,hydrologicalModel2}.
 
% Approximate Computation for the EP
\section{Approximate Computation for the Expected Posterior} \label{sec:computation}
The previous section explored the EUP as an approximation to the EP, demonstrating when 
the two distributions may significantly differ. We now seek a more direct route to EP-based
inference, and introduce an approximate MCMC algorithm towards this end. 
We start by clarifying the difficulties associated with EP computation.

\subsection{Sampling Trajectories}
In light of the hierarchical model in \Cref{eq:ep-prob-model}, the following 
algorithm can in principle be applied to directly sample $\postApproxEP$.  

\begin{algorithm}[H]
    \caption{Direct sampling from $\postApproxEP$}
    \label{alg:ep}
    \begin{algorithmic}[1]
    \Function{sampleEP}{$\postNormEm, \NSample, M$}     
        \For{$\sampleIndex \gets 1, \dots, \NSample$} 
        		\State $\targetTraj^{(\sampleIndex)} \sim \emDist$ \Comment{Sample emulator trajectory}
		\State $\Par^{(\sampleIndex, 1)}, \dots, \Par^{(\sampleIndex, M)} \sim \postDensNorm(\cdot; \targetTraj^{(\sampleIndex)})$ \Comment{Sample posterior given trajectory}
	\EndFor
	\State \Return $\{\Par^{(\sampleIndex, m)}\}_{1 \leq \sampleIndex \leq \NSample, \ 1 \leq m \leq M}$
	\EndFunction
    \end{algorithmic}
\end{algorithm}
If one sample is drawn from each posterior trajectory (i.e., $M=1$) then the resulting samples are 
independent. Otherwise, \Cref{alg:ep} produces dependent samples identically distributed according to
$\postApproxEP$. In practice, directly sampling $\Par \given \targetTraj \sim \postDensNorm(\cdot; \targetTraj)$
is rarely possible, so this inner sampling step is replaced by an MCMC algorithm.
The resulting sampling scheme is sometimes called \textit{Metropolis within Monte Carlo (MwMC)} 
\citep{garegnani2021NoisyMCMC}. MwMC has the downside of requiring $\NSample \gg 1$
MCMC runs, but this may be less of an issue in modern parallel computing environments \citep{BurknerSurrogate}. 
Moreover, methods have been developed to reduce the size of $\NSample$ required to achieve a
desired level of precision \citep{BurknerTwoStep}. 

The more significant issue is the outer sampling step, which requires simulating surrogate 
trajectories $\targetEm \sim \emDist$. While not a problem for finite-dimensional 
surrogate models (e.g., linear models), this presents major challenges for surrogates 
derived from GPs. Given the popularity of GP surrogates, 
this computational bottleneck must be resolved for the EP to be broadly accessible in 
surrogate-based Bayesian workflows. Standard remedies suffer from poor scalability,
limited applicability, or bespoke numerical implementations. For example, naive 
approximations that discretize $\parSpace$ are limited to low-dimensional settings.
Finite-rank GP approximations offer an alternative, but are dependent on the 
particular form of the surrogate \citep{pathwiseConditioning}. In theory, one 
could retain an infinite-dimensional GP representation by constructing 
GP trajectories ``just-in-time'' within the MCMC algorithm; that is, iteratively
condition the GP at each value of $\Par$ visited within the MCMC run.
However, this approach is well-known to suffer from significant numerical 
instability \citep{pathwiseConditioning}. Finally, we highlight the method of 
\citet{trainDynamics}, which is to our knowledge the only existing work to 
attempt EP-based inference with a GP surrogate. 
Their method consists of approximating GP 
trajectories by sampling the surrogate at a finite grid of points, 
and then approximating the trajectory as the GP mean, conditional on the 
sampled values at these points. This approach has the downside of 
addressing the difficult question of choosing an appropriate conditioning set.
Our MCMC method avoids the challenges associated with discretization
and repeated just-in-time sampling.

\subsection{Random Kernel Metropolis-Hastings}
To circumvent the challenges posed by direct sampling, we present a Metropolis-Hastings (MH)
MCMC algorithm that produces approximate EP samples. The sampler targets the joint distribution 
$\emDist(d\targetTraj) \postDens(\Par; \targetTraj)/\normCst(\targetTraj) d\Par$, 
which admits $\postApproxEP$ as a marginal. At a high level, we consider algorithms that alternate between 
$\Par$ and $\targetTraj$ updates, which update the current MCMC state $(\Par, \targetTraj)$ like
\begin{align}
\targetTraj^\prime &\sim \MarkovKerTarget(\targetTraj, \cdot) \label{eq:f-update} \\
\Par^\prime &\sim \MarkovKerPar(\Par, \cdot \given \targetTraj^\prime), \label{eq:u-update}
\end{align}
where $\MarkovKerTarget$ and $\MarkovKerPar$ are Markov kernels. 
We refer to algorithms of this form as \textit{random kernel MCMC}, motivated by the view of 
$\MarkovKerPar(\Par, \cdot \given \targetEm)$ as a random surrogate-based approximation 
of its exact analog $\MarkovKerPar(\Par, \cdot \given \target)$.
Throughout this section we fix $\MarkovKerPar$ to be an MH kernel defined with respect to a 
proposal kernel $\propDistPar$. The $\Par$-update in \Cref{eq:u-update} thus proceeds by sampling a proposal 
$\propPar \sim \propDistPar(\Par, \cdot)$ and setting the next state $\Par^\prime$ to $\propPar$
with probability 
\begin{equation}
\accProbMH_{\Par}(\Par, \propPar)
= \min\left(1, \frac{\postDens(\propPar; \targetTraj^\prime)}{\postDens(\Par; \targetTraj^\prime)} \cdot 
\frac{\propDensPar(\propPar, \Par)}{\propDensPar(\Par, \propPar)} \right);
\label{eq:MH-ratio-u}
\end{equation}
otherwise $\Par^\prime$ is assigned the current state $\Par$. Here $\propDensPar(\Par, \cdot)$ denotes the density of 
$\propDistPar(\Par, \cdot)$. Provided the unnormalized density $\postDens(\Par; \targetTraj^\prime)$
depends on $\targetTraj^\prime$ only through $\targetTraj^\prime(\Par)$, then the MH update for $\Par$ only requires 
realizing the finite-dimensional projection $[\targetTraj^\prime(\Par), \targetTraj^\prime(\propPar)]$ of the 
function $\targetTraj^\prime$.

\todo[inline]{This is a bit awkward; don't want to cause confusion with derivative of $\targetTraj$}

\subsection{A Preconditioned Crank-Nicholson Random Kernel Algorithm}
Having established the MH update for $\Par$, we now focus on specifying the kernel $\MarkovKerTarget$
in \Cref{eq:f-update}. To motivate our choice, first consider the requirements for an exact
Metropolis-within-Gibbs scheme targeting the joint 
$\emDist(d\targetTraj) \postDens(\Par; \targetTraj)/\normCst(\targetTraj) d\Par$. The $\Par$ update
must leave $\postDens(\Par; \targetTraj) d\Par$ invariant, which is accomplished via the MH 
kernel $\MarkovKerPar(\Par, \cdot \given \targetTraj)$ specified above. The $\targetTraj$ update must leave 
 $\emDist(d\targetTraj) \postDens(\Par; \targetTraj)/\normCst(\targetTraj)$ invariant, requiring more 
 care due to the fact that $\targetTraj$ may be infinite-dimensional. Proceeding in the spirit of 
 function space MCMC methods \citep{functionSpaceMCMC}, we consider an MH step with 
a $\emDist$-reversible proposal distribution $\propDistTarget(\targetTraj, \cdot)$, resulting in 
the acceptance probability 
\begin{equation}
\accProbMH_{\target}(\targetTraj, \tilde{\targetTraj})
= \min\left(1, \frac{\postDens(\Par; \tilde{\targetTraj})}{\postDens(\Par; \targetTraj)} \cdot 
\frac{\normCst(\targetTraj)}{\normCst(\tilde{\targetTraj})} \right)
= \min\left(1, \frac{\postDensNorm(\Par; \tilde{\targetTraj})}{\postDensNorm(\Par; \targetTraj)} \right).
\label{eq:MH-ratio-mwg}
\end{equation}
If $\targetEm \sim \GP(\gpMean, \gpKer)$ 
\footnote{More generally, this applies when the random density $\postEm$ arises as a transformation
of an underlying Gaussian measure. The emulator predictive distribution itself need not be Gaussian.}
then we may define $\propDistTarget(\targetTraj, \cdot)$ via the
preconditioned Crank-Nicholson (pCN; \citet{functionSpaceMCMC}) proposal
\begin{equation}
\tilde{\targetTraj} \Def \gpMean + \pcnCor (\targetTraj  - \gpMean) + \sqrt{1 - \pcnCor^2} \xi, 
\qquad \xi \sim \GP(0, \gpKer). \label{eq:pcn-proposal}
\end{equation}
This Metropolis-within-Gibbs algorithm generally cannot be practically implemented due to the intractable normalizing 
constant ratio $\normCst(\targetTraj)/\normCst(\tilde{\targetTraj})$ in \Cref{eq:MH-ratio-mwg}. 
At first glance, it appears that techniques from the doubly intractable MCMC literature 
\citet{doublyIntractableReview,exchangeAlg} may circumvent this issue, but such methods
 typically require the ability to directly sample $\postDensNorm(\cdot; \tilde{\targetTraj})$,
which is infeasible in this context.
To avoid the challenging task of estimating the 
normalizing constant ratio\todo{cite paper that does try this here?}, 
we instead invoke the simple approximation 
$\postDensNorm(\Par; \tilde{\targetTraj}) / \postDensNorm(\Par; \targetTraj) \approx 1$, 
thus removing the accept-reject correction and instead allowing the $\targetTraj$ chain 
to follow a random walk. This approximation is reasonable when the proposal $\tilde{\targetTraj}$ does 
not differ significantly  from the current state $\targetTraj$. We can control the error in the approximation by 
restricting the scale of $\propDistTarget$, thus slowing down the mixing speed of the $\targetTraj$-chain.
For the pCN proposal in \Cref{eq:pcn-proposal}, the $\pcnCor$ parameter controls the correlation 
between $\targetTraj$ and $\tilde{\targetTraj}$, implying that setting $\pcnCor$ close to one ensures 
$\tilde{\targetTraj}$ is sufficiently similar to $\targetTraj$ on average. We illustrate the effect of this 
approximation through experiments; a complete theoretical analysis is the subject of concurrent work and is
beyond the scope of the present paper.

As currently stated, the pCN update in \Cref{eq:pcn-proposal} is practically implementable only when 
$\targetEm$ admits a finite-dimensional representation. However, the algorithm can still be implemented
exactly (i.e., without discretization) when $\targetEm$ is function-valued by tracking only the 
bivariate projections of the surrogate at the current and proposed parameter values $(\Par, \propPar)$.
\Cref{alg:rk-pcn-finite} summarizes the conceptual implementation, which is realizable in the finite-dimensional
setting. \Cref{alg:rk-pcn-infinite} states the practical implementation for infinite-dimensional surrogates.
Additional implementation details are provided in the appendix.
\todo[inline]{Add section in appendix}

\begin{algorithm}[H]
    \caption{Random Kernel pCN, Finite Dimensional (single iteration)}
    \label{alg:rk-pcn-finite}
    \begin{algorithmic}[1]
    \State \textbf{Input:} Current state $(\Par, \targetTraj)$
    \State \textbf{Output:} Updated state $(\Par^\prime, \targetTraj^\prime)$
    \State $\xi \sim \Gaussian(0, \gpKer)$
    \State $\targetTraj^\prime \gets \gpMean + \pcnCor (\targetTraj  - \gpMean) + \sqrt{1 - \pcnCor^2} \xi$ \Comment{$\targetTraj$ update}
    \State $\propPar \sim \propDistPar(\Par, \cdot), v \sim \mathrm{Unif}(0,1)$
    \State $\alpha_{\Par} \gets \min\left\{1, \postDens(\propPar; \targetTraj^\prime) / \postDens(\Par; \targetTraj^\prime) \right\}$
    \State $\Par^\prime \gets \propPar \indicator{v \leq \alpha_{\Par}} + \Par \indicator{v > \alpha_{\Par}}$ \Comment{$\Par$ update}
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
    \caption{Random Kernel pCN, Infinite Dimensional  (single iteration)}
    \label{alg:rk-pcn-infinite}
    \begin{algorithmic}[1]
    \State \textbf{Input:} Current state $(\Par, \targetTraj_{\Par})$
    \State \textbf{Output:} Updated state $(\Par^\prime, \targetTraj^\prime_{\Par^\prime})$
    \State $\propPar \sim \propDistPar(\Par, \cdot), v \sim \mathrm{Unif}(0,1)$
    \State $\targetTraj_{\propPar} \sim \mathrm{law}(\targetEm(\propPar) \given \targetEm(\Par) = \targetTraj_{\Par})$ \Comment{Just-in-time sample}
    \State $\gpMean^{\Par, \propPar} \Def (\gpMean(\Par), \gpMean(\propPar))^\top$, $K_{\star}^{\Par, \propPar} \Def \gpKer((\Par, \propPar), (\Par, \propPar))$ \Comment{Bivariate projection}
    \State $\xi \sim \Gaussian(0, K_{\star}^{\Par, \propPar})$
    \State $(\targetTraj^\prime_{\Par}, \targetTraj^\prime_{\propPar})^\top \gets 
    	\gpMean^{\Par, \propPar} + \pcnCor \{(\targetTraj_{\Par}, \targetTraj_{\propPar})^\top  - \gpMean^{\Par, \propPar}\} + \sqrt{1 - \pcnCor^2} \xi$ \Comment{$\targetTraj$ update}
    \State $\alpha_{\Par} \gets \min\left\{1, \postDens(\propPar; \targetTraj^\prime) / \postDens(\Par; \targetTraj^\prime) \right\}$ 
    	\Comment{Compute using $\targetTraj^\prime_{\Par}, \targetTraj^\prime_{\propPar}$}
    \State $\Par^\prime \gets \propPar \indicator{v \leq \alpha_{\Par}} + \Par \indicator{v > \alpha_{\Par}}$ \Comment{$\Par$ update}
    \State $\targetTraj^{\prime}_{\Par^\prime} \gets \targetTraj^\prime_{\propPar} \indicator{v \leq \alpha_{\Par}} + \targetTraj^\prime_{\Par} \indicator{v > \alpha_{\Par}}$
    \end{algorithmic}
\end{algorithm}

\subsection{A Correlated Pseudo-Marginal Algorithm}
The approximate MwG scheme above is derived by invoking the approximation 
$\postDensNorm(\Par; \tilde{\targetTraj}) / \postDensNorm(\Par; \targetTraj) \approx 1$.
A natural alternative is to invoke the approximation 
$\normCst(\targetTraj) / \normCst(\tilde{\targetTraj}) \approx 1$,
which yields the acceptance probability
\begin{equation}
\accProbMH_{\target}(\targetTraj, \tilde{\targetTraj})
= \min\left(1, \frac{\postDens(\Par; \tilde{\targetTraj})}{\postDens(\Par; \targetTraj)}\right).
\label{eq:MH-ratio-cpm}
\end{equation}
This is precisely a correlated psuedo-marginal (cPM) that exactly targets $\postApproxEP$.
See \citet{pseudoMarginalMCMC,pseudoMarginalEfficiency,corrPM}
for background on pseudo-marginal MCMC.
 
\todo[inline]{Move to appendix?}

\paragraph{Related work.} \todo{update this section to align with new notation}
The pseudo-marginal approach to EUP-based inference is noted in \citep{StuartTeck1} and studied 
in depth in \citep{garegnani2021NoisyMCMC}. \citet{BurknerSurrogate} propose targeting the 
distribution proportional to $\hat{\postDens}^M(\Par; \targetTraj_{1:M})$, where $\targetTraj_{1:M}$
is fixed across all MCMC iterations. This does not target the EUP exactly, and can be viewed
as an analog of the sample average approximation from the optimization literature \citep{SAA}.
To improve MCMC efficiency, \citet{garegnani2021NoisyMCMC} also considers ``noisy'' approximations
of the EUP. In contrast to pseudo-marginal algorithms, these methods re-sample both 
$\targetTraj_{1:M}$ and $\tilde{\targetTraj}_{1:M}$ each iteration. 
\citet{FerEmulation} utilize a similar noisy algorithm with $M = 1$, adopting an
approximate computation viewpoint rather than explicitly trying to target $\postApproxEUPNorm$.

Both \citep{garegnani2021NoisyMCMC} and \citet{BurknerSurrogate} propose MwMC schemes
for EP-based inference. They appear to implicitly assume the use of finite-dimensional emulators,
as difficulties related to sampling trajectories are not addressed. There has been interest in the 
modular Bayes community in designing approximate MCMC schemes as an alternative to
MwMC for cut posterior inference. \citet{PlummerCut} describes the implementation of such 
an algorithm in the WinBUGS software \todo{cite}, referred to as the \textit{naive cut algorithm}.
The author shows that this algorithm does not admit the cut posterior as an invariant
distribution, and moreover that the implicit target distribution depends on the particular Markov kernels
chosen to perform the updates. The paper proposes a solution to improve the approximation 
using tempered transitions. Subsequent work has considered more sophisticated algorithms
that seek to explicitly estimate the intractable normalizing constant ratios
\citep{SAACut} \todo{add Yves' paper here} 
Our MwG algorithm can be viewed as a version of the naive cut algorithm operating in function space.
We opt to avoid normalizing constant estimation and instead slow down the mixing of the 
$\targetTraj$-chain to control the approximation error.

\section{Numerical Experiments} \label{sec:experiments}
We consider several numerical experiments, with the dual aims of (i.) comparing the EP, EUP, and
plug-in mean approximation under various surrogate modeling setups, and (ii.) assessing the 
quality of the rk-pcn approximation to the EP. For the latter, we evaluate the rk-pcn algorithms in
\Cref{alg:rk-pcn-finite,alg:rk-pcn-infinite} at different values of the correlation parameter $\pcnCor$. 
We compare these MCMC approximations against the EUP as well as the naive cut algorithm 
described in \citet{PlummerCut}. We note that there is a growing literature on approximate algorithms 
for cut posterior inference, but our focus in the present paper is on evaluating the rk-pcn algorithm in 
the surrogate modeling setting.
\todo[inline]{cite a few papers here}

% Linear Gaussian Example
\subsection{Linear Gaussian Example}
We start with a toy linear Gaussian model in which the exact posterior, EP, and EUP are all 
Gaussian and available in closed-form. A similar example is considered in
\citet{garegnani2021NoisyMCMC}. Consider the linear Gaussian inverse problem
\begin{align}
\obs &= \fwdLin \Par + \noise
&&\noise \sim \Gaussian(0, \noiseCov) \label{eq:lin-Gauss-inv-prob} \\
\Par &\sim \Gaussian(\priorMean, \priorCov). \nonumber
\end{align}
The exact posterior is $\Par \given \obs \sim \Gaussian(\postMean, \postCov)$, where
\begin{align}
\postMean &= \postCov \left(\fwdLin^\top \noiseCov^{-1}\obs + \priorCov^{-1}\priorMean \right) \label{eq:lin-Gauss-post-moments} \\
\postCov &= \left(\fwdLin^\top \noiseCov^{-1}\fwdLin + \priorCov^{-1} \right)^{-1}. \nonumber
\end{align}
We consider a forward model emulator of the form
\begin{align}
\targetEm(\Par) \sim \Gaussian(\fwdLin\Par + \emBias, \emCov) \label{eq:lin-Gauss-em}, 
\end{align}
corresponding to an additive Gaussian shift of the true model, with bias $\emBias$.
The covariance $\emCov$ quantifies the surrogate uncertainty regarding the magnitude of the bias.
In this toy example, the surrogate randomness does not vary with $\Par$, in contrast to the 
emulators considered in the following more realistic experiments.
The following result characterizes the EP and EUP in this setting. See the appendix for derivations.

\begin{prop}
Under the linear Gaussian model in \Cref{eq:lin-Gauss-inv-prob} with the emulator in \Cref{eq:lin-Gauss-em},
the EP is given by $\postApproxEP(\Par) = \Gaussian(\Par \given \postMeanEP, \postCovEP)$, where
\begin{align}
\postMeanEP &= \postMean - \epGain \emBias,
&&\postCovEP = \postCov + \epGain \emCov \epGain^\top,
\label{eq:lin-gauss-ep}
\end{align}
and $\epGain \Def \postCov \fwdLin^\top \noiseCov^{-1}$. The quantities $\postMean, \postCov$ are the 
exact posterior moments given in \Cref{eq:lin-Gauss-post-moments}. Under the same setup, the 
EUP is given by $\postApproxEUP(\Par) = \Gaussian(\Par \given \postMeanEUP, \postCovEUP)$, where
\begin{align}
&\postMeanEUP = \postCovEUP \left(\fwdLin^\top \eupNoiseCov^{-1}\eupObs + \priorCov^{-1}\priorMean \right),
&&\postCovEUP = \left(\fwdLin^\top \eupNoiseCov^{-1}\fwdLin + \priorCov^{-1} \right)^{-1}
\label{eq:lin-gauss-eup}
\end{align}
and $\eupNoiseCov \Def \noiseCov + \emCov$, $\eupObs \Def \obs - \emBias$.
\label{eq:lin-gauss-posts}
\end{prop}

\subsubsection{Analytical Analysis}
Let $G = USV^\top$ denote the singular value decomposition of $G$, with the singular values $(s_j)$ sorted
in descending order. The right singular vectors $v_j$ associated with large $s_j$ correspond to directions in 
parameter space that are well-informed by the data. We investigate the posterior mean and covariance of 
the EUP and EP in the $V$ basis to understand the influence of the surrogate noise. To simplify matters, consider
the special case $\noiseCov = \sigma^2 I$, $\priorCov = c_0^2 I$, $\emCov = q^2 I$. The following results give
the expressions for the exact, EUP, and EP posterior moments in the $V$ basis.
\begin{prop}
Under the above assumptions $\postCov$, $\postCovEUP$, and $\postCovEP$ are diagonalized in the 
$V$ basis, with respective eigenvalues given by 
\begin{align}
\lambda_j = \frac{c_0^2}{1 + \frac{c_0^2 s_j^2}{\sigma^2}}, \qquad
\lambda_j^{\eup} = \frac{c_0^2}{1 + \frac{c_0^2 s_j^2}{\sigma^2 + q^2}}, \qquad
\lambda_j^{\ep} = \lambda_j + \frac{q^2 s_j^2 c_0^4}{\sigma^4}.
\end{align}
Moreover, the posterior means of each distribution can be written as linear combination of the $v_j$. The 
coefficients in these linear combinations in directions with $s_j \neq 0$ are given by
\begin{align*}
&\alpha_j = \frac{\lambda_j s_j}{\sigma_j^2} \langle y, u_j \rangle + \frac{\lambda_j}{c_0^2} \langle m_0, v_j \rangle, 
&&\alpha_j^{\eup} = \frac{\lambda_j s_j}{\sigma^2 + q^2} \langle y - r, u_j \rangle + \frac{\lambda_j}{c_0^2} \langle m_0, v_j \rangle \\
&\alpha_j^{\ep} = \alpha_j - \frac{c_0^2 s_j}{\sigma^2} \langle r, u_j \rangle.
\end{align*}
\end{prop}
\todo[inline]{fix formatting}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.7\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./../experiments/linear_Gaussian/out/experiment1_svd_lambda.png}
        \label{fig:plot1a}
    \end{subfigure}

    \begin{subfigure}{0.7\linewidth}
        \centering
        \includegraphics[width=\linewidth]{./../experiments/linear_Gaussian/out/experiment1_svd_alpha.png}
        \label{fig:plot1b}
    \end{subfigure}
    \vspace{0.5em}

    \caption{Scaling behavior as a function of $q / \sigma$, with $c_0 = 1.0$, $\sigma=1.0$, $r = (2.5, \dots, 2.5)^\top$.
    The forward model $G$ is the convolution operator used in \Cref{sec:deconvolution}, with parameter and 
    data dimensions $\dimPar = 100$, $\dimObs = 25$.
    The plots show the variance and mean coordinates along certain $v_j$ directions (smaller $j$ indicating directions better informed by data),
    relative to the exact (no surrogate) posterior analogs. Starting from the top-left in clockwise
    order, the plots display $\lambda_j^{\eup} / \lambda_j$, $\lambda_j^{\ep} / \lambda_j$, 
    $\alpha_j^{\eup} - \alpha_j$, and $\alpha_j^{\ep} - \alpha_j$ as a function of $q / \sigma$.}
    \label{fig:lin-gauss-svd-plots}
\end{figure}

The behavior of the EUP and EP as the surrogate uncertainty increases is markedly different. As $q \to \infty$, the EUP 
reverts to the $\Gaussian(\priorMean, \priorCov)$ prior, while the EP tends toward a flat distribution centered
on $\postMeanEP$. In the non-asymptotic regime, the surrogate uncertainty inflates both $\postMeanEUP$ and 
$\postMeanEP$ most significantly along directions well-informed by the data ($v_j$ with $s_j$ large). These 
trends are illustrated for a concrete numerical example in \Cref{fig:lin-gauss-svd-plots}. Note that $\postMeanEP$
is independent of $\emCov$ and thus does not vary with the level of surrogate uncertainty.

\subsubsection{A Deconvolution Problem} \label{sec:deconvolution}
We now consider a concrete instantiation of the linear Gaussian inverse problem, representing
deconvolution for a one-dimensional signal. The parameter $\Par \in \R^{100}$ of interest is 
a discretized signal over the domain $\parSpace = [0,100]$. The forward operator $G$ is the composition
of a linear convolution with a Gaussian kernel, with an observation operator that selects every 
fourth grid point. The data space is thus of dimension $\dimObs=25$. We consider $\Sigma = \sigma^2 I$
with $\sigma = 0.2$ and define $\priorCov$ as a Gaussian kernel matrix, encoding a smoothness 
assumption for the signal. Finally, we consider a surrogate with $\emCov = G \priorCov G^\top$, 
which assumes the surrogate bias follows the same smoothness as the underlying signal.
We run one hundred replicate experiments with this setup, with each replicate sampling a 
ground truth parameter $\Par_{\circ}$ from the prior, generating synthetic data using this parameter, and 
sampling the emulator bias $r$ from $\Gaussian(0, \emCov)$. Thus, each surrogate replicate is 
biased but well-calibrated on average. \Cref{fig:lin-gauss-replicate-summary} displays the marginal 
distributions for the exact posterior and surrogate predictive distribution for a single replicate.

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./../experiments/linear_Gaussian/out/experiment1_exact_post.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./../experiments/linear_Gaussian/out/experiment1_surrogate.png}
    \end{subfigure}
    \caption{Summary of the exact posterior and surrogate marginal distributions for a single replicate in the experiment.
    \textit{(Left)} The true posterior mean, $\pm 2$ standard deviations (shaded blue), $\pm 2$ prior standard deviations, and observations (red).
    \textit{(Right)} Marginal distributions of $\targetEm(\Par_{\circ})$, the surrogate evaluated at the ground truth parameter. The shaded region
    encloses $\pm 2$ predictive standard deviations. The surrogate only predicts at the observation locations.}
    \label{fig:lin-gauss-replicate-summary}
\end{figure}



\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{./../experiments/linear_Gaussian/out/experiment1_coverage.png}
    \caption{Joint coverage of the plug-in mean, EUP, and EP approximations, relative to the exact posterior.
    		 The shaded regions summarize the middle 90\% of the replicates. Joint coverage is defined 
		  via the Gaussian coverage ellipsoids at the different probability levels.}
    \label{fig:lin-gauss-coverage}
\end{figure}
\Cref{fig:lin-gauss-coverage} summarizes the calibration of the three surrogate-based posterior approximations
at different coverage levels. As the surrogate is biased, the plug-in mean posterior systematically fails to cover
the true posterior. By propagating the surrogate uncertainty, both the EP and EUP achieve reasonable coverage 
on average.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{./../experiments/linear_Gaussian/out/experiment1_mcmc.png}
    \caption{The 2-Wasserstein distance between various approximations to the EP. The box plots summarize 
    		 variability over the 100 replicates. For the EUP the distance is computed
    		 in closed-form, as both distributions are Gaussian. The remaining approximations include the rk-pcn
		 algorithm with $\rho \in \{0.9, 0.95, 0.99\}$ and the naive cut algorithm of \citet{PlummerCut}.
		 For these algorithms,
		 burn-in samples are dropped and the remaining samples are used to fit a Gaussian approximation,
		 which is then used in the closed-form distance formula.}
    \label{fig:lin-gauss-mcmc}
\end{figure}


% Ecosystem Model Calibration
\subsection{Ecosystem Model Calibration} \label{sec:vsem}
Our next example is motivated by the problem of producing near-term forecasts of the 
terrestrial carbon cycle \citep{nearTermForecasts,FerEmulation}. In this setting, model parameters 
are typically unknown and must be learned from observational data. Parameter estimation runs into 
computational challenges for large-scale land surface models, 
underscoring the potential for surrogates in this domain \citep{paramLSM}. 

We consider a synthetic data experiment using the \textit{Very Simple Ecosystem Model} (VSEM), 
a toy model capturing the basic structure of more complex land surface models \citep{vsem}. The model 
describes the evolution of the state vector 
$\state(\Time) \Def [\stateV(\Time), \stateR(\Time), \stateS(\Time)]^\top \in \R_{\geq 0}^{3}$,
with the state variables representing the quantity of carbon (\textrm{kg C/$m^2$}) in above-ground vegetation, 
below-ground vegetation (roots), and soil pools, respectively. These states evolve according to the system of coupled 
ordinary differential equations
\begin{align}
\dstateV(\Time) &= \alphaV \NPP(\stateV(\Time), \forcing(\Time)) - \frac{\stateV(\Time)}{\tauV} \\
\dstateR(\Time) &= (1.0 - \alphaV) \NPP(\stateV(\Time), \forcing(\Time)) - \frac{\stateR(\Time)}{\tauR} \nonumber \\ 
\dstateS(\Time) &= \frac{\stateR(\Time)}{\tauR} + \frac{\stateV(\Time)}{\tauV} - \frac{\stateS(\Time)}{\tauS}, \nonumber
\end{align}
where the model forcing $\forcing(\Time)$ is provided by photosynthetically active radiation 
(\textrm{MJ/$m^2$/day}), and the dynamics rely on the following parameterized model of 
Net Primary Productivity (NPP; \textrm{kg C/$m^2$/day}),
\begin{align}
\NPP(\stateV, \forcing) &= (1 - \fracRespiration) \GPP(\stateV, \forcing) \\
\GPP(\stateV, \forcing) &= \forcing \cdot \LUE \cdot \left[1 - \exp\left\{-\KEXT \cdot \LAI(\stateV) \right\} \right] \nonumber \\
\LAI(\stateV) &= \LAR \cdot \stateV, \nonumber
\end{align} 
where $\GPP(\stateV, \forcing)$ and $\LAI(\stateV)$ model Gross Primary Productivity (GPP; \textrm{kg C/$m^2$/day})
and Leaf Area Index (LAI; \textrm{$m^2/m^2$}), respectively.
We numerically solve the ODE at a daily time step
via the basic Euler scheme as implemented in the R \verb+BayesianTools+ package \citep{vsem}. 

We consider estimating the parameters $\Par \Def (\KEXT, \alphaV)$ given noisy monthly averages of LAI over a 
two year period. We assume an additive Gaussian noise model
\begin{align*}
&\obs = \fwd(\Par) + \noise,
&&\noise \sim \Gaussian(0, \sigma^2 I) 
\end{align*}
where $\fwd: \parSpace \to \R^{24}$ maps to the twenty-four LAI averages. For simplicity, we fix $\sigma^2$
and assume independent uniform priors on $\Par$. Synthetic data $\obs$ is simulated
using this model with fixed ground truth values $\{\Par_{\circ}, \sigma_{\circ}^2\}$.
\todo[inline]{state the specific values/priors here}

We consider a GP emulator of the log-posterior $\target(\Par) \Def \log\{\priorDens(\Par) p(\obs \given \Par)\}$.
The GP prior is defined via a constant mean function and a Gaussian kernel. The training (i.e., design) data
$\{(\Par_n, \target(\Par_n))\}_{n=1}^{\Ndesign}$ is constructed by sampling a set of points from the prior and then 
evaluating the exact log-posterior density at these points. The GP mean constant and kernel hyperparameters are 
optimized by maximum marginal likelihood using the \verb+gpjax+ Python package \todo{cite}. 

\section{Conclusion} \label{sec:conclusion}

% Appendix
\section{Appendix}

For the below proofs we use the following measure-theoretic setup.
Let $\refMeas$ be a reference measure (e.g., Lebesgue) on $(\parSpace, \BorelSig)$,
and $\emDist$ a probability measure on $(\emSpace, \emSig)$. Assume that 
the map $(\Par, \targetTraj) \mapsto \postDens(\Par; \targetTraj)$ from $\parSpace \times \emSpace$
to $\R_{\geq 0}$ is measurable
and $\normCst(\targetTraj) \Def \int \postDens(\Par; \targetTraj) \emDist(\d\targetTraj) \in (0,\infty)$
$\emDist$-almost surely. Let $\postDensNorm(\Par; \targetTraj) \Def \postDens(\Par; \targetTraj) / \normCst(\targetTraj)$
and define the joint distribution 
$\emJoint(\d\Par, \d\targetTraj) \Def \postDensNorm(\Par; \targetTraj) \refMeas(\d\Par)\emDist(\d\targetTraj)$.
Define $\postApproxEP$ to be the density corresponding to the $\Par$-marginal of $\emJoint$; that is,
$\postApproxEP(\Par) \Def \int \postDensNorm(\Par; \targetTraj) \emDist(\d\targetTraj)$. 

\subsection{Proof of \Cref{prop:EP-variational}}
\paragraph{KL Divergence.} We start by proving the KL divergence result.
Let $\qMeas$ be a probability measure on $\parSpace$ with 
$\refMeas$-density $\qDens$. We restrict to measures 
$\postApproxEP \ll \qMeas$, as the KL divergence is infinite otherwise. 
Note that 
$\frac{\d\emJoint}{\d(\emDist \otimes \qMeas)}(\Par, \targetTraj) = \frac{\postDensNorm(\Par; \targetTraj)}{\qDens(\Par)}$.
Using Tonelli's theorem, we have 
\begin{align*}
\E_{\emDist}\left[\KL{\postNormEm}{\qMeas} \right]
&= \int_{\emSpace} \int_{\parSpace} 
\postDensNorm(\Par; \targetTraj) \log \frac{\postDensNorm(\Par; \targetTraj)}{\qDens(\Par)}
\refMeas(\d\Par) \emDist(\d\targetTraj) \\
&= \int_{\parSpace \times \emSpace}  \log \frac{\postDensNorm(\Par; \targetTraj)}{\qDens(\Par)}
\emJoint(\d\Par, \d\targetTraj) \\
&= \int_{\parSpace \times \emSpace}  \log \frac{\d\emJoint}{\d(\emDist \otimes \qMeas)}(\Par, \targetTraj)
\ \emJoint(\d\Par, \d\targetTraj) \\
&= \KL{\emJoint}{\emDist \otimes \qMeas}.
\end{align*}
Finally, 
\begin{align*}
\KL{\emJoint}{\emDist \otimes \qMeas}
&= \int \log \frac{\d\emJoint}{\d(\emDist \otimes \qMeas)} \d\emJoint \\
&= \int \log \left[\frac{\d\emJoint}{\d(\emDist \otimes \postApproxEP)} \frac{\d(\emDist \otimes \postApproxEP)}{\d(\emDist \otimes \qMeas)}\right] d\emJoint \\
&\proptoAdd \int \log \frac{\d(\emDist \otimes \postApproxEP)}{\d(\emDist \otimes \qMeas)} \d\emJoint \\
&= \int_{\emSpace \times \parSpace} 
\log \frac{\postApproxEP(\Par)}{\qDens(\Par)} \postDensNorm(\Par; \targetTraj) \emDist(\d\targetTraj) \refMeas(\d\Par) \\
&= \int_{\parSpace} \log \frac{\postApproxEP(\Par)}{\qDens(\Par)} 
 \postApproxEP(\Par) \refMeas(\d\Par) \\
&= \KL{\postApproxEP}{\qMeas},
\end{align*} 
where we have used $\proptoAdd$ to absorb additive constants with respect to $\qMeas$. The result follows 
from the fact that $\KL{\postApproxEP}{\qMeas}$ is uniquely minimized at $\qMeas = \postApproxEP$. $\qquad \blacksquare$

\paragraph{Squared $L_2$ loss.} 
For the expected squared error objective, apply Tonneli's theorem 
\begin{align}
\E_{\emDist}\left[\norm{\postNormEm - \qMeas}^2_{L_2(\parSpace)} \right]
&= \int \E_{\emDist} \left[\postDensNorm(\Par; \targetTraj) - \qDens(\Par) \right]^2 \refMeas(d\Par) \nonumber
\end{align}
and notice that the integrand is minimized pointwise by
$\qDens(\Par) = \E_{\emDist}[\postDensNorm(\Par; \targetTraj)] = \postApproxEP(\Par)$. $\qquad \blacksquare$
 
\subsection{Proof of \Cref{prop:kl-cut-op}}
Recall the joint distribution 
$\jointKOH(\d\Par, \d\targetTraj, \d\obs, \d\emObs) =
\priorDens(\Par) \lik(\Par; \targetTraj, \obs) \emLik(\targetTraj; \emObs) 
\emDistPrior(\d\targetTraj) \, \d\Par \, \d\obs \, \d\emObs$
with conditional $\postKOH(\d\Par, \d\targetTraj)$.
Let $\postKOH_{\targetTraj}(\d\Par)$ denote the $\targetTraj$-marginal of this conditional.
Similarly, let $\condMargKOH$ denote the marginal conditional of 
$\Par$ given $(\obs,\targetTraj)$.
By the disintegration theorem, any $\qMeas \in \qSpaceCut$ can be written as 
$\qMeas(\d\Par, \d\targetTraj) = \emDist(\d\targetTraj) \qCond(\targetTraj, \d\Par)$ since 
$\qSpaceCut$ restricts the $\targetTraj$-marginal of $\qMeas$ to equal $\emDist$.
Subject to regularity conditions \todo{be precise here}, it follows that
\begin{equation}
\frac{\d\qMeas}{\d\postKOH}(\Par, \targetTraj) =
\frac{\d\emDist}{\postKOH_{\targetTraj}(\d\Par)}(\targetTraj)
\frac{\d\qCond(\targetTraj,\cdot)}{d\condMargKOH}(\Par).
\end{equation}
Therefore,
\begin{align*}
\KL{\qMeas}{\postKOH} 
&= \int \log \left[\frac{\d\qMeas}{\d\postKOH}\right] \qMeas(\d\Par, \d\targetTraj) \\
&\proptoAdd \int \log \left[\frac{\d\qCond(\targetTraj,\cdot)}{d\condMargKOH}(\Par)\right] \emDist(\d\targetTraj) \qCond(\targetTraj,\d\Par) \\
&= \int_{\emSpace} \left\{\int_{\parSpace}  
\log \left[\frac{\d\qCond(\targetTraj,\cdot)}{d\condMargKOH}(\Par)\right] \qCond(\targetTraj,\d\Par) \right\} \emDist(\d\targetTraj) \\
&= \int_{\emSpace} \KL{\qCond(\targetTraj,\cdot)}{\condMargKOH} \emDist(\d\targetTraj).
\end{align*}
Since the integrand is minimized pointwise by $\qCond(\targetTraj,\cdot) = \condMargKOH$, it follows that
$\qMeasOpt(\d\Par, \d\targetTraj) = \emDist(\d\targetTraj)\condMargKOH(\d\Par)$. $\qquad \blacksquare$
 
\subsection{Proofs of \Cref{prop:ep-eup-pw-err} and \Cref{prop:ep-eup-TV-err}}
Recall that for two random variables $a$ and $b$ it holds that $\E[ab] = \E[a]\E[b] + \Cov(a,b)$.
Applying this identity, we have
\begin{equation*}
\postApproxEP(\Par)
= \emE[\postEm(\Par) \normCstEm^{-1}]
= \emE[\postEm(\Par)] \emE[\normCstEm^{-1}] + \Cov(\postEm(\Par), \normCstEm^{-1}).
\end{equation*} 
Subtracting $\postApproxEUPNorm(\Par) = \emE[\postEm(\Par)] / \emE[\normCstEm]$
and grouping terms completes the derivation. The integrated error follows from applying the 
triangle inequality, integrating over $\parSpace$, and applying Tonelli's theorem, which gives
\begin{equation*}
\int \emE[\postEm(\Par)] \refMeas(\d\Par) = \emE \int \postEm(\Par) \refMeas(\d\Par) = \emE[\normCstEm]
\qquad \blacksquare
\end{equation*} 
 
\bibliography{./../shared/surrogates} 
% \bibliographystyle{ieeetr}

\end{document}


