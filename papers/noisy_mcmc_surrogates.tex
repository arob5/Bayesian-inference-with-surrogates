\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode} % Note that this also loads algorithmicx
\usepackage{cleveref}
\usepackage{natbib}
\usepackage{bbm}
\usepackage{caption, subcaption} % Captions and sub-figures. 
\usepackage{fancyvrb} % For writing using verbatim font inline. 
% \usepackage[demo]{graphicx}

% For tables
\usepackage{array}
\usepackage{booktabs}

% Bibliography
\bibliographystyle{plainnat}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Tables. 
\usepackage{multirow}

% Local custom commands. 
\include{latex_macros_general}
\include{latex_macros_gp_inv_prob}
\newcommand{\bphi}{\boldsymbol{\phi}}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{{./figures/}}

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}

% Title and author
\title{Uncertainty Propagation and Active Learning for Surrogate-Based Bayesian Inference}
\author{Andrew Roberts}

\begin{document}

\maketitle

Simulation-based computer models are key tools for studying complex systems within 
the physical, biological, and engineering sciences. 
Such models often have uncertain parameters that must be estimated from data. 
Bayesian methods are commonly employed
to quantify uncertainty in these parameter calibration tasks.
However, standard Bayesian inference algorithms such as Markov chain Monte Carlo (MCMC) 
are hindered by the computational cost of the simulation model.
A popular approach to deal with this issue is to train a surrogate model 
(i.e., emulator) as a computationally thrifty approximation of the expensive computer code.
Surrogates have seen widespread use in Bayesian inference pipelines across a variety 
of applications [\todo: cite]. 

Despite significant advances in surrogate modeling, fitting a 
highly accurate emulator under a limited computational budget remains a challenging task.
In computationally-intensive applications, the surrogate error can be non-negligible. 
This error is propagated when the emulator is used to infer the values of the calibration 
parameters, potentially leading to overconfident results with miscalibrated uncertainty 
estimates in downstream applications \citep{BurknerSurrogate}.
It is thus crucial to acknowledge and propagate this 
additional source of uncertainty in surrogate-based Bayesian workflows.
Probabilistic surrogates such as Gaussian processes \citep{gpML,gramacy2020surrogates} 
and probabilistic neural networks \citep{deepEnsembles,BayesOptNN} provide a notion of 
predictive uncertainty that can utilized to this end
 \citep{reviewPaper,BilionisBayesSurrogates,BurknerSurrogate,CES,FerEmulation}.
 Despite this, applications of surrogate-based Bayesian inference routinely ignore 
 surrogate uncertainty [\todo], or propagate it in ad hoc ways [\todo: cite].
 
Typical surrogate-modeling workflows employ a two-step procedure
in which an emulator is fit to data generated from a computer model in the first stage, 
and then deployed in a second stage to accelerate inference for the computer 
model parameters \citep{modularization,BurknerTwoStep,BurknerSurrogate}. 
In the first step, emulators are trained to approximate a particular target quantity, 
often a summary of the computer model outputs 
(e.g., \citet{hydrologicalModel,idealizedGCM,Surer2023sequential}), the log-likelihood
function (e.g., \citet{VehtariParallelGP,FATES_CES,trainDynamics}), or the unnormalized 
log-posterior density (e.g., \citet{emPostDens,gp_surrogates_random_exploration,Kandasamy_2017}).
In the second step, the emulator 
is inserted in place of the target quantity to enable the application of Bayesian inference  
algorithms without requiring further queries to the expensive simulator.

This modular framework 
has several practical benefits \citep{modularization,PlummerCut}, but leaves open the 
question as to the ``correct'' approach for propagating surrogate uncertainty within the 
posterior approximation in the second stage. A variety of uncertainty-aware posterior 
approximations have been proposed, but little guidance exists on choosing a particular 
method \citep{reviewPaper,BilionisBayesSurrogates,StuartTeck1,VehtariParallelGP,
BurknerSurrogate,BurknerTwoStep,FerEmulation}. Moreover, previous research 
tends to focus on a particular surrogate model (e.g., Gaussian process) and target 
(e.g., the log-likelihood), limiting the ability to understand how a particular 
uncertainty propagation method may perform under different modeling setups. 
 
In addition to improving our conceptual understanding of competing uncertainty 
propagation methods, the development of practical, general-purpose computational 
algorithms are needed to support generic workflows for modular surrogate-based 
Bayesian inference. A wide body of work has sidestepped computational difficulties
by focusing on special cases that allow for tractable surrogate approximations of the 
likelihood function 
\citep{StuartTeck1,GP_PDE_priors,hydrologicalModel,hydrologicalModel2,
Surer2023sequential,VillaniAdaptiveGP,weightedIVAR,idealizedGCM,CES,
FATES_CES,VehtariParallelGP,quantileApprox}. A closed-form likelihood approximation
enables the use of standard MCMC software. However, such approaches typically require 
particular distributional assumptions on the emulator predictive distribution and the 
likelihood function. \citep{garegnani2021NoisyMCMC} studies the application of 
pseudo-marginal and ``noisy'' MCMC algorithms, which do not rely on such distributional
assumptions. \citep{BurknerSurrogate} propose a generic probabilistic programming workflow,
including MCMC schemes for a variety of different uncertainty propagation methods. 

[\todo: need to motivate our work here; these two papers don't directly apply to the GP setting]

\paragraph{Contributions.}
As summarized above, a wide variety of methods have been proposed for 
uncertainty-aware posterior approximation in surrogate-based Bayesian inference. 
In this paper, we provide new insights into when and why the performance of different 
methods can deviate. In particular, we investigate the implications of propagating
uncertainty through the derivation of a pointwise likelihood approximation, as compared 
to aggregating samples from an ensemble of posterior approximations. We demonstrate 
that the extent to which these two methods agree depends crucially on the emulator 
target and on the tails of the emulator predictive distribution. 

[\todo: paragraph on MCMC] [\todo: paragraph on practical considerations/model checking]

These algorithms require only
slight adjustments to standard MCMC implementations, and are generally applicable to any 
surrogate with a predictive distribution from which samples can be drawn.

% Surrogates for Bayesian Inverse Problems
\section{Surrogates for Bayesian Inverse Problems}

\subsection{Bayesian Inference Setting}
We consider the general goal of estimating parameters $\Par \in \parSpace \subseteq \R^{\dimPar}$ given 
observations $\obs \in \obsSpace \subseteq \R^{\dimObs}$ within a Bayesian framework.
Assuming a prior density $\priorDens(\Par)$ and likelihood $p(\obs \given \Par)$, 
we seek to characterize the posterior distribution 
\begin{align}
&\postDensNorm(\Par) \Def p(\Par \given \obs) = \frac{1}{\normCst} \priorDens(\Par) p(\obs \given \Par), 
&&\normCst = \int_{\parSpace} \priorDens(\Par) p(\obs \given \Par) d\Par, \label{post_dens_generic}
\end{align}
where $\normCst$ is an (intractable) normalizing constant. 
Let $\postDens(\Par) \Def \priorDens(\Par) p(\obs \given \Par)$ denote the unnormalized posterior 
density, which plays a central role in our development. 
We assume that pointwise evaluations of  $\postDens(\Par)$ can be computed, but at significant 
computational expense. This renders standard iterative optimization and sampling algorithms 
(e.g., MCMC) infeasible, as each iteration requires a new density evaluation $\postDens(\Par)$.

\subsection{Bayesian Inverse Problems}
The challenge posed by computationally expensive density evaluations $\postDens(\Par)$ commonly 
arises in the Bayesian approach to inverse problems \citep{Stuart_BIP}. In this setting, 
the likelihood often takes the form $\obs = \fwd(\Par) + \noise$ for some forward model
$\fwd: \parSpace \to \obsSpace$. For a concrete example, we consider the problem of estimating the 
parameters in a system of ordinary differential equations (ODEs)
\begin{align}
\frac{d}{d\Time} \state(\Time, \Par) &= \odeRHS(\state(\Time, \Par), \Par), &&x(\timeStart) = \stateIC, \label{ode_ivp}
\end{align}
where the dynamics depend on parameters $\Par$. Each value for $\Par$ implies a different solution trajectory
$[\state(\Time, \Par)]_{\timeStart \leq \Time \leq \timeEnd}$, which we encode by the
map $\solutionOp: \Par \mapsto [\state(\Time, \Par)]_{\timeStart \leq \Time \leq \timeEnd.}$. The goal is then 
to identify the parameters that yield trajectories in agreement with observed data 
$\obs$, which is assumed to be some noise-corrupted function $\obsOp$ of the true trajectory. Thus, the 
likelihood is of the form 
\begin{align}
&\obs = \fwd(\Par) + \noise, &&\fwd \Def \obsOp \circ \solutionOp. \label{eq:additive-noise}
\end{align}
In practice, the ODE is solved numerically so $\solutionOp$ represents the map induced by a numerical 
solver. Therefore, in this setting the computational cost of computing $\postDens(\Par)$ stems from the 
dependence of the likelihood on $\fwd(\Par)$, and in particular on the solver $\solutionOp(\Par)$.

\subsection{Surrogates Targets for Bayesian Inference} \label{sec:surrogates-Bayes}
Given the cost of computing $\postDens(\Par)$, we seek to approximate
the posterior using a small set of queries to the posterior density. 
Surrogate models (i.e., emulators) leverage this limited information by 
learning a map which yields predictions of $\postDens(\Par)$ at new values 
of $\Par$. Typically, the emulator does not learn the map
$\Par \mapsto \postDens(\Par)$ directly, but rather induces an approximation
of $\postDens$ by approximating some underlying target map 
$\Par \mapsto \func(\Par)$. Different target maps may be emulated in order to
 accelerate Bayesian inference, so long as $\func(\Par)$ is sufficient to compute 
 $\postDens(\Par)$ without requiring additional simulator runs. We write 
 $\postDens(\Par; \func)$ to indicate the dependence of the posterior density 
 on $\func$, with the assumption that $\postDens(\Par; \func)$ is relatively 
 quick to compute once the expensive computation $\func(\Par)$ is
 obtained. 

Consider a computational budget of $\Ndesign$ evaluations of $\func$, where 
$\Ndesign$ is typically much smaller than that required by standard posterior
inference algorithms. Surrogate modeling offers a solution to this problem 
by using the queries $\{(\Par_n, \func(\Par_n))\}_{n=1}^{\Ndesign}$ to 
fit a regression or interpolation model $\funcEm$, such that $\funcEm(\Par)$
provides a prediction of $\func(\Par)$ at new values of $\Par$.
Replacing the true target $\func$ with its emulator $\funcEm$ induces a 
surrogate posterior density $\postDens(\Par; \funcEm)$. In order to quantify
the uncertainty introduced via this approximation, we consider emulators 
that provide predictions in the form of a probability distribution; 
i.e., $\funcEm(\Par)$ is random and thus $\funcEm$ is a random function. 
Therefore, $\postDens(\Par; \funcEm)$
is a univariate random variable and $\postDens(\cdot; \funcEm)$ a random 
function. We write $\postEm$ to denote the former when the particular 
emulated quantity is not of consequence.

The manner in which the uncertainty in $\funcEm$ propagates to $\postEm$
depends on the target $\func$ as well as the form of the exact density 
$\postDens$. Below, we highlight two general choices of $\func$ common 
in the literature. This categorization has also 
been explored in \citet{StuartTeck1,StuartTeck2,GP_PDE_priors}. See
\citet{reviewPaper} for a discussion of practical considerations in choosing 
the emulator target. 

\subsubsection{Forward Model Emulation}
One natural approach is to target the underlying forward model 
$\Par \mapsto \fwd(\Par)$ (i.e., choosing $\func \Def \fwd$), a strategy 
we refer to as \textit{forward model emulation}.
This method consists of fitting a surrogate $\funcEm$ to the design 
$\{(\Par_n, \fwd(\Par_n))\}_{n=1}^{\Ndesign}$ and then using $\funcEm$
in place of $\fwd$. Much previous work has considered this strategy 
in the context of the additive noise model in \Cref{eq:additive-noise},
under the Gaussian assumption $\noise \sim \Gaussian(0, \likPar)$
\citep{StuartTeck1,GP_PDE_priors,hydrologicalModel,hydrologicalModel2,
Surer2023sequential,VillaniAdaptiveGP,weightedIVAR,idealizedGCM,CES}.
In this special case, the induced posterior density surrogate takes the form
\begin{align}
\postEm(\Par) &= \priorDens(\Par) \Gaussian(\obs \given \funcEm(\Par), \likPar). \label{eq:post-em-fwd-Gaussian}
\end{align}

\subsubsection{Log-Density Emulation}
Other lines of research have instead targeted the log-likelihood $\Par \mapsto \log p(\obs \given \Par)$
\citep{VehtariParallelGP,FATES_CES,trainDynamics,quantileApprox,
ActiveLearningMCMC,FerEmulation,StuartTeck1,random_fwd_models,
GP_PDE_priors,OakleyllikEm,JosephMinEnergy,AlawiehIterativeGP}
or the (unnormalized) log-posterior 
$\Par \mapsto \log \left\{\priorDens(\Par)p(\obs \given \Par)\right\}$
\citep{emPostDens,Kandasamy_2017,llikRBF,gp_surrogates_random_exploration,
landslideCalibration}.


We collectively refer to these strategies as \textit{log-density emulation}. In the 
log-likelihood case, an emulator $\funcEm$ is fit to a design 
$\{(\Par_n, \log p(\obs \given \Par_n))\}_{n=1}^{\Ndesign}$
and induces a posterior density surrogate 
\begin{align}
\postEm(\Par) &= \priorDens(\Par) \Exp{\funcEm(\Par)}. \label{eq:post-em-llik}
\end{align}
The log-posterior case is quite similar, except that the effect of the prior is also 
approximated by the emulator, so the induced posterior surrogate simply takes 
the form $\postEm(\Par) = \Exp{\funcEm(\Par)}$.

% Comparing Uncertainty Propagation Methods
\section{Comparing Uncertainty Propagation Methods}
The second stage in the modular surrogate workflow consists of using the 
trained emulator $\funcEm$ to approximate the posterior $\postDensNorm$.
To avoid overconfident posterior inference, the uncertainty in $\funcEm$
should be propagated within this posterior approximation. Given the lack of
a unifying probabilistic model across the two stages, proper uncertainty 
quantification is not automatically given by standard Bayesian conditioning.
Consequently, many different uncertainty propagation methods have been 
proposed [\todo: cite]. This problem shares a close resemblance with other 
instances of modular inference, including data imputation [\todo: cite],
cut distributions [\todo: cite], and dimension reduction via active subspaces [\todo: cite].

Irrespective of the underlying target quantity $\func$, the probabilistic emulator $\funcEm$ 
induces a random approximation of the posterior density
\begin{align}
\postNormEm(\Par) &\Def \frac{1}{\normCstEm} \postEm(\Par),
&&\normCstEm \Def \int_{\parSpace} \postEm(\Par) d\Par, \label{eq:random-post}
\end{align}
which is referred to as the ``sample'' approximation in \citet{StuartTeck1}. We can thus
view the challenge of uncertainty propagation as that of constructing a deterministic 
posterior approximation that summarizes the uncertainty encoded in $\postNormEm$.
Below we introduce two methods that have been proposed for this purpose, and then
analyze when the behavior of these methods deviate. 

\subsubsection{Expected Posterior}
A deterministic summary of $\postNormEm$ can be constructed via the expectation 
\begin{equation}
\postApproxEP(\Par) \Def \E_{\Ndesign}\left[\postNormEm(\Par) \right], \label{eq:ep-approx}
\end{equation}
with $\E_{\Ndesign}$ denoting the expectation with respect to the underlying emulator $\funcEm$.
We follow the terminology in \citet{BurknerSurrogate} and call $\postApproxEP$ the 
\textit{expected posterior (EP)}. The EP can be understood via the generative procedure
\begin{align}
&\postDensNorm^\prime \sim \mathrm{law}(\postNormEm) 
&&\Par^\prime \sim \postDensNorm^\prime, \label{eq:ep-direct-sample}
\end{align}
implying that $\postApproxEP$ represents the aggregation of samples from an ensemble of 
posterior approximations, each corresponding to a single trajectory of $\funcEm$.
Note that the quantity $\postNormEm(\Par)$ depends on the entire random function $\funcEm$ 
through its dependence on $\normCstEm$, as opposed to only depending on the prediction 
$\funcEm(\Par)$ at the single input $\Par$. Therefore, care must be taken in ensuring the 
expectation in \Cref{eq:ep-approx} is well-defined in the case that $\funcEm$ is an infinite-dimensional
random element (e.g., a GP). We assume throughout that $\funcEm$ is constructed such that 
trajectories of $\postNormEm$ are almost surely integrable, implying the sampling procedure
in \Cref{eq:ep-direct-sample} is well-defined. See 
\citet{StuartTeck1,StuartTeck2,random_fwd_models,garegnani2021NoisyMCMC} for additional
technical details. The EP corresponds to the cut posterior in modular Bayesian inference
\citep{PlummerCut}, and the sampling procedure in \Cref{eq:ep-direct-sample} is closely 
related to multiple imputation algorithms used to handle missing data [\todo: cite]. The 
potentially infinite-dimensional nature of $\funcEm$ presents additional practical difficulties
not typically present in these other settings, the consequences of which are 
discussed in \Cref{sec:computation}.

\subsubsection{Expected Likelihood}
Note that the random posterior $\postNormEm(\Par)$ depends on the entire 
emulator $\funcEm$ due to its dependence on $\normCstEm$, while the unnormalized 
density surrogate $\postEm(\Par)$ depends only on $\funcEm(\Par)$, the prediction at $\Par$.



Early work in surrogate-based Bayesian inference focused on jointly learning
the parameters of both the computer model and emulator within a unified Bayesian model 
(e.g., \citet{KOH}). In this case, surrogate uncertainty is automatically quantified via the 
Bayesian posterior. However, subsequent work highlighted common deficiencies of this
approach \citep{modularization}. In particular, allowing observational data to inform 
emulator parameters can produce counterintuitive posterior inferences when the computer
model is misspecified. This line of research inspired the two-step (i.e., modular)
surrogate workflow commonly used today \citep{modularization,BurknerTwoStep,BurknerSurrogate}.
This can also be seen as a particular inference of cut Bayesian inference \citep{PlummerCut}. 


\subsection{Comparison}
\subsubsection{Gaussian Log-Density Emulation Setting}
\subsubsection{Gaussian Forward Model Emulation Setting}

% Computation for the Posterior Approximations
\section{Computation for the Posterior Approximations} \label{sec:computation}
\subsection{Expected Likelihood}
\subsection{Expected Posterior}
\subsubsection{Direct Sampling}
Direct sampling, MCMC within Monte Carlo, Just-in-time sampling
\subsubsection{Metropolis-Hastings Algorithm}
\subsubsection{Noisy MCMC Algorithms}
Connection to BUGS naive cut algorithm



\section{Temporary}
\subsection{Expected Likelihood}
The expected likelihood approximation may also be motivated via the definition of a modified 
inverse problem with an extended parameter space. To this end, we introduce a random variable
$\gamma$ such that $\funcEm[\Ndesign](\Par) \overset{\mathrm{d}}{=} \gamma \given \Par$.
Consider the joint probability model 
\begin{align}
p(\Par, \obs, \gamma) \Def 
p(\obs \given \gamma) p(\gamma \given \Par) \priorDens(\Par). \label{eq:EL-prob-model}
\end{align}
For a forward model emulator $p(\obs \given \gamma)$ is the likelihood evaluated at
the forward model output $\gamma$. For a log-likelihood emulator, 
$p(\obs \given \gamma) = \Exp{\gamma}$. The expected likelihood approximation 
corresponds to the conditional marginal 
\begin{align}
p(\Par \given \obs) \propto \priorDens(\Par) \int p(\obs \given \gamma) p(\gamma \given \Par) d\gamma
\label{eq:EL-marginal}
\end{align}
This extended parameter space formulation is adopted in \citet{BilionisBayesSurrogates}, noted in
\citet{SinsbeckNowak}, and a special case is given as an example in \citet{StuartTeck2}.

When the integral in \Cref{eq:EL-marginal} can be computed analytically, then $p(\Par \given \obs)$ can 
be targeted by any standard MCMC sampler. If samples can be drawn from $p(\gamma \given \Par)$ then
it can still be targeted exactly via pseudo-marginal methods. A third option is to update the marginal conditionals
\begin{align}
p(\Par \given \gamma, \obs) &\propto p(\gamma \given \Par) \priorDens(\Par) \label{eq:EL-conditionals} \\
p(\gamma \given \Par, \obs) &\propto p(\obs \given \gamma) p(\gamma \given \Par)
\end{align}
in turn, which can be done via Metropolis-Hastings steps, slice sampling, or other means. This algorithm
requires the ability to evaluate the predictive density of the emulator.

\subsection{Expected Posterior}
The probability model in \Cref{eq:EL-prob-model} does not encode the dependence structure of the 
surrogate predictive distribution across different values of $\Par$; the conditionals $\gamma \given \Par$
only capture the pointwise predictions. In this section, we consider formulating a probability model that 
reflects the full distribution of the random function $\funcEm$. Formally, consider
\begin{align}
p(\Par, \obs, \funcEm) &\Def
p(\Par \given \obs, \funcEm) p(\funcEm) p(\obs) \\
&= \priorDens(\Par) p(\obs \given \funcEm(\Par))p(\funcEm) \frac{p(\obs)}{p(\obs \given \funcEm)}, \label{eq:EP-prob-model}
\end{align}
where $p(\Par \given \obs, \funcEm)$ is the posterior over $\Par$ obtained using a particular 
trajectory of the emulator, with associated normalizing constant $p(\obs \given \funcEm)$.
The quantity $p(\funcEm)$ is purely formal at the moment, as no Lebesgue 
density exists for the random element $\funcEm$. This could be given meaning in \Cref{eq:EP-prob-model}
by replacing $\funcEm$ with a random vector representing a discretization of $\funcEm$. The expected 
posterior corresponds to the conditional marginal
\begin{align}
p(\Par \given \obs) \propto \int p(\Par \given \obs, \funcEm) p(\funcEm) d\funcEm.
\label{eq:EP-marginal}
\end{align}
A sample can be directly drawn from this distribution by first sampling a trajectory $\func \sim \mathrm{law}(\funcEm)$
and then drawing a sample from $p(\Par \given \obs, \func)$. Assuming the first step can be completed, 
then the second step will still typically require an MCMC run. This approach is thus parallelizable, but 
may require many MCMC runs to adequately characterize the expected posterior. The larger problem is 
that the first step is often intractable without resorting to discretization of $\funcEm$. An alternative to direct
sampling is to target the joint posterior over $(\Par, \funcEm)$ within a single MCMC run. We might try to 
do this analogously to \Cref{eq:EL-conditionals} by updating the marginal conditionals 
\begin{align}
p(\Par \given \funcEm, \obs) \propto \priorDens(\Par) p(\obs \given \funcEm(\Par)) \label{eq:EP-conditionals} \\
p(\funcEm \given \Par, \obs) \propto p(\obs \given \funcEm(\Par)) \frac{p(\funcEm)}{p(\obs \given \funcEm)}
\end{align}
in turn, which is most simply done via Metropolis-Hastings updates.
The $\Par$ update should only require a standard Metropolis-Hastings step. We focus on the
$\func$ update.

 Assuming a proposal 
$\tilde{\func} \sim q_{\func}(\func, \cdot)$, the ratio appearing in the MH acceptance
probability for the $\funcEm$ update takes the form 
\begin{align}
\frac{p(\obs \given \tilde{\func}(\Par))}{p(\obs \given \func(\Par))} \frac{p(\tilde{\func})}{p(\func)} 
\frac{q_{\func}(\tilde{\func}, \func)}{q_{\func}(\func, \tilde{\func})} \frac{p(\obs \given \func)}{p(\obs \given \tilde{\func})}.
\end{align}
There are two issues to deal with here. The first is the proposal and the infinite dimensional nature of $\funcEm$.
However, if we choose $q_\func$ to be $\mathrm{law}(\funcEm)$-invariant then the ratio should simplify to
\begin{align}
\frac{p(\obs \given \tilde{\func}(\Par))}{p(\obs \given \func(\Par))} \frac{p(\obs \given \func)}{p(\obs \given \tilde{\func})}.
\label{eq:MH-ratio-prior-invariant}
\end{align}
The simplest option is to set $q_\func(\func, \cdot) \Def \mathrm{law}(\funcEm)$, which yields an MH independence
sampler update. If the emulator $\funcEm$ depends on a transformation of a latent Gaussian, then 
specialized alternatives such as the preconditioned Crank-Nicolson proposal, or an elliptical slice
sampling update, may be considered. We emphasize that the simplification in 
\Cref{eq:MH-ratio-prior-invariant} means that this ratio only depends on the emulator trajectories at the current 
value of $\Par$. Thus, there is no requirement to sample full trajectories. See \Cref{alg:mwg-ep}.

The second issue is the dependence on the intractable normalizing constants 
$p(\obs \given \func)$ and $p(\obs \given \tilde{\func})$. 
If the proposed value $\tilde{\func}$ is not too far from $\func$ then it may be reasonable to invoke the 
approximation $p(\obs \given \func) / p(\obs \given \tilde{\func}) \approx 1$.
\Cref{alg:mwg-ep} uses this approximation, along with the independence MH proposal.

\begin{algorithm}
    \caption{Metropolis-within-Gibbs Approximation to $\llikEmSampDensNorm$}
    \label{alg:mwg-ep}
    \begin{algorithmic}[1] 
    \State \textbf{Input:} Current state $(\Par, \func_\Par)$
    \State \textbf{Output:} Updated state $(\Par^\prime, \func^\prime_{\Par^\prime})$
     \State Propose $\tilde{\Par} \sim q(\Par, \cdot)$
     \State Propose $(\tilde{\func}_\Par, \tilde{\func}_{\propPar}) \sim \mathrm{law}(\funcEm(\Par), \funcEm(\propPar))$ \Comment{Begin $\func$ update}
     \State $\alpha_{\func} \gets \min\left\{1, p(\obs \given \tilde{\func}_\Par) / p(\obs \given \func_\Par) \right\}$
      	\If{$\mathrm{Unif}(0,1) < \alpha_{\func}$}
                \State $(\func^\prime_\Par, \func^\prime_{\propPar}) \gets (\tilde{\func}_\Par, \tilde{\func}_{\propPar})$ 
            \Else
                \State $\func^\prime_{\Par} \gets \func_{\Par}$
                \State $\func^\prime_{\propPar} \gets \mathrm{law}(\funcEm(\propPar) \given \funcEm(\Par) = \func_\Par)$
            \EndIf
      \State $\alpha_{\Par} \gets \min\left\{1, \priorDens(\propPar )p(\obs \given \func^\prime_{\propPar}) / \priorDens(\Par) p(\obs \given \func^\prime_{\Par}) \right\}$ \Comment{Begin $\Par$ update}
             \If{$\mathrm{Unif}(0,1) < \alpha_{\Par}$}
                \State $\Par^\prime \gets \propPar$
                \State $\func^\prime_{\Par^\prime} \gets \func^\prime_{\propPar}$ 
            \Else
            	\State $\Par^\prime \gets \Par$
		\State $\func^\prime_{\Par^\prime} \gets \func^\prime_{\Par}$
            \EndIf
    \end{algorithmic}
\end{algorithm}

A second option is to consider an $\func$ update based on algorithms designed 
for doubly intractable target distributions. 














\subsection{Noisy Algorithm}

A common solution to this computational bottleneck is to learn a statistical approximation of the map 
$\Par \mapsto \postDens(\Par)$, which we refer to synonymously as a \textit{surrogate} or \textit{emulator}
model. Learning the surrogate typically consists of an initial offline step where training data 
is generated by running the expensive simulator at a set of input parameter values. A regression model 
is then fit to this training set to learn an approximation of the input-output relationship 
$\Par \mapsto \postDens(\Par)$. Our interest is in \textit{probabilistic} surrogate models, which output
a prediction for $\postDens(\Par)$ in the form of a probability distribution, as opposed to just a point estimate.
We let $\postEm[\Ndesign](\Par)$ denote the random variable representing the surrogate prediction 
of $\postDens(\Par)$, with the subscript indicating the number of exact simulation runs that were used 
to train the surrogate. We refer to the distribution of $\postEm[\Ndesign](\Par)$ as the surrogate 
\textit{predictive distribution} at input $\Par$; we allow this distribution to be arbitrary, and potentially 
only accessible through samples. Note that the map $\Par \mapsto \postDens(\Par)$ is typically not 
approximated directly; rather, an emulator is fit to a quantity on which $\postDens(\Par)$ depends 
(e.g., the log-likelihood or an underlying mechanistic model), which then induces a random approximation 
of $\postDens(\Par)$. Our framework thus seeks to be agnostic to the particular quantity that is 
being emulated. Concrete examples of typical surrogate modeling workflows are given in \cref{sec:surrogate-examples}.

Given $\postEm[\Ndesign]$, a fixed random approximation of $\postDens$, a natural question is how to 
utilize this surrogate in approximating the posterior distribution in \cref{post_dens_generic}. \Cref{sec:post-approx}
is dedicated to this question, in which we summarize previous approaches and present our proposed method.




We focus on the Bayesian inference setting in which pointwise evaluations of the unnormalized posterior
density 
\begin{equation}
\postDens(\Par) \Def \priorDens(\Par) p(\obs \given \Par) \label{post_dens_generic}
\end{equation}
are available, but expensive owing to the cost of computing the likelihood $p(\obs \given \Par)$. This setting 
commonly arises in the Bayesian approach to inverse problems \citep{Stuart_BIP}. 
Consider a \textit{forward model} $\fwd: \parSpace \subseteq \R^{\dimPar} \to \R^{\dimObs}$ describing 
some system of interest, parameterized by input parameters $\Par \in \parSpace$. In addition, suppose that 
we have noisy observations $\obs \in \obsSpace \subseteq \R^{\dimObs}$ of the output signal that $\fwd(\Par)$ 
seeks to approximate. The \textit{inverse problem} concerns learning the parameter values $\Par$ such
 that $\fwd(\Par) \approx \obs$; i.e., \textit{calibrating} the model so that it agrees with the observations. 
 The statistical approach to this problem assumes that the link between model outputs and 
observations is governed by a probability distribution on $\obs \given \Par$. We assume that this distribution 
admits a density with corresponding log-likelihood 
\begin{align}
\llik: \parSpace \to \R, \label{log_likelihood}
\end{align}
such that $p(\obs \given \Par) = \Exp{\llik(\Par)}$. The notation $\llik(\Par)$ suppresses the dependence 
on $\obs$, as the observed data will be fixed throughout. We start by focusing inference only on the 
calibration parameter $\Par$, assuming that other likelihood parameters (e.g., noise covariance) 
are fixed. We discuss inference for such nuisance parameters in \Cref{section_lik_par}.

The Bayesian approach completes this specification with a prior distribution 
on $\Par$. Letting $\priorDens(\Par)$ denote the density of this distribution, the Bayesian solution of the inverse problem is given 
by the posterior distribution
\begin{align}
\postDensNorm(\Par) \Def p(\Par \given \obs) = \frac{1}{\normCst}\postDens(\Par) = \frac{1}{\normCst} \priorDens(\Par) \Exp{\llik(\Par)}, \label{post_dens}
\end{align}
with normalizing constant given by 
\begin{align}
\normCst &= \int \priorDens(\Par) \Exp{\llik(\Par)} d\Par. \label{norm_cst}
\end{align}
We emphasize that throughout this paper $\postDens(\Par)$ denotes the \textit{unnormalized} 
posterior density. We will also find it useful to introduce the notation
\begin{equation}
\lpost(\Par) \Def \log \postDens(\Par) = \log \priorDens(\Par) + \llik(\Par) \label{eq:lpost}
\end{equation}
for the logarithm of the unnormalized posterior density.
When relevant, we will make explicit the dependence on the forward 
model by writing $\llik(\Par; \fwd)$, $\lpost(\Par; \fwd)$, and $\postDens(\Par; \fwd)$. 

In addition to considering 
generic likelihoods, we will give special attention to the additive Gaussian noise model
\begin{align}
\obs &= \fwd(\Par) + \noise \label{inv_prob_Gaussian} \\
\noise &\sim \Gaussian(0, \likPar) \nonumber 
\end{align}
with corresponding log-likelihood 
\begin{align}
\llik(\Par; \fwd) &= \log\Gaussian(\obs| \fwd(\Par), \likPar) 
= -\frac{1}{2} \log\det (2\pi \likPar) - \frac{1}{2} (\obs - \fwd(\Par))^\top \likPar^{-1} (y - \fwd(\Par)), \label{llik_Gaussian}
\end{align}
as this model features prominently in the inverse problems literature.
In general, the nonlinearity of $\fwd$ precludes a closed-form characterization of the posterior. In this case, the 
standard approach is to instead draw samples from the distribution using a Markov chain Monte Carlo (MCMC) 
algorithm. Such algorithms are serial in nature, often requiring $\sim 10^5 - 10^7$ iterations, with each 
iteration involving an evaluation of the unnormalized posterior density $\postDens(\Par; \fwd)$. 
In the inverse problem context, this computational requirement is often prohibitive when the forward model 
evaluations $\fwd(\Par)$ incur significant computational cost, as each density evaluation requires the 
expensive computation $\fwd(\Par)$. Motivated by this problem, a large body of work has focused on deriving 
cheap approximations to either $\fwd(\Par)$ or $\lpost(\Par)$ (note that approximating the former induces 
an approximation of the latter). We focus on surrogate models that take the form of statistical 
regression models approximating the maps $\Par \mapsto \fwd(\Par)$ or $\Par \mapsto \lpost(\Par)$.
\footnote{This is in contrast to other surrogate modeling strategies (e.g., reduced-order modeling)
that exploit the specific structure of the forward model; see, e.g., \todo.}
We refer to methods that explicitly model the former map as \textit{forward model emulation}, and those that 
model the latter as \textit{log-density emulation}. We also include methods that emulate the log-likelihood
map $\Par \mapsto \llik(\Par)$ in this latter category (see \Cref{sec:llik_vs_lpost}).
Throughout this review, we will typically view the functions
$\fwd(\Par)$, $\llik(\Par)$, and $\lpost(\Par)$ as computationally expensive black-boxes. We will occasionally refer to 
such maps as \textit{simulators}, owing to the fact that in typical applications evaluating these maps requires
running an expensive computer code. The following section provides a concrete example of such a simulation
model stemming from the numerical solution of differential equations.


\bibliography{prob_surrogates_bayes} 
% \bibliographystyle{ieeetr}

\end{document}







