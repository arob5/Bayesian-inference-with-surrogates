\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode} % Note that this also loads algorithmicx
\usepackage{cleveref}
\usepackage{natbib}
\usepackage{bbm}
\usepackage{caption, subcaption} % Captions and sub-figures. 
\usepackage{fancyvrb} % For writing using verbatim font inline. 
% \usepackage[demo]{graphicx}

% For tables
\usepackage{array}
\usepackage{booktabs}

% Bibliography
\bibliographystyle{plainnat}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Tables. 
\usepackage{multirow}

% Local custom commands. 
\include{latex_macros_general}
\include{latex_macros_unc_prop}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{{./figures/}}

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{rmk}{Remark}

\newtheorem{ex}{Example}
\crefname{ex}{example}{examples}
\Crefname{ex}{Example}{Examples}
\Cref{ex:fwd-em, ex:ldens-em}


% Ensure cleverref knows how to handle citing of multiple subsubsections
\crefname{subsubsection}{section}{sections}
\Crefname{subsubsection}{Section}{Sections}
\crefname{ex}{example}{examples}
\Crefname{ex}{Example}{Examples}

% Title and author
\title{Uncertainty Propagation in Surrogate-Based Bayesian Inference}
\author{Andrew Roberts, Jonathan Huggins, Michael Dietze}

\begin{document}
\maketitle

\begin{abstract}
Standard Bayesian inference schemes are infeasible for inverse problems 
with computationally expensive forward models. A common solution is to 
replace the model with a cheaper surrogate. To avoid overconfident 
conclusions, it is essential to acknowledge the surrogate approximation by propagating 
its uncertainty. However, at present there is no standard method for uncertainty 
propagation in this context. To fill this gap, we propose a particular uncertainty-aware 
posterior approximation as the baseline, which is justified by Bayesian decision theoretic
arguments. [\todo: unfinished]
\end{abstract}

\section{Introduction}
Simulation-based computer models are key tools for studying complex systems within 
the physical, biological, and engineering sciences. Such models often have 
uncertain parameters that must be estimated (i.e., calibrated) using observational data.
Quantifying the uncertainty in these estimated values is crucial for downstream 
decision making. While Bayesian methods are particularly well-suited to this task, 
standard Bayesian inference algorithms such as Markov chain Monte Carlo (MCMC) 
are hindered by the computational cost of the simulation model. A popular solution 
is to use a small set of expensive simulations to train a statistical approximation 
of the simulator. This emulator (i.e., surrogate) is then used as a drop-in replacement 
for the true computer model, enabling the application of algorithms like MCMC. 
This modular surrogate-based Bayesian workflow has seen widespread use across
a variety of applications \citep{FerEmulation,FadikarAgentBased,idealizedGCM,
trainDynamics,FATES_CES,CLMBayesianCalibration}.

Despite significant advances in surrogate modeling, fitting a 
highly accurate emulator under a limited computational budget remains a challenging task.
Given this reality, it is inevitable that emulator errors will propagate to estimates
of the calibration parameters. Ignoring these errors can lead to overconfident results 
with miscalibrated uncertainties \citep{BilionisBayesSurrogates,BurknerSurrogate}.
It is thus crucial to acknowledge and propagate this additional source of uncertainty in 
surrogate-based Bayesian workflows. 
Probabilistic surrogates such as Gaussian processes (GPs; \citet{gpML,gramacy2020surrogates}) 
and probabilistic neural networks \citep{deepEnsembles,BayesOptNN} provide a notion of 
predictive uncertainty that be can utilized to this end.

While in principle surrogate and calibration parameters can be learned 
jointly (e.g., \citet{KOH}), in practice it is more common to conduct inference 
for these quantities in two distinct stages \citep{modularization,PlummerCut}.
Such decoupling has several practical benefits, but leaves open the 
question as to the ``correct'' approach for propagating surrogate uncertainty 
within the posterior approximation in the second stage.
A variety of uncertainty-aware posterior 
approximations have been proposed, but little guidance exists on choosing a particular 
method \citep{reviewPaper,BilionisBayesSurrogates,StuartTeck1,VehtariParallelGP,
BurknerSurrogate,BurknerTwoStep,FerEmulation}. Moreover, previous studies have 
explicitly cited computational challenges as a key factor in determining their 
approach \citep{VehtariParallelGP,StuartTeck2}. In this paper, we start by setting 
aside the computational considerations in order to specify a theoretically-justified 
baseline posterior approximation. While in general computation for this distribution 
is difficult, one can consider (1) targeting a simpler distribution approximating the baseline,
or (2) developing approximate inference algorithms that directly target the baseline.
We show that existing uncertainty propagation methods can be viewed as 
implementations of the former approach, and then introduce a new MCMC algorithm
falling under the latter approach that outperforms the alternatives. 
 
\subsection{Contributions.}
\begin{itemize}
\item We adopt a Bayesian decision theoretic viewpoint to formalize the question of 
choosing the correct uncertainty propagation method. We show that, with respect 
to common loss functions, the Bayes' estimator is given by a mixture distribution 
termed the \textit{expected posterior (EP)}.
\item We analyze an existing alternative, the \textit{expected unnormalized posterior (EUP)},
as an approximation to the EP. We clarify when this approximation is reasonable and 
when it can deviate significantly from the EP baseline.
\item We provide additional insights tailored to two popular modeling setups: 
(i.) emulating the log-likelihood or log-posterior with a GP, and (ii.) emulating an 
underlying forward model with a GP under an additive Gaussian error structure. 
We show that the EUP is generally a robust approximation to the EP in 
the latter case, but can suffer pathological behavior in the former.
\item We introduce an approximate MCMC algorithm that directly 
targets the EP, and numerically demonstrate favorable performance compared 
to the EUP approximation. In the case that the surrogate is a function of a 
GP, we highlight connections with correlated pseudo-marginal and 
preconditioned Crank-Nicholson algorithms. 
\end{itemize}

\subsection{Outline.}
\Cref{sec:surrogates-intro} introduces the surrogate-based Bayesian workflow.
In \Cref{sec:EP} we derive the EP as a Bayes' estimator, and discuss connections 
with the so-called cut posterior distribution. In \Cref{sec:approximating-ep}
we analyze the EUP as an EP approximation and highlight practical 
takeaways for common applications in which GPs are used to emulate 
forward models or log-densities.
\Cref{sec:computation} presents an approximate MCMC scheme directly 
targeting the EP, and describes connections with alternative inference algorithms. 
\Cref{sec:experiments} contains numerical experiments, and 
\Cref{sec:conclusion} concludes. Proofs are given in the appendix.

% Surrogates for Bayesian Inverse Problems
\section{Surrogates for Bayesian Inference} \label{sec:surrogates-intro}
We begin by introducing the Bayesian inference setting, including the challenges
associated with Bayesian inverse problems involving expensive forward models. 
We then describe the common two-stage surrogate modeling pipeline, and highlight 
several different strategies for integrating surrogates within a Bayesian analysis.

\subsection{Bayesian Inference Setting}
We consider the general goal of estimating parameters $\Par \in \parSpace \subseteq \R^{\dimPar}$ given 
observations $\obs \in \obsSpace \subseteq \R^{\dimObs}$ within a Bayesian framework.
A Bayesian model consists of a joint probability distribution $p(\Par, \obs)$, defined by 
specifying a prior density $\priorDens(\Par)$ and likelihood function $\lik(\Par; \obs)$.
The goal is then to summarize the posterior distribution 
\begin{align}
&\postDensNorm(\Par) \Def p(\Par \given \obs) = \frac{1}{\normCst} \priorDens(\Par) \lik(\Par; \obs), 
&&\normCst = \int_{\parSpace} \priorDens(\Par) \lik(\Par; \obs) d\Par. \label{eq:post_dens_generic}
\end{align}
While closed-form characterizations are typically thwarted by the intractable normalizing constant
$\normCst$, posterior samples can be simulated using MCMC algorithms, which only require 
access to pointwise evaluations of the unnormalized density 
$\postDens(\Par) \Def \priorDens(\Par) \lik(\Par; \obs)$.
However, such methods commonly require $10^5 - 10^7$ iterations, with each iteration 
involving a query to the density $\postDens(\Par)$.
In various engineering and scientific applications, computing $\lik(\Par; \obs)$ (and thus
$\postDens(\Par)$) requires running an expensive computer simulation. 
This renders MCMC infeasible in this setting, motivating the need for inference schemes
that use only a small set of evaluations of $\postDens(\Par)$.
 
\subsection{Bayesian Inverse Problems} \label{sec:bip}
The challenge posed by computationally expensive density evaluations $\postDens(\Par)$ commonly 
arises in the Bayesian approach to inverse problems \citep{Stuart_BIP}. In this setting, 
the likelihood often takes the form $\obs = \fwd(\Par) + \noise$ for some forward model
$\fwd: \parSpace \to \obsSpace$. For a concrete example, we consider the problem of estimating the 
parameters in a system of ordinary differential equations (ODEs)
\begin{align}
\frac{d}{d\Time} \state(\Time, \Par) &= \odeRHS(\state(\Time, \Par), \Par), &&x(\timeStart) = \stateIC, \label{ode_ivp}
\end{align}
where the dynamics depend on parameters $\Par$. Each value for $\Par$ implies a different solution trajectory
$[\state(\Time, \Par)]_{\timeStart \leq \Time \leq \timeEnd}$, which we encode by the
map $\solutionOp: \Par \mapsto [\state(\Time, \Par)]_{\timeStart \leq \Time \leq \timeEnd.}$. The goal is then 
to identify the parameters that yield trajectories in agreement with observed data 
$\obs$, which is assumed to be some noise-corrupted function $\obsOp$ of the true trajectory. Thus, the 
likelihood is of the form 
\begin{align}
&\obs = \fwd(\Par) + \noise, &&\fwd \Def \obsOp \circ \solutionOp. \label{eq:additive-noise}
\end{align}
In practice, the ODE is solved numerically so $\solutionOp$ represents the map induced by a numerical 
solver. Therefore, in this setting the computational cost of computing $\postDens(\Par)$ stems from the 
dependence of the likelihood on $\fwd(\Par)$, and in particular on the solver $\solutionOp(\Par)$.

\subsection{Surrogate Targets for Bayesian Inference} \label{sec:surrogates-Bayes}
Given the cost of computing $\postDens(\Par)$, we seek to approximate
the posterior using a small set of queries to the posterior density. 
Surrogates address this problem by approximating some underlying 
\textit{target map} $\Par \mapsto \target(\Par) \in \targetRange$, which in turn 
induces a cheap approximation of $\postDens(\Par)$.
Different target maps may be emulated in order to
accelerate Bayesian inference, so long as $\target(\Par)$ is sufficient 
to compute $\postDens(\Par)$ without requiring additional simulator runs.
Two common examples are detailed in \Cref{ex:fwd-em, ex:ldens-em}.
We write $\postDens(\Par; \target)$ and $\normCst(\target)$ to indicate the 
dependence of the posterior density and normalizing constant on $\target$, 
with the assumption that $\postDens(\Par; \target)$ is relatively 
quick to compute once the expensive computation $\target(\Par)$ is
obtained. In addition, we slightly abuse notation by using $\lik(\target(\Par); \obs)$ 
to denote the likelihood parameterized as a function of the target quantity. 

In many applications, computational constraints impose a budget of 
$\Ndesign$ evaluations of $\target$, where 
$\Ndesign$ is typically much smaller than that required by standard posterior
inference algorithms. The queries $\{(\Par_n, \target(\Par_n))\}_{n=1}^{\Ndesign}$
are then leveraged to fit a regression model $\targetEm$,
such that $\targetEm(\Par)$ provides a prediction of $\target(\Par)$.
In order to quantify the uncertainty introduced via this approximation, we consider 
emulators that provide predictions in the form of a probability distribution; 
i.e., $\targetEm(\Par)$ is random and thus $\targetEm$ is a random function. 
Let $\emDist(\cdot \given \Par)$ and $\emDist$ denote their respective distributions,
and $\emE$ the expectation with respect to $\emDist$.
Using $\targetEm$ as a drop-in replacement for 
$\target$ implies that $\postDens(\Par; \targetEm)$ and $\normCst(\targetEm)$
are univariate random variables, while $\postDens(\cdot; \targetEm)$ 
is a random function.

The manner in which the uncertainty in $\targetEm$ propagates to 
$\postDens(\cdot; \targetEm)$ depends on the target $\target$,
the predictive distribution $\emDist$, and the particular form of the 
density $\postDens$. Below, we highlight two general choices 
of $\target$ common in the literature. This categorization has also 
been explored in \citet{StuartTeck1,StuartTeck2,GP_PDE_priors}. See
\citet{reviewPaper} for a discussion of practical considerations in choosing 
the emulator target. 

\begin{ex} \label{ex:fwd-em}
In the Bayesian inverse problem setting in \Cref{sec:bip},
a natural approach is to target the underlying forward model 
$\Par \mapsto \fwd(\Par)$ (i.e., choose $\target \Def \fwd$), a strategy 
we refer to as \textit{forward model emulation}.
This method consists of fitting a surrogate $\targetEm$ to the design 
$\{(\Par_n, \fwd(\Par_n))\}_{n=1}^{\Ndesign}$ and then using $\targetEm$
in place of $\fwd$. Much previous work has considered this strategy 
in the context of the additive noise model in \Cref{eq:additive-noise},
under the Gaussian assumption $\noise \sim \Gaussian(0, \likPar)$
\citep{StuartTeck1,GP_PDE_priors,hydrologicalModel,hydrologicalModel2,
Surer2023sequential,VillaniAdaptiveGP,weightedIVAR,idealizedGCM,CES}.
In this special case, the induced (unnormalized) posterior density surrogate takes the form
\begin{align}
\postEm(\Par) &= \priorDens(\Par) \Gaussian(\obs \given \targetEm(\Par), \likPar). \label{eq:post-em-fwd-Gaussian}
\end{align}
\end{ex}

\begin{ex} \label{ex:ldens-em}
Other lines of research have instead targeted the log-likelihood $\Par \mapsto \log \lik(\target(\Par); \obs)$
\citep{VehtariParallelGP,FATES_CES,trainDynamics,quantileApprox,
ActiveLearningMCMC,FerEmulation,StuartTeck1,random_fwd_models,
GP_PDE_priors,OakleyllikEm,JosephMinEnergy,AlawiehIterativeGP}
or the (unnormalized) log-posterior 
$\Par \mapsto \log \left\{\priorDens(\Par)\lik(\target(\Par); \obs)\right\}$
\citep{emPostDens,Kandasamy_2017,llikRBF,gp_surrogates_random_exploration,
landslideCalibration}.

We collectively refer to these strategies as \textit{log-density emulation}. In the 
log-likelihood case, an emulator $\targetEm$ is fit to a design 
$\{(\Par_n, \log \lik(\target(\Par_n); \obs)\}_{n=1}^{\Ndesign}$
and induces a posterior density surrogate 
\begin{align}
\postEm(\Par) &= \priorDens(\Par) \Exp{\targetEm(\Par)}. \label{eq:post-em-llik}
\end{align}
The log-posterior case is quite similar, except that the effect of the prior is also 
approximated by the emulator, so the induced posterior surrogate simply takes 
the form $\postEm(\Par) = \Exp{\targetEm(\Par)}$.
\end{ex}

% The Expected Posterior
\section{The Expected Posterior} \label{sec:EP}
The second stage in the modular surrogate workflow consists of using the 
trained emulator $\targetEm$ to approximate the posterior $\postDensNorm$.
A simple approximation may be constructed by plugging in the surrogate mean
\begin{equation}
\postApproxNormMean(\Par) \Def \postDens(\Par; \emE[\targetEm]) / \normCst(\emE[\targetEm]),
\label{eq:mean-approx}
\end{equation}
but this ignores the emulator uncertainty, resulting in overconfident 
posterior inference. This poses the question of defining a posterior approximation 
that correctly propagates the uncertainty in $\targetEm$.
Given the lack of a unifying probabilistic model across the two inference stages, 
proper uncertainty quantification is not automatically given by standard Bayesian 
conditioning. Consequently, various uncertainty propagation methods have been 
proposed, each resulting in different posterior inferences 
\citep{BilionisBayesSurrogates,StuartTeck1,VehtariParallelGP,BurknerSurrogate,
FerEmulation}.
We identify and justify a mixture distribution termed the 
\textit{expected posterior (EP)} as the correct distribution to target in 
modular surrogate-based inference. 

\subsection{Decision Theoretic Derivation} \label{sec:decision-theoretic}
Irrespective of the underlying target $\target$, the probabilistic emulator $\targetEm$ 
induces a random approximation of the posterior defined by plugging $\targetEm$
in place of $\target$; this yields
\begin{align}
\postDensNorm(\Par; \targetEm) 
&= \frac{\postDens(\Par; \targetEm)}{\normCst(\targetEm)},
&&\normCst(\targetEm) \Def \int_{\parSpace} \postDens(\Par; \targetEm) \d\Par, \label{eq:random-post}
\end{align}
which is referred to as the ``sample approximation'' in \citet{StuartTeck1}. We use the succinct
shorthand $\postEm(\cdot) \Def \postDens(\cdot; \targetEm)$, 
$\postNormEm(\cdot) \Def \postDensNorm(\cdot; \targetEm)$, and 
$\normCstEm \Def \normCst(\targetEm)$ when explicit reference to the underlying 
emulator is not necessary.

We view the challenge of uncertainty propagation as that of constructing a deterministic 
probability distribution that summarizes the uncertainty encoded in $\postNormEm$.
To identify such a distribution, we adopt a Bayesian decision theoretic viewpoint and consider
the Bayes' estimator
\begin{equation}
\qDensOpt \in \argmin_{\qDens \in \qSpace} \emE[\loss(\postNormEm, q)],
\label{eq:variational-opt}
\end{equation}
for a loss function $\loss$ and space of densities $\qSpace$ over $\parSpace$. The following 
result provides the unique minimizer $\qDensOpt$ with respect to two common losses.

\begin{prop} \label{prop:EP-variational}
If the loss $\loss(\postNormEm, q)$ is chosen as the forward Kullback-Leibler (KL) divergence 
$\KL{\postNormEm}{q}$ or squared $L_2$ error $\norm{\postNormEm - q}_{L_2(\parSpace)}^2$
then the optimization problem in \Cref{eq:variational-opt} is solved uniquely by 
\begin{equation}
\qDensOpt(\Par) = 
\emE \left[\postNormEm(\Par) \right]
= \int \postDensNorm(\Par; \targetTraj) \emDist(d\targetTraj).
\label{eq:ep-approx}
\end{equation}
\end{prop}

We thus take $\qDensOpt$ as the baseline for surrogate-based uncertainty propagation. 
This distribution has been considered previously in various 
contexts, but is not widely used in the surrogate modeling literature
\citep{trainDynamics,BurknerSurrogate,garegnani2021NoisyMCMC}.
This is likely due in part to computational difficulties, which we address in \Cref{sec:computation}.
Following \citet{BurknerSurrogate}, we refer to $\qDensOpt$ as the \textit{expected posterior (EP)},
denoted by $\postApproxEP \Def \qDensOpt$.

\subsection{Hierarchical Formulation}
The EP arises as the marginal of the 
joint distribution $\emDist(d\targetTraj) \postDensNorm(\Par; \targetTraj) d\Par$, which 
can be understood via the hierarchical model 
\begin{align}
&\targetTraj  \sim \emDist, 
&&\Par \given \targetTraj \sim \postDensNorm(\cdot; \targetTraj).
\label{eq:ep-prob-model}
\end{align}
This perspective highlights the interpretation of the EP as a mixture of posteriors,
with each ensemble member $\postDensNorm(\Par; \targetTraj)$ induced by 
a particular emulator realization $\targetTraj$ that is weighted according to $\emDist$.
We assume throughout that $\targetEm$ is constructed such that 
trajectories of $\postNormEm$ are almost surely integrable, implying the sampling procedure
in \Cref{eq:ep-prob-model} is well-defined. See 
\citet{StuartTeck1,StuartTeck2,random_fwd_models,garegnani2021NoisyMCMC} for additional
technical conditions ensuring existence.

In the case that $\targetEm$ is a forward model emulator (\Cref{ex:fwd-em}), the EP 
represents the marginal posterior $\Par \given \obs$ under the hierarchical model 
\begin{align*}
&\targetTraj  \sim \emDist \\
&\Par \sim \priorDens \\
&\obs \given \targetTraj, \Par \sim \lik(\targetTraj(\Par); \obs).
\label{eq:ep-prob-model-fwd}
\end{align*}

\subsection{Cut Posterior} \label{sec:cut}
Our above formulation is agnostic to how the emulator is constructed. The 
randomness in $\targetEm$ may be derived from Bayesian methods 
(e.g., GPs, BART, Bayesian neural networks) or non-Bayesian alternatives
(e.g., deep ensembles, epistemic neural networks). In this section, we show 
that in the former case the EP can be viewed as a cut posterior distribution,
as defined in the modular Bayes literature 
\citep{PlummerCut,cutInference,moduleModels,cutVar,cutVar2}.

In particular, suppose that the surrogate model is defined by specifying 
a prior $\targetTraj \sim \emDistPrior$ and likelihood $\lik(\targetTraj; \emObs)$,
where $\emObs \Def \{(\Par_n, \target(\Par_n))\}_{n=1}^{\Ndesign}$ denotes
the emulator training data. The common example of a conjugate GP model 
corresponds to $\emDistPrior = \GP(\gpMean[0], \gpKer[0])$ and 
$\lik(\targetTraj; \emObs) = \Gaussian(\target(\Par_{1:\Ndesign}) \given \targetTraj(\Par_{1:\Ndesign}), \tau^2 I)$.
This setup encompasses standard parametric Bayesian models as well.
We can thus consider the joint Bayesian model 
\begin{equation}
\jointKOH(\d\Par, \d\targetTraj, \d\obs, \d\emObs) \Def
\priorDens(\Par) \lik(\targetTraj(\Par); \obs) \lik(\targetTraj; \emObs) 
\emDistPrior(\d\targetTraj) \, \d\Par \, \d\obs \, \d\emObs
\label{eq:koh-joint}
\end{equation}
over all unknowns $(\targetTraj, \Par)$. This fully Bayesian (non-modular) model 
is akin to the framework proposed in the seminal work of \citet{KOH}. Subsequent 
studies showed that allowing the observational data $\obs$ to indirectly inform 
the emulator can produce counterintuitive results, contributing to adoption of 
the modular framework \citep{modularization}. The following result shows that 
the EP can be viewed as an optimal approximation to the fully Bayesian model, 
subject to the constraint that $\obs$ is not allowed to inform $\targetTraj$.

\begin{prop} \label{prop:kl-cut-op}
Let $\postKOH$ denote the distribution of $(\Par, \targetTraj)$
given $(\obs, \emObs)$ under the joint $\jointKOH$. Also, let $\emDist$ denote 
the distribution of $\targetTraj$ given $\emObs$ under the joint 
$\emDistPrior(\d\targetTraj) \lik(\targetTraj; \emObs) \d\emObs$. Then, 
\begin{equation}
\emDist(\d\targetTraj) \postDensNorm(\Par; \targetTraj)\d\Par
= \argmin_{\qMeas \in \qSpaceCut}} \KL{\qMeas}{\postKOH},
\label{eq:kl-cut-opt}
\end{equation}
where 
\begin{equation}
\qSpaceCut \Def 
\left\{\qMeas(\d\Par, \d\targetTraj) : \int \qMeas(\d\Par, \cdot) = \emDist(\cdot) \right\}.
\end{equation}
\end{prop} 
The optimum in \Cref{eq:kl-cut-opt} is precisely the joint distribution noted in the previous 
section, and also corresponds to the cut posterior with respect to the fully Bayesian model.
This gives a second variational justification for the EP, complementing the result in 
\Cref{prop:EP-variational}.

\paragraph{Related work.} In the surrogate modeling literature the EP has been considered 
in \citet{trainDynamics,BurknerSurrogate,garegnani2021NoisyMCMC}. In 
\citet{StuartTeck2,VehtariParallelGP}, the EP is briefly noted but deemed computationally impractical. 
This difference of opinion can be explained by the fact that these latter two papers are focused 
on GP surrogates, which present additional challenges stemming from the inability to exactly 
sample surrogate trajectories $\targetTraj \sim \emDist$. On the other hand, 
\citet{BurknerSurrogate,garegnani2021NoisyMCMC} appear to implicitly assume the use of 
finite-dimensional surrogate models for which sampling trajectories is straightforward.
See \Cref{sec:computation} for additional computational details.

In the Bayesian modularization literature, there is a wide body of work 
on the cut posterior, which is equivalent to the EP 
when a fully Bayesian reference model is considered (\Cref{sec:cut})
\citep{PlummerCut,cutInference,moduleModels}.
Various papers have justified the cut posterior as a reverse KL divergence minimizer, 
akin to \Cref{prop:kl-cut-op} \citep{cutVar,cutVar2,moduleModels}. 

The hierarchical sampling view of the EP in \Cref{eq:ep-prob-model} also 
corresponds to a Bayesian multiple imputation algorithm, typically applied
in missing data problems \citep{multipleImputationMedical,missingData}.
The notion of aggregating multiple posterior distributions is also used in 
contexts other than modular inference, including for robustness to model 
misspecification \citep{BayesBag,BayesBag2}.

\section{Approximating the Expected Posterior} \label{sec:approximating-ep}
Having justified the EP as the baseline target distribution for uncertainty 
propagation, we now turn to the practical question of conducting EP-based
inference. While exact inference is typically infeasible, two 
natural strategies are to
(1) target a distribution that approximates the EP but is more amenable
to standard inference algorithms, and (2) employ an approximate 
inference algorithm (see \Cref{sec:computation} for the latter). We re-interpret 
alternative posterior approximations proposed in the literature 
as instances of the former approach. Previous work commonly
eschews the EP in favor of approximations of the \textit{unnormalized}
density surrogate $\postEm$ \citep{StuartTeck1,StuartTeck2,VehtariParallelGP}.
However, these works stop short of studying how such alternative approximations 
relate to the EP. 

In this section, we introduce the most popular of these approximations, the 
\textit{expected unnormalized posterior (EUP)}, and demonstrate 
how the EUP can be viewed as an approximation to the EP.
We analyze when this approximation is reasonable, and when the EUP may 
deviate significantly from the EP baseline. We then show how these results map 
onto the popular GP settings from \Cref{ex:fwd-em, ex:ldens-em}.

\subsection{The Expected Unnormalized Posterior} \label{sec:eup}
Notice that, unlike $\postNormEm(\Par)$, the unnormalized density surrogate
$\postEm(\Par)$ depends only on the single-point prediction $\targetEm(\Par)$
rather than the full emulator $\targetEm$. The EUP is defined by computing
a pointwise expectation of $\targetEm(\Par)$ and then normalizing post-hoc:
\begin{equation}
\postApproxMarg(\Par) \Def 
\frac{\emE \left[\postEm(\Par) \right]}{\int_{\parSpace} \emE\left[\postEm(\Par) \right] d\Par}
= \frac{\emE\left[\postEm(\Par) \right]}{\emE[\normCstEm]}. \label{eq:post-approx-EL} 
\end{equation}
The equality in \Cref{eq:post-approx-EL} follows from
changing the order of integration, courtesy of Tonelli's theorem \citep{StuartTeck1}. The EUP
is a marginal of the joint distribution 
$\emDist(d\targetTraj) \postDens(\Par; \targetTraj) / \emE[\normCst(\targetEm)] d\Par$. 
As compared to the analogous EP joint
$\emDist(d\targetTraj) \postDens(\Par; \targetTraj) / \normCst(\targetTraj) d\Par$,
we see that the EUP replaces the normalizing function $\normCst(\targetTraj)$ with
the global point estimate $\emE[\normCst(\targetEm)] $.

When $\targetEm$ is a forward model emulator, this implies that the EUP is the 
marginal posterior $\Par \given \obs$ under the hierarchical model 
\begin{align}
\Par &\sim \priorDens \label{eq:el-prob-model} \\
\gamma \given \Par &\sim \emDist(\cdot \given \Par) \nonumber \\
\obs \given \gamma &\sim \lik(\gamma; \cdot), \nonumber
\end{align}
which can be interpreted as an inverse problem on an extended parameter space.

\subsection{Comparison of the EP and EUP}
Notice in \Cref{eq:post-approx-EL} that the EUP is a ratio estimator, and differs from 
the EP due to the nonlinearity of the normalization operation. The EUP can thus 
be derived from the EP by invoking two approximations: 
(i.) treating $\postEm(\Par)$ and $\normCstEm^{-1}$ as independent; and 
(ii.) assuming $\emE[\normCstEm^{-1}] \approx \emE[\normCstEm]^{-1}$.
The below result quantifies the effect of these two approximations.

\begin{prop} \label{prop:ep-eup-pw-err}
The pointwise difference between the EP and EUP is given by
\begin{equation}
\postApproxEP(\Par) - \postApproxNormMarg(\Par)
= \emE[\postEm(\Par)] \jgap + \Cov[\postEm(\Par), \normCstEm^{-1}],
\label{eq:ep-eup-pw-err}
\end{equation}
where $\jgap \Def \emE[\normCstEm^{-1}] - \emE[\normCstEm]^{-1}$
is the ``Jensen gap.''
\end{prop}

By Jensen's inequality $\jgap \geq 0$, implying that the Jensen gap represents a 
$\Par$-independent positive bias in the difference between EP and EUP, modulated by the magnitude of 
$\emE[\postEm(\Par)]$. Since both distributions integrate to one, any positive 
biases must be balanced by negative biases at other values of $\Par$.
The second term in \Cref{eq:ep-eup-pw-err} will be negative for ``influential'' $\Par$ values, 
meaning that larger realizations of $\postEm(\Par)$ correspond to larger values of 
$\normCstEm$. The influence of a parameter value will typically increase when 
$\postEm(\Par)$ is large on average, highly variable, and is positively correlated other 
$\postEm(\Par^\prime)$. The latter property may be satisfied, for example, when using 
a GP emulator with a long lengthscale. Based on this logic, we expect the EUP to inflate 
influential regions and depress non-influential regions, relative to the EP. This can lead 
the EUP to be more peaked, while the EP is more smooth. The pointwise error in 
\Cref{prop:ep-eup-pw-err} can be integrated to obtain the following $L_1$ bound 
between $\postApproxEP$ and $\postApproxMarg$. Multiplying both sides by $1/2$
yields a total variation bound.

\begin{prop} \label{prop:ep-eup-TV-err}
Let $\jgap$ be defined as in \Cref{prop:ep-eup-pw-err}. Then,
\begin{equation}
\norm{\postApproxEP - \postApproxMarg}_{L_1(\parSpace)}
\leq \emE[\normCstEm] \jgap + \int \Cov[\postEm(\Par), \normCstEm^{-1}] d\Par
\label{eq:ep-eup-TV-err}
\end{equation}
\end{prop}

Decreasing the variance of $\normCstEm$ will shrink both terms in 
\Cref{eq:ep-eup-TV-err}. This may occur when there is little 
uncertainty in $\targetEm$, the unnormalized posterior $\postDens(\cdot; \targetTraj)$
is insensitive to $\targetTraj$, or $\normCstEm$ is insensitive to the variability 
in $\postEm$. In the first case, note that if $\targetEm$ is heavily 
concentrated around its mean, then both the EP and EUP will bear a close resemblance
to the plug-in mean approximation in \Cref{eq:mean-approx}.
In special cases, the two terms in \Cref{eq:ep-eup-TV-err} perfectly balance so that 
the EP and EUP agree. For example, this occurs when 
$\postEm(\Par) = \omega g(\Par)$, where $\omega$ is a random constant and 
$g(\Par)$ a deterministic function. 

\subsubsection{Gaussian Log-Density Emulation Setting} \label{sec:ldens-Gaussian}
We now consider the particular example from \Cref{ex:ldens-em},
where $\postEm(\Par) = \Exp{\targetEm(\Par)}$
and $\targetEm \sim \GP(\gpMean, \gpKer)$ is a GP emulator; that is, 
$\E[\targetEm(\Par)] = \gpMean(\Par)$ and 
$\Cov[\targetEm(\Par),\targetEm(\Par^\prime)] = \gpKer(\Par, \Par^\prime)$ for all 
$\Par, \Par^\prime \in \parSpace$. We also make use of the shorthand 
$\gpKer(\Par) \Def \gpKer(\Par, \Par)$. This setup encompasses both the log-likelihood
and log-posterior emulation settings via suitable definitions of $\gpMean$ and $\gpKer$.
GP log-density emulators have been used in various studies 
\citep{VehtariParallelGP,FATES_CES,trainDynamics,quantileApprox,ActiveLearningMCMC,FerEmulation,
StuartTeck1,random_fwd_models,GP_PDE_priors,OakleyllikEm,JosephMinEnergy,AlawiehIterativeGP}.

In this setting, the pointwise distribution of the induced posterior surrogate is log-normal
$\postEm(\Par) \sim \LN(\gpMean(\Par), \gpKer(\Par))$, implying that
\begin{equation}
\postApproxNormMarg(\Par) 
\propto \Exp{\gpMean(\Par) + \frac{1}{2}\gpKer(\Par)}
= \postApproxMean(\Par) \Exp{\frac{1}{2}\gpKer(\Par)}.
\label{eq:EUP-Gaussian-ldens}
\end{equation} 
The expression in \Cref{eq:EUP-Gaussian-ldens} shows that the EUP inflates the plug-in mean 
density in uncertain regions \citep{StuartTeck2,GP_PDE_priors}. In particular, 
 \begin{equation}
 \frac{\postApproxNormMarg(\Par^\prime)/\postApproxNormMarg(\Par)}{\postApproxNormMean(\Par^\prime)/\postApproxNormMean(\Par)}
 = \Exp{\frac{1}{2}\left[\gpKer(\Par^\prime) - \gpKer(\Par) \right]},
 \label{eq:unc-infl-factor}
 \end{equation}
showing that the degree of inflation scales with the emulator variance; that is, if 
$\postApproxNormMean(\Par)=\postApproxNormMean(\Par^\prime)$, then the EUP will give 
always give higher weight to the location with higher emulator uncertainty.

Unfortunately, the exponential scaling in \Cref{eq:EUP-Gaussian-ldens} can result in
undesirable degrees of uncertainty inflation. For example, suppose that 
the standard deviation of $\targetEm(\Par^\prime)$ is twice that of $\targetEm(\Par)$, so that 
the expression in \Cref{eq:unc-infl-factor} reduces to $\Exp{\frac{3}{2}\gpKer(\Par)}$.
If $\gpKer(\Par) = 4$, this means
$\Exp{\frac{3}{2}\gpKer(\Par)} \approx 400$, vastly magnifying the modest difference 
in emulator uncertainty. Practically, this can result in $\postApproxNormMarg$ concentrating 
on small subsets of $\parSpace$ where emulator uncertainty is the largest.
With respect to \Cref{eq:ep-eup-pw-err}, this manifests as a large negative covariance 
between $\postEm(\Par)$ and $\normCstEm$ in uncertain regions, implying 
$\postApproxNormMarg(\Par) \gg \postApproxEP(\Par)$. 

Given this extreme sensitivity to emulator uncertainty, we recommend against the use of the EUP
approximation in this setting. \citet{VehtariParallelGP} reach a similar conclusion, and propose
the use of an alternative approximation defined via a pointwise quantile of $\postEm(\Par)$.
This quantile approximation is also considered in \citet{quantileApprox,FATES_CES}.
While this approximation is more robust, we highlight that the true underlying issue is often 
a poorly calibrated emulator. For example, many common likelihoods (e.g., Gaussian) 
have known upper bounds, which are ignored by the GP emulator $\targetEm$. The simple 
adjustment of enforcing this bound constraint within $\targetEm$ can mitigate the aforementioned issues.
\citet{quantileApprox} employs such a bound-constrained GP log-density emulator.

\subsubsection{Gaussian Forward Model Emulation Setting} \label{sec:fwd-Gaussian} 
We next return to the setting in \Cref{ex:fwd-em}, where
\begin{align}
&\obs = \fwd(\Par) + \noise, &&\noise \sim \Gaussian(0, \likPar)
\end{align}
with prior $\Par \sim \priorDens$ independent of $\noise$. We consider the case 
where $\fwd$ is replaced with a (potentially multi-output) GP emulator 
$\targetEm \sim \GP(\gpMean, \gpKer)$. This setup has been considered frequently in various 
applications \citep{Surer2023sequential,weightedIVAR,StuartTeck2,GP_PDE_priors,CES,
idealizedGCM,villani2024posteriorsamplingadaptivegaussian,hydrologicalModel,hydrologicalModel2}.

The unnormalized posterior surrogate takes the form 
$\postEm(\Par) = \priorDens(\Par)\Gaussian(\obs \mid \targetEm(\Par), \likPar)$, implying
\begin{equation}
\postApproxNormMarg(\Par) \propto \priorDens(\Par) \Gaussian(\obs \mid \gpMean(\Par), \likPar + \gpKer(\Par)),
\label{eq:EUP-Gaussian-fwd}
\end{equation}
following from the formula for the convolution of two Gaussians [\todo: add to appendix].
A key observation in this setting is that $\postEm(\Par) \in [0, B_{\likPar}]$, where 
$B_{\likPar} \Def \sup_{u \in \parSpace} \priorDens(\Par) / \det(2\pi\likPar)^{1/2}$.
[\todo: need to finish this thought. The conjecture here is that the EUP in this setting is 
more robust in this setting due to the bound.

Unlike in the Gaussian log-density case, the EUP does not strictly inflate the plug-in 
mean approximation in regions of larger uncertainty. This is due to the fact that 
the Gaussian likelihood is bounded above. When $\gpMean(\Par)$ and $\obs$
are close, then an increase in $\gpKer(\Par)$ may actually deflate the density 
at $\Par$. The same increase in $\gpKer(\Par)$ will inflate the density at values 
of $\Par$ where $\gpMean(\Par)$ and $\obs$ are far apart.
 
\paragraph{Related work.} The EUP is proposed in the forward model emulator setting 
in \citet{BilionisBayesSurrogates}, motivated by the extended parameter space viewpoint
in \Cref{eq:el-prob-model}. \citet{StuartTeck2,CES} also note this perspective
in the particular Gaussian setting of \Cref{eq:post-em-fwd-Gaussian}.
In \citet{SinsbeckNowak}, the EUP is justified as the distribution 
$q$ that minimizes $\emE\left[\norm{\postEm - q}_{L_2(\parSpace)}^2 \right]$.
\citet{StuartTeck1,StuartTeck2,VehtariParallelGP} also highlight this Bayesian 
decision theoretic justification. 
In contrast with the EP, the optimality is only guaranteed for the estimate of the 
\textit{unnormalized} posterior.
As shown in \Cref{prop:EP-variational}, the EP is the minimizer when the complete 
normalized distributions are considered.

The EUP is referred to as the ``marginal'' approximation in 
\citet{StuartTeck1,StuartTeck2,random_fwd_models,TeckHyperpar},
in which it is analyzed theoretically for both log-density and forward 
model emulators. \citet{VehtariParallelGP} highlight pathological 
behavior of the EUP for GP log-density emulators, and recommend 
against its use in this setting. To our knowledge, \citet{BurknerSurrogate}
is the only previous work to directly compare the EP and EUP (which 
they call the ``expected likelihood''). Their comparison is limited to 
numerical results in case studies involving forward model emulators.
The closed-form EUP expressions in 
\Cref{eq:EUP-Gaussian-ldens,eq:EUP-Gaussian-fwd} have been 
noted in a variety of works 
\citep{StuartTeck1,StuartTeck2,VehtariParallelGP,weightedIVAR,
GP_PDE_priors,Surer2023sequential,Takhtaganov2018AdaptiveBayesianGP}. 
The EUP has seen wide 
use in various applications involving both forward model 
and log-density emulators 
\citep{weightedIVAR,GP_PDE_priors,CES,idealizedGCM,
villani2024posteriorsamplingadaptivegaussian,hydrologicalModel,hydrologicalModel2}.
 
% Approximate Computation for the EP
\section{Approximate Computation for the Expected Posterior} \label{sec:computation}
In this section, we consider a more direct route to EP-based inference through
the use of approximate computational algorithms. 
We first clarify the limitations of existing inference methods, 
and then introduce an efficient MCMC approximation that alleviates 
these difficulties.

\subsection{Sampling Trajectories}
In light of the hierarchical model in \Cref{eq:ep-prob-model}, the following 
algorithm can in principle be applied to directly sample $\postApproxEP$.  

\begin{algorithm}[H]
    \caption{Direct sampling from $\postApproxEP$}
    \label{alg:ep}
    \begin{algorithmic}[1]
    \Function{sampleEP}{$\postNormEm, \NSample, M$}     
        \For{$\sampleIndex \gets 1, \dots, \NSample$} 
        		\State $\targetTraj^{(\sampleIndex)} \sim \emDist$ \Comment{Sample emulator trajectory}
		\State $\Par^{(\sampleIndex, 1)}, \dots, \Par^{(\sampleIndex, M)} \overset{iid}{\sim} \postDensNorm(\cdot; \targetTraj^{(\sampleIndex)})$ \Comment{Sample posterior given trajectory}
	\EndFor
	\State \Return $\{\Par^{(\sampleIndex, m)}\}_{1 \leq \sampleIndex \leq \NSample, \ 1 \leq m \leq M}$
	\EndFunction
    \end{algorithmic}
\end{algorithm}
If one sample is drawn from each posterior trajectory (i.e., $M=1$) then the resulting samples are 
independent. Otherwise, \Cref{alg:ep} produces dependent samples identically distributed according to
$\postApproxEP$. In practice, directly sampling $\Par \given \targetTraj \sim \postDensNorm(\cdot; \targetTraj)$
is rarely possible, so this inner sampling step is replaced by an MCMC algorithm.
The resulting sampling scheme is sometimes called \textit{Metropolis within Monte Carlo (MwMC)} 
\citep{garegnani2021NoisyMCMC}. MwMC has the downside of requiring $\NSample \gg 1$
MCMC runs, but this may be less of an issue in modern parallel computing environments \citep{BurknerSurrogate}. 
Moreover, methods have been developed to reduce the size of $\NSample$ required to achieve a
desired level of precision \citep{BurknerTwoStep}. 

The more significant issue is the outer sampling step, which requires simulating surrogate 
trajectories $\targetEm \sim \emDist$. While not a problem for finite-dimensional 
surrogate models (e.g., linear models), this presents major challenges for surrogates 
derived from GPs. Given the popularity GP surrogates, 
this computational bottleneck must be resolved for the EP to be broadly accessible in 
surrogate-based Bayesian workflows. Standard remedies suffer from poor scalability,
limited applicability, or bespoke numerical implementations. For example, naive 
approximations that discretize $\parSpace$ are limited to low-dimensional settings.
Finite-rank GP approximations offer an alternative, but are dependent on the 
particular form of the surrogate \citep{pathwiseConditioning}. In theory, one 
could retain an infinite-dimensional GP representation by constructing 
GP trajectories ``just-in-time'' within the MCMC algorithm; that is, iteratively
condition the GP at each value of $\Par$ considered within the MCMC run.
However, this approach is well-known to suffer from significant numerical 
instability \citep{pathwiseConditioning}. Finally, we highlight the method of 
\citet{trainDynamics}, which is to our knowledge the only existing work to 
attempt EP-based inference with a GP surrogate. 
Their method consists of approximating GP 
trajectories by sampling the surrogate at a finite grid of points, 
and then approximating the trajectory as the GP mean, conditional on the 
sampled values at these points. Our MCMC method avoids the challenging 
task of choosing an appropriate conditioning set.

\subsection{Approximate Metropolis-within-Gibbs}
In this section, we present an approximate Metropolis-within-Gibbs (MwG) algorithm that 
overcomes the limitations of the alternative methods discussed above. We 
target the joint distribution 
$\emDist(d\targetTraj) \postDens(\Par; \targetTraj)/\normCst(\targetTraj) d\Par$, which admits
$\postApproxEP$ as a marginal. Consider a MwG
scheme that alternates between $\Par$ and $\targetTraj$ updates. 
For a fixed $\targetTraj$, the $\Par$ update must leave the distribution 
$\postDensNorm(\Par; \targetTraj) d\Par$ invariant, which can be achieved 
with a standard Metropolis-Hastings (MH) step. For a fixed $\Par$, the $\targetTraj$
update must leave the distribution 
$\emDist(d\targetTraj) \postDens(\Par; \targetTraj)/\normCst(\targetTraj)$
invariant. This step faces two issues: (i.) the fact that $\targetTraj$ is potentially 
infinite-dimensional, and (ii.) the fact that we cannot compute 
$\normCst(\targetTraj)$. The former can be addressed by so-called 
function space MCMC methods \citep{functionSpaceMCMC}. If we utilize an
MH step with a $\emDist$-reversible proposal distribution 
$\propDist_{\target}(\targetTraj, \cdot)$, then the MH acceptance probability reduces to
\begin{equation}
\accProbMH_{\target}(\targetTraj, \tilde{\targetTraj})
= \min\left(1, \frac{\postDens(\Par; \tilde{\targetTraj})}{\postDens(\Par; \targetTraj)} \cdot 
\frac{\normCst(\targetTraj)}{\normCst(\tilde{\targetTraj})} \right),
\label{eq:MH-ratio-mwg}
\end{equation}
where $\tilde{\targetTraj} \sim \propDist_{\target}(\targetTraj, \cdot)$ is the proposed value.
If $\targetEm \sim \GP(\gpMean, \gpKer)$
\footnote{More generally, this applies when $\postEm$ arises as a transformation
of an underlying Gaussian. The emulator predictive distribution need not be Gaussian.}, 
then we can take $\propDist_{\target}$ as
the preconditioned Crank-Nicholson (pCN; \citet{functionSpaceMCMC}) proposal
\begin{equation}
\tilde{\targetTraj} \Def \gpMean + \pcnCor (\targetTraj  - \gpMean) + \sqrt{1 - \pcnCor^2} \xi, 
\qquad \xi \sim \GP(0, \gpKer).
\end{equation}
To address the issue regarding the intractable normalizing constant ratio in 
\Cref{eq:MH-ratio-mwg}, we might try to apply techniques from the doubly 
intractable MCMC literature \citep{doublyIntractableReview}. However, exact 
MCMC schemes such as the exchange algorithm \citep{exchangeAlg} require 
directly sampling $\postDensNorm(\cdot; \tilde{\targetTraj})$,
which is infeasible in this context. To avoid the challenging task of estimating the 
normalizing constant ratio, we instead invoke the simple approximation 
$\normCst(\targetTraj)/\normCst(\tilde{\targetTraj}) \approx 1$, which is reasonable when 
the proposal $\tilde{\targetTraj}$ does not differ significantly from the current
state $\targetTraj$. We can thus control the error in the approximation by slowing
down the mixing speed of the $\targetTraj$-chain. For the pCN proposal,
the $\pcnCor$ parameter controls the correlation between $\targetTraj$ and 
$\tilde{\targetTraj}$. Therefore, choosing $\pcnCor$ close to one ensures that
$\tilde{\targetTraj}$ is sufficiently similar to $\targetTraj$ on average. 

\subsection{A Correlated Pseudo-Marginal Algorithm}
We now consider the alternative starting point of constructing an 
approximate correlated pseudo-marginal algorithm (cPM) targeting $\postApproxEP$. 
See \citet{pseudoMarginalMCMC,pseudoMarginalEfficiency,corrPM}
for background on pseudo-marginal MCMC.
Designing a pseudo-marginal chain with the correct invariant distribution would 
require access to an unbiased estimator of
$\postDens(\Par; \targetEm)/\normCst(\targetEm)$, which is infeasible.
If we could compute $\normCst(\targetTraj)$, then an unbiased
estimate is given by
 \begin{align}
&\hat{\postDens}^M(\Par; \targetTraj_{1:M}) \Def \frac{1}{M} \sum_{m=1}^{M} \frac{\postDens(\Par; \targetTraj_m)}{\normCst(\targetTraj_m)},
&&\targetTraj_m \overset{iid}{\sim} \emDist.
\end{align}
We write $\targetTraj_{1:M} \sim \emDist^{\otimes M}$ to denote the $M$ independent samples.
A cPM algorithm is defined by specifying a proposal of the form 
$\propDist(\Par, \targetTraj_{1:M}; d\propPar, d\tilde{\targetTraj}_{1:M}) = 
\propDist(\Par, d\propPar) \propDist_{\target}(\targetTraj_{1:M}, d\tilde{\targetTraj}_{1:M})$, where 
$\propDist_{\target}$ is a $\emDist^{\otimes M}$-reversible Markov kernel. This yields an acceptance probability
\begin{align}
\accProbMH &= 
\min\left(1, \frac{\propDist(\propPar, d\Par)\hat{\postDens}^M(\propPar; \tilde{\targetTraj}_{1:M})}{\propDist(\Par, d\propPar)\hat{\postDens}^M(\Par; \targetTraj_{1:M})} \right) \\
&= \min\left(1, 
\frac{\propDist(\propPar, d\Par)}{\propDist(\Par, d\propPar)}
\sum_{m=1}^{M} \frac{\postDens(\propPar; \tilde{\targetTraj}_m)}{\sum_{l=1}^{L} \postDens(\Par; \targetTraj_l) 
\frac{\normCst(\tilde{\targetTraj}_m)}{\normCst(\targetTraj_l)}}
\right) \\
&\approx
\min\left(1, \frac{\propDist(\propPar, d\Par)\postDens(\propPar; \tilde{\targetTraj}_{1:M})}{\propDist(\Par, d\propPar)\postDens(\Par; \targetTraj_{1:M})} \right),
\end{align}
where the final step again invokes the approximation $\normCst(\tilde{\targetTraj}_m)/\normCst(\targetTraj_l) \approx 1$ for each $(m,l)$. 
In the case that $\targetEm$ is Gaussian, we can define $\propDist_{\target}$ to perform $M$ independent pCN updates.
[stopping here for now, see notes below]

\vspace 

\paragraph{Some considerations:}
\begin{itemize}
\item I am realizing that the cPM algorithm exactly targets the EUP. The idea of ``slowing down the f chain'' to improve
the approximation won't work with any MCMC algorithm with a well-defined target distribution (since changing the mixing
rate won't change the target). We can perhaps tout the merits of the cPM approach over the PM approach based on
efficiency, but not based on the quality of the EP approximation.
\item On the other hand, I believe the MwG algorithm still provides this opportunity for ``slowing down the f chain''.
This algorithm can be viewed as an instance of the naive cut algorithm on function space (the practical implementation of
the algorithm ends up looking different due to the necessary conditioning).
\item When I originally derived the cPM algorithm, I had thought that it would have the same target distribution
as the MwG algorithm, with the only difference being whether we choose to update $(u,f)$ jointly or one at
a time. In the joint case, we invoke the approx $Z(\tilde{f})/Z(f) \approx 1$, which ends up reducing the acc prob
that which is consistent with the EUP target. On the other hand, for the MwG scheme we only invoke this approximation 
in the $f$ step, which I guess leads to the two updates being inconsistent with one another.
\item Doesn't really make sense to introduce the idea of using a sample mean with $M$ samples here, but not with the
MwG algorithm. Can use this idea for both algorithms.
\item My current thought is that we first introduce the MwG scheme, mentioning connections to the naive cut algorithm.
Then we can demonstrate how it slightly differs from cPM/PM schemes. The derivation I use for the cPM scheme above
provides a nice connection between the two EP approximation viewpoints we lay out in this paper 
(approx dist vs approx computation).
\item The algorithm below is the ``practical'' version of the MwG scheme (some of the notation is out of date). Need
to decide whether we want to have the algorithm boxes state the conceptual version of the algorithms (in function space)
or the practical version. If going with the latter, need to figure out notation we want to use for the conditioning required
in the algorithm.
\end{itemize}

\begin{algorithm}[H]
    \caption{Metropolis-within-Gibbs Approximation to $\postApproxEP$}
    \label{alg:mwg-ep}
    \begin{algorithmic}[1] 
    \State \textbf{Input:} Current state $(\Par, \targetTraj_\Par)$
    \State \textbf{Output:} Updated state $(\Par^\prime, \targetTraj^\prime_{\Par^\prime})$
     \State Propose $\tilde{\Par} \sim \propDist(\Par, \cdot)$
     \State Propose $(\tilde{\targetTraj}_\Par, \tilde{\targetTraj}_{\propPar}) \sim \emDist(\cdot, \cdot \given \Par, \propPar)$ \Comment{Begin $\targetTraj$ update}
     \State $\alpha_{\targetTraj} \gets \min\left\{1, \postDens(\tilde{\targetTraj}_\Par) / \postDens(\targetTraj_\Par) \right\}$
      	\If{$\mathrm{Unif}(0,1) < \alpha_{\targetTraj}$}
                \State $(\targetTraj^\prime_\Par, \targetTraj^\prime_{\propPar}) \gets (\tilde{\targetTraj}_\Par, \tilde{\targetTraj}_{\propPar})$ 
            \Else
                \State $\targetTraj^\prime_{\Par} \gets \targetTraj_{\Par}$
                \State $\targetTraj^\prime_{\propPar} \gets \emDist(\cdot \given \targetEm(\Par) = \targetTraj_\Par)$
            \EndIf
      \State $\alpha_{\Par} \gets \min\left\{1, \priorDens(\propPar )\lik(\targetTraj^\prime_{\propPar}; \obs) / \priorDens(\Par) \lik(\targetTraj^\prime_{\Par}; \obs) \right\}$ \Comment{Begin $\Par$ update}
             \If{$\mathrm{Unif}(0,1) < \alpha_{\Par}$}
                \State $\Par^\prime \gets \propPar$
                \State $\targetTraj^\prime_{\Par^\prime} \gets \targetTraj^\prime_{\propPar}$ 
            \Else
            	\State $\Par^\prime \gets \Par$
		\State $\targetTraj^\prime_{\Par^\prime} \gets \targetTraj^\prime_{\Par}$
            \EndIf
    \end{algorithmic}
\end{algorithm}

\paragraph{Related work.}
The pseudo-marginal approach to EUP-based inference is noted in \citep{StuartTeck1} and studied 
in depth in \citep{garegnani2021NoisyMCMC}. \citet{BurknerSurrogate} propose targeting the 
distribution proportional to $\hat{\postDens}^M(\Par; \targetTraj_{1:M})$, where $\targetTraj_{1:M}$
is fixed across all MCMC iterations. This does not target the EUP exactly, and can be viewed
as an analog of the sample average approximation from the optimization literature \citep{SAA}.
To improve MCMC efficiency, \citet{garegnani2021NoisyMCMC} also considers ``noisy'' approximations
of the EUP. In contrast to pseudo-marginal algorithms, these methods re-sample both 
$\targetTraj_{1:M}$ and $\tilde{\targetTraj}_{1:M}$ each iteration. 
\citet{FerEmulation} utilize a similar noisy algorithm with $M = 1$, adopting an
approximate computation viewpoint rather than explicitly trying to target $\postApproxNormMarg$.

Both \citep{garegnani2021NoisyMCMC} and \citet{BurknerSurrogate} propose MwMC schemes
for EP-based inference. They appear to implicitly assume the use of finite-dimensional emulators,
as difficulties related to sampling trajectories are not addressed. There has been interest in the 
modular Bayes community in designing approximate MCMC schemes as an alternative to
MwMC for cut posterior inference. \citet{PlummerCut} describes the implementation of such 
an algorithm in the WinBUGS software [\todo: cite], referred to as the \textit{naive cut algorithm}.
The author shows that this algorithm does not admit the cut posterior as an invariant
distribution, and moreover that the implicit target distribution depends on the particular Markov kernels
chosen to perform the updates. The paper proposes a solution to improve the approximation 
using tempered transitions. Subsequent work has considered more sophisticated algorithms
that seek to explicitly estimate the intractable normalizing constant ratios
\citep{SAACut} [\todo: add Yves' paper here]. 
Our MwG algorithm can be viewed as a version of the naive cut algorithm operating in function space.
We opt to avoid normalizing constant estimation and instead slow down the mixing of the 
$\targetTraj$-chain to control the approximation error.

\section{Numerical Experiments} \label{sec:experiments}
\section{Conclusion} \label{sec:conclusion}

% Appendix
\section{Appendix}

For the below proofs we use the following measure-theoretic setup.
Let $\refMeas$ be a reference measure (e.g., Lebesgue) on $(\parSpace, \BorelSig)$,
and $\emDist$ a probability measure on $(\emSpace, \emSig)$. Assume that 
the map $(\Par, \targetTraj) \mapsto \postDens(\Par; \targetTraj)$ is measurable
and $\normCst(\targetTraj) \Def \int \postDens(\Par; \targetTraj) \emDist(\d\targetTraj) \in (0,\infty)$
$\emDist$-almost surely. Let $\postDensNorm(\Par; \targetTraj) \Def \postDens(\Par; \targetTraj) / \normCst(\targetTraj)$
and define the joint distribution 
$\emJoint(\d\Par, \d\targetTraj) \Def \postDensNorm(\Par; \targetTraj) \refMeas(\d\Par)\emDist(\d\targetTraj)$.
Define $\postApproxEP$ to be the density corresponding to the $\Par$-marginal of $\emJoint$; that is,
$\postApproxEP(\Par) \Def \int \postDensNorm(\Par; \targetTraj) \emDist(\d\targetTraj)$. 

\subsection{Proof of \Cref{prop:EP-variational}}
\paragraph{KL Divergence.} We start by proving the KL divergence result.
Let $\qMeas$ be a probability measure on $\parSpace$ with 
$\refMeas$-density $\qDens$. We restrict to measures 
$\postApproxEP \ll \qMeas$, as the KL divergence is infinite otherwise. 
Note that 
$\frac{\d\emJoint}{\d(\emDist \otimes \qMeas)}(\Par, \targetTraj) = \frac{\postDensNorm(\Par; \targetTraj)}{\qDens(\Par)}$.
Using Tonelli's theorem, we have 
\begin{align*}
\E_{\emDist}\left[\KL{\postNormEm}{\qMeas} \right]
&= \int_{\emSpace} \int_{\parSpace} 
\postDensNorm(\Par; \targetTraj) \log \frac{\postDensNorm(\Par; \targetTraj)}{\qDens(\Par)}
\refMeas(\d\Par) \emDist(\d\targetTraj) \\
&= \int_{\parSpace \times \emSpace}  \log \frac{\postDensNorm(\Par; \targetTraj)}{\qDens(\Par)}
\emJoint(\d\Par, \d\targetTraj) \\
&= \int_{\parSpace \times \emSpace}  \log \frac{\d\emJoint}{\d(\emDist \otimes \qMeas)}(\Par, \targetTraj)
\ \emJoint(\d\Par, \d\targetTraj) \\
&= \KL{\emJoint}{\emDist \otimes \qMeas}.
\end{align*}
Finally, 
\begin{align*}
\KL{\emJoint}{\emDist \otimes \qMeas}
&= \int \log \frac{\d\emJoint}{\d(\emDist \otimes \qMeas)} \d\emJoint \\
&= \int \log \left[\frac{\d\emJoint}{\d(\emDist \otimes \postApproxEP)} \frac{\d(\emDist \otimes \postApproxEP)}{\d(\emDist \otimes \qMeas)}\right] d\emJoint \\
&\proptoAdd \int \log \frac{\d(\emDist \otimes \postApproxEP)}{\d(\emDist \otimes \qMeas)} \d\emJoint \\
&= \int_{\emSpace \times \parSpace} 
\log \frac{\postApproxEP(\Par)}{\qDens(\Par)} \postDensNorm(\Par; \targetTraj) \emDist(\d\targetTraj) \refMeas(\d\Par) \\
&= \int_{\parSpace} \log \frac{\postApproxEP(\Par)}{\qDens(\Par)} 
 \postApproxEP(\Par) \refMeas(\d\Par) \\
&= \KL{\postApproxEP}{\qMeas}.
\end{align*} 
where we have used $\proptoAdd$ to absorb additive constants with respect to $\qMeas$. The result follows 
from the fact that $\KL{\postApproxEP}{\qMeas}$ is uniquely minimized at $\qMeas = \postApproxEP$. $\qquad \blacksquare$

\paragraph{Squared $L_2$ loss.} 
For the expected squared error objective, apply Tonneli's theorem 
\begin{align}
\E_{\emDist}\left[\norm{\postNormEm - \qMeas}^2_{L_2(\parSpace)} \right]
&= \int \E_{\emDist} \left[\postDensNorm(\Par; \targetTraj) - \qDens(\Par) \right]^2 \refMeas(d\Par) \nonumber
\end{align}
and notice that the integrand is minimized pointwise by
$\qDens(\Par) = \E_{\emDist}[\postDensNorm(\Par; \targetTraj)] = \postApproxEP(\Par)$. $\qquad \blacksquare$
 
\subsection{Proof of \Cref{prop:kl-cut-op}}
Recall the joint distribution 
$\jointKOH(\d\Par, \d\targetTraj, \d\obs, \d\emObs) =
\priorDens(\Par) \lik(\targetTraj(\Par); \obs) \lik(\targetTraj; \emObs) 
\emDistPrior(\d\targetTraj) \, \d\Par \, \d\obs \, \d\emObs$
with conditional $\postKOH(\d\Par, \d\targetTraj)$.
Let $\postKOH_{\targetTraj}(\d\Par)$ denote the $\targetTraj$-marginal of this conditional.
Similarly, let $\condMargKOH$ denote the marginal conditional of 
$\Par$ given $(\obs,\targetTraj)$.
By the disintegration theorem, any $\qMeas \in \qSpaceCut$ can be written as 
$\qMeas(\d\Par, \d\targetTraj) = \emDist(\d\targetTraj) \qCond(\targetTraj, \d\Par)$ since 
$\qSpaceCut$ restricts the $\targetTraj$-marginal of $\qMeas$ to equal $\emDist$.
Subject to regularity conditions [\todo: be precise here], it follows that
\begin{equation}
\frac{\d\qMeas}{\d\postKOH}(\Par, \targetTraj) =
\frac{\d\emDist}{\postKOH_{\targetTraj}(\d\Par)}(\targetTraj)
\frac{\d\qCond(\targetTraj,\cdot)}{d\condMargKOH}(\Par).
\end{equation}
Therefore,
\begin{align*}
\KL{\qMeas}{\postKOH} 
&= \int \log \left[\frac{\d\qMeas}{\d\postKOH}\right] \qMeas(\d\Par, \d\targetTraj) \\
&\proptoAdd \int \log \left[\frac{\d\qCond(\targetTraj,\cdot)}{d\condMargKOH}(\Par)\right] \emDist(\d\targetTraj) \qCond(\targetTraj,\d\Par) \\
&= \int_{\emSpace} \left\{\int_{\parSpace}  
\log \left[\frac{\d\qCond(\targetTraj,\cdot)}{d\condMargKOH}(\Par)\right] \qCond(\targetTraj,\d\Par) \right\} \emDist(\d\targetTraj) \\
&= \int_{\emSpace} \KL{\qCond(\targetTraj,\cdot)}{\condMargKOH} \emDist(\d\targetTraj).
\end{align*}
Since the integrand is minimized pointwise by $\qCond(\targetTraj,\cdot) = \condMargKOH$, it follows that
$\qMeasOpt(\d\Par, \d\targetTraj) = \emDist(\d\targetTraj)\condMargKOH(\d\Par)$. $\qquad \blacksquare$
 
\subsection{Proofs of \Cref{prop:ep-eup-pw-err} and \Cref{prop:ep-eup-TV-err}}
Recall that for two random variables $a$ and $b$ it holds that $\E[ab] = \E[a]\E[b] + \Cov(a,b)$.
Applying this identity, we have
\begin{equation*}
\postApproxEP(\Par)
= \emE[\postEm(\Par) \normCstEm^{-1}]
= \emE[\postEm(\Par)] \emE[\normCstEm^{-1}] + \Cov(\postEm(\Par), \normCstEm^{-1}).
\end{equation*} 
Subtracting $\postApproxNormMarg(\Par) = \emE[\postEm(\Par)] / \emE[\normCstEm]$
and grouping terms completes the derivation. The integrated error follows from integrating 
over $\parSpace$ and applying Tonelli's theorem, which gives
\begin{equation*}
\int \emE[\postEm(\Par)] \refMeas(\d\Par) = \emE \int \postEm(\Par) \refMean(\d\Par) = \emE[\normCstEm]
\qquad \blacksquare
\end{equation*} 
 
\bibliography{prob_surrogates_bayes} 
% \bibliographystyle{ieeetr}

\end{document}


