\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,url,fancyhdr}
\usepackage[affil-it]{authblk}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{natbib}
\usepackage{bbm}
\usepackage{caption, subcaption}
\usepackage{fancyvrb}
\usepackage{float}
\usepackage[most]{tcolorbox}
\usepackage[hypertexnames=false]{hyperref}
\usepackage{cleveref}

% Bibliography
\bibliographystyle{plainnat}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools}
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Tables. 
\usepackage{multirow}

% Color boxes.
\tcbuselibrary{breakable} % ensure breakable capability is loaded

\newtcbtheorem[number within=section, crefname={example}{examples}, Crefname={Example}{Examples}]{examplebox}{Example}{
    before skip=12pt plus 2pt minus 2pt,
    after skip=12pt plus 2pt minus 2pt,
    breakable,
    enhanced,
    colback=white,
    colframe=gray!80!black,
    colbacktitle=gray!20,
    coltitle=black,
    fonttitle=\bfseries,
    fontupper=\normalfont,
    sharp corners,
    attach boxed title to top left={yshift=-2mm, xshift=2mm},
    boxed title style={colframe=gray!80!black, sharp corners},
}{ex}

% Local custom commands. 
\input{../shared/macros_general.tex}
\input{macros.tex}
\newcommand{\bphi}{\boldsymbol{\phi}}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{{./../../out/review_final/}}

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{remark}{Remark}
\newtheorem{rec}{Recommendation}

\crefname{prop}{Proposition}{Propositions}
\Crefname{prop}{Proposition}{Propositions}
\crefname{definition}{Definition}{Definitions}
\Crefname{definition}{Definition}{Definitions}
\crefname{lemma}{Lemma}{Lemmas}
\Crefname{lemma}{Lemma}{Lemmas}
\crefname{thm}{Theorem}{Theorems}
\Crefname{thm}{Theorem}{Theorems}
\crefname{corollary}{Corollary}{Corollaries}
\Crefname{corollary}{Corollary}{Corollaries}
\crefname{rec}{Recommendation}{Recommendations}
\Crefname{rec}{Recommendation}{Recommendations}
\crefname{remark}{Remark}{Remark}
\Crefname{remark}{Remark}{Remark}

% Title and author
\title{Probabilistic Surrogates for Bayesian Inverse Problems: Posterior Approximation and Active Learning}
\author[1]{Andrew Gerard Roberts\thanks{Emails: \texttt{arober@bu.edu}, \texttt{dietze@bu.edu}, \texttt{huggins@bu.edu}}}
\author[2]{Michael Dietze}
\author[1,3]{Jonathan H. Huggins}

\affil[1]{Faculty of Computing and Data Sciences, Boston University}
\affil[2]{Department of Earth and Environment, Boston University}
\affil[3]{Department of Mathematics and Statistics, Boston University}
\date{}

\begin{document}

\maketitle

% Introduction 
\section{Introduction}

\todo[inline]{
	Need a section or figure laying out the Bayesian surrogate-based workflow. 
	Also need to highlight the major challenges (concentrated posterior, non-stationary likelihoods, sparse designs, GP tail behavior)
}

Within the Bayesian paradigm, there is need for posterior approximation algorithms tailored to settings 
where evaluation of the (unnormalized) posterior density incurs significant computational expense. 
This situation commonly arises in the physical, biological, and engineering sciences, 
where likelihood evaluations require running a complex computer simulation; 
e.g., \citep{ESM_modeling_2pt0,yeastMatingSurrogate,FerEmulation,FATES_CES,CLMBayesianCalibration}.
Such computer models often derive from systems of differential equations, with the goal being to estimate (i.e., calibrate) 
unknown parameters characterizing the physical model.
To address this computational bottleneck, a large body of research has emerged that seeks to characterize the Bayesian 
posterior distribution over model parameters while minimizing the number of required posterior density evaluations. 
A popular class of methods involves replacing either the computer model, log-likelihood function, or
log-posterior density with a statistical surrogate (also called an emulator or meta-model), 
which induces a computationally cheap approximation to the posterior density.
The surrogate can be trained offline using a small set of expensive model runs (often performed in 
parallel), and plugged in as an approximation to facilitate the application of 
standard inference schemes such as Markov chain Monte Carlo (MCMC) 
\citep{modularization,BurknerSurrogate,BurknerTwoStep}.

This generic surrogate-based Bayesian workflow can be instantiated in a variety of ways.
A key modeling decision is the choice of input-output map used to generate training data for
fitting the emulator---i.e., the choice of which quantity to emulate. One option is to 
target the computational bottleneck at its source by emulating the underlying computer model.
This strategy, which we term \textit{forward model emulation}, has been applied extensively
in the computer experiments literature; surrogates have been devised for a wide variety of 
computer models, including those with high-dimensional outputs \citep{HigdonBasis,RougierHighDim}, 
high-dimensional inputs \citep{RemoteSensingEmulator,ZhouHighDimInput}, 
dynamical structure \citep{GP_dynamic_emulation,Bayesian_emulation_dynamic}, and
inherent stochasticity \citep{stochasticComputerModels,VehtariParallelGP,FadikarAgentBased}. 
Alternatively, in the context of Bayesian inference, 
it has been noted that only an approximation of the posterior density is required to 
accelerate posterior estimation \citep{StuartTeck1,GP_PDE_priors}. Therefore, an alternative surrogate 
strategy consists of directly emulating the log-likelihood 
(e.g., \citet{VehtariParallelGP,FerEmulation,trainDynamics}) or 
(unnormalized) log-posterior density (e.g., \citet{emPostDens,gp_surrogates_random_exploration,Kandasamy_2017}). 
We collectively refer to such approaches as \textit{log-density emulation}.
In this review, we adopt a generic viewpoint that encompasses both forward model and log-likelihood
emulation. We will explore the strengths and drawbacks of each approach, and discuss in which contexts
each might be preferred.

In addition to choosing the target map for emulation, another key decision is the 
choice of surrogate model. Gaussian processes \citep{KOH,HigdonBasis,StuartTeck1,VehtariParallelGP}, 
polynomial chaos expansions
\citep{dimRedPolyChaos,PCEBIP,BurknerSurrogate}, and 
neural networks \citep{Lueckmann2018LikelihoodfreeIW,DagonCLM} have 
been extensively applied for this purpose. While many previous studies
on surrogate-based Bayesian inference focus on a specific model 
(e.g., \citet{StuartTeck1,VehtariParallelGP}), recent work has emphasized generic 
probabilistic workflows \citep{BurknerSurrogate,garegnani2021NoisyMCMC,BurknerTwoStep}.
We adopt the latter perspective in this review, remaining agnostic to the particular
surrogate model, while also highlighting Gaussian processes as a special case in order
to aid intuition.

While surrogates offer the potential for significant computational savings, 
they introduce a new source of uncertainty within the Bayesian model. 
To avoid incorrect or miscalibrated inference, it is necessary
to both propagate and---within computational constraints---reduce this uncertainty.
The latter can be addressed by means of sequential design (i.e., active learning)
algorithms, which refine the posterior approximation by iteratively constructing the set of simulator runs used for
surrogate training \citep{SinsbeckNowak,Li_2014,VehtariParallelGP,Lueckmann2018LikelihoodfreeIW,Surer2023sequential,
KandasamyActiveLearning2015,VillaniAdaptiveGP,weightedIVAR,Semler_2023,Semler2024GradientEnhanced,
surrogateNoisyMCMC,hydrologicalModel,AlawiehIterativeGP}.
In many practical applications it is computationally infeasible to reduce the surrogate approximation error to 
a negligible level. Hence, recent work has stressed the importance of inferential workflows that 
propagate surrogate uncertainty so that downstream uncertainty estimates acknowledge the 
surrogate approximation
\citep{BurknerSurrogate,surrogateNoisyMCMC,CES,FerEmulation,hydrologicalModel,hydrologicalModel2}.
In order to propagate surrogate uncertainty, the emulator must include uncertainty
estimates in addition to point predictions. We therefore focus on \textit{probabilistic emulators}, 
which provide predictions in the form of a probability distribution. Gaussian processes naturally 
fall within this category, while other models can be converted into probabilistic emulators
via Bayesian treatments \citep{BayesianPCE1,BayesianPCE2} or ensemble methods \citep{deepEnsembles}. 

% Goals
\subsection{Goals}
Or contributions? Need to think about what we want in this section. Generally speaking, it seems that 
our main contribution is a broad synthesis of a collection of related methods for surrogate-based 
Bayesian inference. We review the varied literature on two related goals: uncertainty propagation 
(posterior approximation) and uncertainty reduction (sequential design/active learning). We provide
detailed derivations of common results used in the Gaussian settings, while also highlighting 
generic probabilistic workflows that do not rely on distributional assumptions.

% Paper Organization
\subsection{Paper Organization}
\Cref{sec:background} begins with background on Bayesian inverse problems and Gaussian processes.
\Cref{sec:surrogate-models} provides an overview of probabilistic surrogates, highlighting distinctions
between finite and infinite-dimensional emulators and describing the techniques of forward model 
emulation and log-density emulation. \Cref{sec:post-approx} addresses the question of how to 
use a probabilistic surrogate to approximate the posterior distribution, with an emphasis on correctly
propagating surrogate uncertainty. \Cref{sec:seq-design} reviews active learning strategies for 
goal-oriented surrogate refinement. We offer a list of practical recommendations in \Cref{sec:recs},
which are emphasized in a numerical case study presented in \Cref{sec:case-study}.
In \Cref{sec:related-work} we highlight related work in computer model calibration, probabilistic numerics,
and multifidelity methods (\todo: this third one may change). We conclude in \Cref{sec:conclusion}. 
All derivations and proofs are provided in the appendix.

% Background
\section{Bayesian Inference with Expensive Models} \label{sec:background}
From a generic perspective, the scope of this paper concerns problems of Bayesian inference in which evaluation
of the (unnormalized) posterior density incurs significant computational expense. This situation is exceedingly common 
in large-scale scientific and engineering applications, where the goal is to infer latent parameters related to 
observations through a computationally expensive computer model. We begin by introducing such Bayesian inverse 
problems, and provide a concrete motivating example. 
 
\subsection{The Bayesian Inference Setting}
Many scientific problems require inferring unknown parameters $\Par \in \parSpace \subseteq \R^{\dimPar}$ using 
noisy observations $\obs \in \obsSpace \subseteq \R^{\dimObs}$. In statistical approaches to this problem, the link
between these quantities is modeled by specifying a likelihood $\lik(\Par; \obs) \Def p(\obs \given \Par)$, and a Bayesian 
completes the model with a prior distribution $\Par \sim \priorDens$ over the parameters. 
The central task of Bayesian inference is to characterize the posterior distribution
\begin{align}
&\postDensNorm(\Par) \Def p(\Par \given \obs) = \frac{1}{\normCst} \priorDens(\Par) \lik(\Par; \obs),
&&\normCst = \int_{\parSpace} \priorDens(\Par) \lik(\Par; \obs) \d\Par,
\end{align}
which encodes the uncertainty in the parameters after observing the data. Both the posterior density $\postDensNorm$
and normalizing constant $\normCst$ depend on $\obs$, but we suppress this in the notation as the data realization 
will remain fixed throughout. Typically, the integral defining $\normCst$ is intractable, so posterior inference algorithms
rely on pointwise evaluations of the \textit{unnormalized} posterior density $\postDens(\Par) \Def \priorDens(\Par)\lik(\Par; \obs)$.
A standard approach is to sample the posterior using a Markov chain Monte Carlo (MCMC) 
algorithm, often requiring $10^5 - 10^7$ serial evaluations of $\postDens(\Par)$. While not a problem for simple 
statistical models, this sequential computation renders MCMC infeasible when the cost of a density evaluation is high.

\subsection{Bayesian Inverse Problems} \label{sec:bip}
The inference challenge posed by expensive posterior densities commonly arises in the Bayesian approach to 
inverse problems \citep{Stuart_BIP}. In this setting, the observation $\obs$ typically corresponds to an 
observable quantity associated with a complex physical system. The goal is to recover latent parameters of interest
$\Par$ that gave rise to the observed data. The bulk of the modeling effort typically consists of constructing a
mechanistic model $\fwd: \parSpace \to \obsSpace$ encoding domain knowledge, which describes the forward 
process by which parameters produce observed quantities. We refer to $\fwd$ as the \textit{forward model}.
The task of solving the inverse problem entails
inverting the relationship, identifying parameter values that might have yielded a particular observation.
This parameter recovery is commonly cast as a problem of Bayesian inference with a Gaussian noise model
\begin{equation}
\obs = \fwd(\Par) + \noise, \qquad
\noise \sim \Gaussian(0, \likPar), \label{eq:inv_prob_Gaussian} 
\end{equation}
implying the likelihood
\begin{equation}
\lik(\Par; \obs) = \det(2\pi\likPar)^{-\dimObs/2} \Exp{-\frac{1}{2} \norm{\obs - \fwd(\Par)}^{2}_{\likPar}}.
\footnote{We utilize the weighted norm notation $\norm{x}^{2}_{A} \Def x^\top A^{-1}x$, where $A$ is a positive definite matrix.}
\label{eq:Gaussian-likelihood}
\end{equation}
Computing $\lik(\Par; \obs)$ (and thus $\postDens(\Par)$) requires the forward model evaluation $\fwd(\Par)$,
which may involve running an expensive computer simulation (e.g., a numerical differential equation solver). Hence, in Bayesian
inverse problems the posterior density $\postDens(\Par)$ is often a computationally expensive, and potentially black box 
(i.e., difficult or impossible to differentiate), function. 

\begin{examplebox}{Parameter Estimation for ODEs}{ex:ode}
In modeling the Earth system, complex dynamical models are used to simulate trajectories
of various physical processes, such as temperature trends and carbon fluxes
 \citep{ESM_modeling_2pt0,paramLSM,idealizedGCM,FATES_CES,CLMBayesianCalibration,FerEmulation}.
These models often feature empirical parameters with unknown values that must be estimated from data.
As a simple illustrative example, we consider the problem of parameter estimation for an ordinary 
differential equation (ODE). While this example is simplified for clarity, the setup is structurally similar to many 
inverse problems faced in practice, such as parameter estimation for land surface models \citep{paramLSM}. 
Consider a parameter-dependent initial value problem 
\begin{align}
\frac{d}{d\Time} \state(\Time, \Par) &= \odeRHS(\state(\Time, \Par), \Par), &&x(\timeStart, \Par) = \stateIC, \label{ode_ivp}
\end{align}
describing the time evolution of $\dimState$ state variables 
$\state(\Time, \Par) \Def \left\{\indexState{\state}(\Time, \Par)\right\}_{\stateIndex=1}^{\dimState}$
with dynamics depending on $\Par \in \parSpace$. As our focus will be on estimating these parameters 
from observations, we consider the parameter-to-state map
\begin{align}
\Par &\mapsto \left\{\state(\Time, \Par) :  \Time \in [\timeStart, \timeEnd] \right\}.
\end{align}
In practice, the solution is typically approximated via a numerical discretization of the form 
\begin{align}
\solutionOp: \Par &\mapsto \left[\indexTime[0]{\state}(\Par), \dots, \indexTime[\NTimeStep]{\state}(\Par) \right]^\top. \label{eq:ode-solution-op}
\end{align}
Here, $\solutionOp: \parSpace \to \R^{\NTimeStep \times \dimState}$ represents the map induced by a numerical solver, 
and $\indexTime[0]{\state}(\Par), \dots, \indexTime[\NTimeStep]{\state}(\Par)$ are approximations of the state 
values $\state(\Time, \Par)$ at a finite set of time points in $[\timeStart, \timeEnd]$. 
Going forward, we focus on the discrete-time operator $\solutionOp$, neglecting discretization error
for simplicity. Finally, suppose we have observed data $\obs \in \obsSpace \subseteq \R^{\dimObs}$ that we model as a
noise-corrupted function of the state trajectory. This is formalized by the definition of an observation operator 
$\obsOp: \R^{\NTimeStep \times \dimState} \to \obsSpace$ mapping from the state trajectory to a 
$\dimObs$-dimensional observable quantity. Assuming the data generating process
\begin{align}
&\obs = (\obsOp \circ \solutionOp)(\ParTrue) + \noise, 
&&\noise \sim \Gaussian(0, \likPar) \label{ode_inv_prob} 
\end{align}
for some ``true'' parameter value $\ParTrue \in \parSpace$, we see that this problem is of the form in 
\Cref{eq:inv_prob_Gaussian} with forward model $\fwd \Def \obsOp \circ \solutionOp$.
In this case, the computational
cost of evaluating $\postDens(\Par)$ can be high, owing to the dependence on the numerical solver $\solutionOp(\Par)$.
\end{examplebox}

\section{Surrogate Models}
Given the inference bottleneck imposed by a computationally expensive posterior density, many methods have emerged
aiming to approximate the posterior using only a small set of density evaluations. Many such approaches 
consist of replacing a computationally-limiting component of the model with a cheap \textit{surrogate}, thus enabling 
the use of standard inference schemes on the resulting approximate model. In this section, we introduce the particular
sub-class of surrogate models that form the focus of this article.

\begin{remark}
The term ``surrogate'' is widely used in varying contexts in which some baseline quantity is replaced by an 
approximation. The remainder of this section defines our precise usage of the word. In the interest of variety, we 
also use ``emulator'' as a synonym, with ``emulate'' referring to the process of constructing an emulator. 
\end{remark}

\subsection{Regression-Based Surrogates}
While there is a vast literature on surrogates designed for specific model structures, 
we instead focus on the broadly applicable strategy of learning regression-based emulators from black-box model 
evaluations. Even within this class of surrogates, the regression modeling setup can vary widely, 
with a key decision being the choice of response variable to approximate with the regression model. 
To formalize this notion, let $\target: \parSpace \to \targetRange$ denote the map that the surrogate seeks to 
approximate. When relevant, we will augment the notation from \Cref{sec:background} to emphasize the dependence
on this \inlinedef{target map}; e.g., $\postDens(\Par; \target)$, $\lik(\Par; \target, \obs)$, $\normCst(\target)$, etc. 
We make the assumption throughout that $\postDens(\Par; \target)$ depends on $\Par$ and $\target$ only as a 
function of $\target(\Par)$.
The implicit assumption here is that the target map has been chosen to alleviate the computational bottleneck; hence,
the density $\postDens(\Par; \target)$ is cheap to compute once the expensive computation $\target(\Par)$ is 
available.

A regression-based surrogate is a regression model $\targetEm$ fit to training data 
$\{(\Par_{\designIdx}, \target(\Par_{\designIdx}))\}_{\designIdx=1}^{\Ndesign}$ constructed by evaluating the exact
target map at a set of \inlinedef{design points} $\design \Def \{\Par_{\designIdx}\}_{\designIdx=1}^{\Ndesign}$.
Substituting the exact map with its emulator induces an approximation of the posterior density 
$\postDensNorm(\Par; \targetEm) = \postDens(\Par; \targetEm) / \normCst(\targetEm)$. Provided that the 
emulator predictions can be computed relatively cheaply, the approximation $\postDens(\Par; \targetEm)$
can now be fed to standard inference algorithms (e.g., MCMC).

\begin{remark}
Throughout this article, we focus on the case where the target $\target$ is a deterministic function.
This implies the observed simulation outputs $\target(\Par_{\designIdx})$ are noiseless, and hence 
emulators commonly seek to (approximately) interpolate between design points.
Many of the ideas here are also relevant to the stochastic case, including to the simulation-based
inference setting where the likelihood takes the form of a black-box stochastic simulator. We discuss
connections to these topics in \todo{add reference}.
\end{remark}

\subsection{Probabilistic Surrogates}
In practice, fitting a highly accurate surrogate can be challenging, and the induced posterior approximation inherits 
imperfections from the underlying emulator. This raises the concern that the surrogate-based posterior approximation
can be both biased and overconfident. To address this fundamental challenge and mitigate the problem 
of unquantified posterior approximation error, we argue that a Bayesian surrogate-based workflow should include
the following two steps:
\begin{enumerate}
\item \textit{Active learning}: while computational resources allow, augment the emulator design with additional 
runs of the simulator, targeting the design points with the greatest potential for improvement in the posterior
approximation or an alternative downstream goal.
\item \textit{Uncertainty propagation}: when the computational budget is exhausted, 
construct a final posterior approximation that propagates the surrogate uncertainty. 
\end{enumerate}
Both of these steps require emulators that are equipped with a notion of predictive uncertainty. For this reason, 
we focus on \textit{probabilistic surrogates}---models that provide predictions in the form of probability
distributions.

\begin{remark}
Conceptually, we typically think of the randomness in the predictive distribution as quantifying \textbf{epistemic uncertainty} \citep{epistemicAleatoric}, which in principle could be reduced, were it computationally feasible to evaluate 
$\target$ at any given input. The predictive distribution may also quantify \textbf{aleatoric uncertainty}, 
irreducible uncertainty stemming from the inability of any parameterization of the surrogate to exactly 
represent the true target function. In the case that the target is stochastic, the predictive distribution will
also model the aleatoric uncertainty due to the inherent randomness of the simulator.
\citet{BurknerSurrogate} present a framework that incorporates both notions of uncertainty.
\end{remark}

\subsubsection{Definitions and Notation}
Concretely, we adopt the viewpoint of an emulator as a random function $\targetEm \sim \emDist$ that
approximates $\target$. Let $\emE$ denote expectation with respect to $\emDist$, and $\targetEm(\Par) \sim \emDist(\Par)$ the pointwise marginal predictive distributions of the surrogate. Supposing for the moment that
the surrogate predicts a scalar-valued quantity, define the pointwise 
predictive mean $\emMean(\Par) \Def \emE[\targetEm(\Par)]$ and variance 
$\emVar(\Par) \Def \Var_{\emDist}[\targetEm(\Par)]$. While some emulators provide only pointwise predictions,
many also encode correlational structure across input values. We thus denote 
$\emKer(\Par, \Par^\prime) \Def \Cov_{\emDist}[\targetEm(\Par), \targetEm(\Par^\prime)]$, 
noting that $\emKer(\Par, \Par) = \emVar(\Par)$.
For a finite set of inputs $\ParBatch \Def \{\Par_b\}_{b=1}^{\Nbatch} \subset \parSpace^{\Nbatch}$, we use the 
vectorized notation $\target(\ParBatch) \Def [\target(\Par_1), \dots, \target(\Par_\Nbatch)]^\top$, with
$\targetEm(\ParBatch) \sim \emDist(\ParBatch)$ denoting the $\Nbatch$-dimensional joint predictive distribution with mean vector $\emMean(\ParBatch)$ and covariance matrix $\emVar(\ParBatch)$. Similarly, given another set
$\ParBatch^\prime$ of $\Nbatch^\prime$ inputs, we write $\emKer(\ParBatch, \ParBatch^\prime)$ to denote
the $\Nbatch \times \Nbatch^\prime$ cross covariance. In particular, we use the shorthand 
$\{\design, \target(\design)\}$ for the design points and their corresponding outputs.

Of central importance to this work is the manner in which emulator uncertainty propagates to downstream 
quantities of interest. For example, the quantity $\postDensNorm(\Par; \targetEm)$ resulting from plugging
the surrogate in place of the true target map is a random density with a distribution that summarizes
surrogate-induced uncertainty in the true posterior. 
When discussing such pushforward distributions we make use of the 
notation $\postNormEm \Def \postDensNorm(\cdot; \targetEm)$ when explicit reference to the underlying emulator
is not necessary.

In many situations, the target $\target$ is a multi-valued function and hence $\targetEm$ is a multi-output
regression model. In this case, $\emMean(\Par)$ and $\emVar(\Par)$ denote the predictive mean vector and 
covariance matrix, respectively, over the different outputs. To avoid complicating notation, we do not extend
the above vectorized notation in the multi-output setting. We make clarifying remarks when necessary to 
avoid ambiguity.

\subsection{Common Surrogate Models}
In this section, we highlight several popular models that fall under our definition of 
\textit{probabilistic surrogate}.

\subsubsection{Gaussian Processes}
Gaussian processes (GPs) are widely used as surrogate models, with extensive applications in 
response surface modeling for computer experiments 
\citep{design_analysis_computer_experiments,SanterCompExp}, 
black-box optimization \citep{reviewBayesOpt}, reliability 
analysis \citep{contourEstimation,cole2021entropybased}, and parameter 
calibration \citep{KOH,computerModelCalibrationReview}. For in-depth treatments, we refer to
\citet{gramacy2020surrogates,gpML,StuartTeck2}.

A typical GP-based workflow consists of specifying a prior $\targetEm[0] \sim \GP(\emMean[0], \emKer[0])$ 
over the target function $\target$, defined by a prior mean function $\emMean[0](\cdot)$ and 
covariance function (i.e., kernel) $\emKer[0](\cdot, \cdot)$. The 
defining property of a GP is its Gaussian finite-dimensional marginal distributions
$\targetEm[0](\ParBatch) \sim \Gaussian(\emMean[0](\ParBatch), \emKer[0](\ParBatch))$
(using the notation $\emKer[0](\ParBatch) \Def \emKer[0](\ParBatch, \ParBatch)$).
Commonly, the hyperparameters defining the mean and kernel are optimized, though Bayesian 
treatments are also possible. With fixed hyperparameters, the surrogate is constructed by 
closed-form conditioning 
$\targetEm \Def \targetEm[0] \given [\targetEm[0](\design) = \target(\design)] \sim \GP(\emMean, \emKer)$,
with the conditional mean and kernel given by
\begin{align}
\emMean(\ParBatch) 
&= \emMean[0](\ParBatch) + \emKer[0](\ParBatch, \design) \emKer[0](\design)^{-1}[\target(\design) - \emMean[0](\design)] \\
\emKer(\ParBatch) 
&= \emKer[0](\ParBatch) - \emKer[0](\ParBatch, \design) \emKer[0](\design)^{-1} \emKer[0](\design, \ParBatch).
\nonumber
\end{align}
Thus, in their most basic form GP surrogates are Gaussian predictors 
$\targetEm(\ParBatch) \sim \Gaussian(\emMean(\ParBatch), \emKer(\ParBatch))$. 
Extensions of the GP methodology
can produce more flexible emulators with non-Gaussian predictive distributions. For example, fully Bayesian 
GPs \citep{fullyBayesianGPs} and deep GPs \citep{deepGPVecchia,deepGPAL}
typically yield predictions in the form of (infinite) mixtures of Gaussians.

\subsubsection{Polynomials}
Surrogates that consist of linear combinations of polynomial basis functions are 
commonly used in the engineering and applied math communities. 
Polynomial chaos expansions (PCEs; \citet[Chapter 9]{UQpredCompSci}) are a particular example whereby 
a polynomial basis is used to approximate a random variable $\target(\Par)$ as a function of
a random input $\Par \sim \priorDens$. In particular, the expansion is of the form
\begin{equation}
\targetEm[\dimBasis](\Par) = \sum_{\idxBasis=1}^{\dimBasis} c_{\idxBasis} \basisVec_{\idxBasis}(\Par),
\end{equation}
where $\basisVec_{1}, \dots, \basisVec_{\dimBasis}$ are orthogonal polynomials with respect 
to the distribution $\priorDens$ on the inputs. Once constructed, a PCE is often used to 
approximate moments of $\target(\Par)$. More relevant to our context,
the map $\targetEm[\dimBasis](\Par)$ can also be used as a surrogate for $\target(\Par)$.
With fixed coefficients $c_{\idxBasis}$, this map is deterministic and thus PCEs do not fall
within our definition of probabilistic surrogates. We nonetheless highlight them here
due to their popularity, the fact that they can be converted into random surrogates by 
considering Bayesian treatments of the coefficients 
\citep{BayesianPCE1,BayesianPCE2,BurknerSurrogate},
and their use in conjunction with probabilistic surrogates (e.g., as the mean function
of a GP; \citet{PCEGPWind,PCEGP2,SinsbeckNowak}). PCE surrogates have been
employed to accelerate Bayesian inversion in various applications 
\citep{dimRedPolyChaos,BurknerSurrogate,PCEBIP}.

\subsubsection{Neural Networks}
In regimes where the input dimension $\dimPar$ and computational 
budget $\Ndesign$ are large, neural networks are well-suited to 
serve as surrogate models. Bayesian treatment of neural 
network parameters provides probabilistic predictions, but in practice significant 
approximations are required for inference \citep{BayesOptNN}. One popular simplification
treats only the final neural network layer in a Bayesian fashion 
\citep{BayesLastLayer,BayesOptBayesLastLayer}. These difficulties have motivated
interest in surrogate models with predictive distributions 
not necessarily rooted in the Bayesian philosophy. This includes deep ensembles, 
which summarize uncertainty via an ensemble of neural network 
models \citep{deepEnsembles,Lueckmann2018LikelihoodfreeIW},
and epistemic neural networks \citep{epistemicNN,BayesOptEpistemicNN}.

\subsection{Finite vs. Infinite Dimensional Surrogates}
As will be explored throughout this paper, methods for surrogate-based posterior inference
may present varying degrees of computational challenges depending on the particular type
of emulator model. A key influencing factor is whether or not the surrogate admits a 
finite-dimensional representation. We define $\targetEm$ to be finite-dimensional if its randomness stems from a finite-dimensional
parameter $\theta_{\Ndesign}$; i.e., $\targetEm(\cdot) = g(\cdot; \theta_{\Ndesign})$ for some 
random vector $\theta_{\Ndesign}$ and non-random function $g$.
In this case, it is feasible to sample trajectories (sample paths) of $\targetEm$ via 
\begin{align}
&\targetTraj(\cdot) \Def g(\cdot; \theta),
&&\theta \sim \mathrm{law}(\theta_{\Ndesign}).
\end{align}
The sampled trajectory $\targetTraj(\cdot)$ can now be evaluated at any input value. A standard example is a 
model taking the form of a linear combination of basis functions 
$\targetEm(\cdot) = \sum_{\idxBasis=1}^{\dimBasis} \theta_{\Ndesign}^{(\idxBasis)} g^{(\idxBasis)}(\cdot)$.

An infinite-dimensional surrogate admits no such finite-dimensional representation. 
Typical examples include surrogates constructed from GPs. For these models, 
it is computationally infeasible to sample trajectories. Instead, the surrogate can typically be 
characterized by the set of distributions $\emDist(\ParBatch)$ over finite-dimensional
subsets $\ParBatch$.

% Surrogate targets
\section{Choosing the Target Map} \label{sec:target-map}
Perhaps even more important than the choice of model class for the surrogate is the decision
as to what should be emulated in the first place; in other words, the definition of the target map
$\target$. While this question is highly problem-dependent, the structure of a Bayesian inference
problem presents multiple high-level options. We categorize these under the broad labels
\inlinedef{forward model emulation} and \inlinedef{log-density emulation}. A similar dichotomy
is explored in \citet{StuartTeck1,GP_PDE_priors,random_fwd_models}, and briefly noted in 
\citet{Surer2023sequential,trainDynamics,ActiveLearningMCMC,emPostDens}.


% --- PAGE 1: THE PLOTS ---
\begin{figure}[p] % [p] suggests putting it on its own page
    \centering
    \enlargethispage{2cm} % Borrow 2cm from the bottom margin
    
    % Adjust row spacing globally for this figure
    \captionsetup[subfigure]{aboveskip=2pt, belowskip=2pt}

    % ROW 1
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[height=0.18\textheight]{gp_dist_fwdem.png}
        \caption{\texorpdfstring{$\targetEm \approx \fwd$}{Forward Model Emulator}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \rule{\textwidth}{0pt} 
        \vfill % Fills vertical space to match the left plot
    \end{subfigure}

    \vspace{0.2em} % Reduced spacing

    % ROW 2
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[height=0.18\textheight]{lpost_dist_fwdem.png}
        \caption{\texorpdfstring{$\log \Gaussian(\obs \given \targetEm(\cdot), \likPar)$}{Induced Log-Likelihood Emulator}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[height=0.18\textheight]{gp_dist_ldensem.png}
        \caption{\texorpdfstring{$\targetEm \approx \log \postDens$}{Log-Density Emulator}}
    \end{subfigure}

    \vspace{0.2em}

    % ROW 3
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[height=0.18\textheight]{dens_dist_fwdem.png}
        \caption{\texorpdfstring{$\Gaussian(\obs \given \targetEm(\cdot), \likPar)$}{Induced Likelihood Emulator}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[height=0.18\textheight]{dens_dist_ldensem.png}
        \caption{\texorpdfstring{$\Exp{\targetEm}$}{Induced Density Approximation}}
    \end{subfigure}

    \vspace{0.2em}

    % ROW 4
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[height=0.18\textheight]{post_norm_dist_fwdem.png}
	\caption{\texorpdfstring{$\Gaussian(\obs \given \targetEm(\cdot), \likPar) / \normCst(\targetEm)$}{Induced Density Approximation}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[height=0.18\textheight]{post_norm_dist_ldensem.png}
        \caption{\texorpdfstring{$\Exp{\targetEm} / \normCst(\targetEm)$}{Induced Density Approximation}}
    \end{subfigure}

    % We leave the main caption empty or use a short version here
    \caption{Surrogate pushforward distributions.} 
\end{figure}

% --- PAGE 2: THE MAIN CAPTION ---
\begin{figure}[t]
    \ContinuedFloat % Keeps the figure numbering the same (e.g., Fig 1)
    \caption{Comparison of forward model and log-likelihood emulation. The left column displays the forward model emulation setting, while the right column displays the log-likelihood emulation setting. The rows represent (1) the primary emulator/blank, (2) the induced log-likelihood, (3) the induced likelihood, and (4) additional metrics. The black line is ground truth, red points are design points, and blue lines are the emulator mean with 90\% credible intervals.}
    \label{fig:em_dist_1d}
\end{figure}


\subsection{Forward Model Emulation}
In the Bayesian inverse problem context (\Cref{sec:bip}), the primary computational bottleneck 
is the underlying forward model $\fwd$. A natural strategy is to fit an emulator to approximate
the map $\Par \mapsto \fwd(\Par)$, thus defining $\target \Def \fwd$. 
The first row of \Cref{fig:em_dist_1d} presents a toy example in which uncertainty in a forward model
emulator propagates to the induced log-likelihood and likelihood approximations.  

The particular form of the forward model surrogate will be dictated by the properties of $\fwd$.  
A common challenge in emulating forward models stems from the fact that the observation 
space (i.e., the output space of $\fwd(\Par)$) can be very high-dimensional. 
Such complications commonly arise in settings with spatial or temporal structure, 
such as epidemic modeling \citep{FadikarAgentBased},
engineering design \citep{PODemulation}, ecological forecasting 
\citep{emPostDens,DagonCLM}, and climate modeling \citep{ESM_modeling_2pt0,idealizedGCM}.
One popular approach to deal with this challenge is to approximate the forward model output
as a linear combination of a small number of basis vectors, and then emulate the scalar coefficients 
of these vectors \citep{HigdonBasis,FadikarAgentBased,PODemulation}.
Alternatively, surrogates 
can be fit to low-dimensional summaries of the high-dimensional output, such as spatial or 
temporal averages \citep{ESM_modeling_2pt0,idealizedGCM,CLMBayesianCalibration,CLMSurrogates}.
Many other approaches have been proposed, including emulators designed 
specifically for dynamical models \citep{GP_dynamic_emulation, Bayesian_emulation_dynamic, 
Liu_West_dynamic_emulation, dynamic_nonlinear_simulators_GP}.
Log-density emulation, described in \Cref{sec:log_density_emulation}, offers another avenue for 
dimension reduction when the observation space is high-dimensional.


\begin{examplebox}{Forward Model Surrogate, Gaussian Setting}{fwd-em}
Consider the setting of a Bayesian inverse problem with an additive Gaussian noise model
(\Cref{eq:inv_prob_Gaussian}). Assume an emulator $\targetEm$ has been 
fit to approximate the true forward model $\fwd$. This induces an approximation of the 
unnormalized posterior density 
\begin{align}
\postDens(\Par; \targetEm) &= \priorDens(\Par)\Gaussian(\obs \given \targetEm(\Par), \likPar),
\label{eq:fwd-em-Gaussian}
\end{align}
for each $\Par \in \parSpace$. In general, the distribution of $\postDens(\Par; \targetEm)$ depends on 
the predictive distribution of $\targetEm$. The additional assumption 
$\targetEm(\Par) \sim \Gaussian(\emMean(\Par), \emVar(\Par))$ facilitates closed-form computation
of the first two moments,
\begin{align*}
\emE\left[\postDens(\Par; \targetEm) \right] 
&= \priorDens(\Par) \Gaussian(\obs \given \emMean(\Par), \likPar + \emVar(\Par)) \\
\Var_{\emDist}\left[\postDens(\Par; \targetEm) \right]
&= \priorDens^2(\Par) \bigg[\frac{\Gaussian\left(\obs \given \emMean(\Par), \frac{1}{2}\likPar + 
\emVar(\Par)  \right)}{\det(2\pi \likPar)^{1/2}} - \\
&\qquad \qquad\qquad \frac{\Gaussian\left(\obs \given \emMean(\Par), \frac{1}{2}\left[\likPar + \emVar(\Par)\right]  \right)}{\det(2\pi [\likPar + \emVar(\Par)])^{1/2}}\bigg].
\end{align*}
for each $\Par \in \parSpace$. This Gaussian setting has been considered frequently in the literature
\citep{StuartTeck1,GP_PDE_priors,hydrologicalModel,hydrologicalModel2,Surer2023sequential,
VillaniAdaptiveGP,weightedIVAR,idealizedGCM,CES}.
\end{examplebox}

\subsection{Log-Density Emulation} \label{sec:log_density_emulation}
Ultimately, only an unnormalized density is required as input to standard posterior inference algorithms.
Therefore, for the purpose of posterior inference, it is sufficient to bypass the forward model and directly 
emulate either the log-likelihood or unnormalized log-posterior density.  
We refer to these two approaches collectively as \inlinedef{log-density emulation}.
The second row of \Cref{fig:em_dist_1d} demonstrates how uncertainty in a GP log-likelihood emulator 
propagates to the likelihood. While one could consider directly emulating the density itself,
fitting surrogates on the log scale is typically preferred as a way to improve numerical stability,
enforce non-negativity in the density approximation, and yield a smoother target function for emulation.

Perhaps the most significant benefit of using log-density emulation is the reduction to predicting a 
scalar-valued output quantity, as opposed to the potentially high-dimensional output space of the forward model. 
This notion is referred to as \textit{scalarization} in \citet{ranjan2016inverse, trainDynamics}.
However, log-density emulation also presents several challenges. Even on the log scale, log-densities can be fast-varying and 
exhibit a large dynamic range, proving troublesome for surrogate models that assume stationarity \citep{wang2018adaptive}.
A simple toy example is used in \citep{Surer2023sequential} to demonstrate such modeling challenges, and the 
authors conclude that forward model emulation is preferred in their application of interest. 
Posterior approximations based on log-density surrogates can also be quite sensitive to emulator misspecification,
owing to the fact that additive errors in the log-density surrogate are exponentiated, implying multiplicative errors in the 
induced density approximation. This sensitivity can easily lead to pathological behavior when propagating 
surrogate uncertainty in this setting, as discussed in \todo{add references/crossref}.

A third challenge follows from the fact that 
the likelihood parameters (e.g., $\likPar$ in \Cref{eq:inv_prob_Gaussian}) are typically not known and must also be 
learned from data. An obvious solution is to extend the input space of the emulator to include the likelihood parameters
\citep{llikRBF,emPostDens}, but the resulting response surface may prove more challenging to emulate. 
This approach also increases both the input dimensionality of the emulator, as well as the number of design points required to achieve a reasonable fit. \citet{llikRBF} describe the construction of designs in the extended input space, 
noting that design points can be added along the likelihood parameter dimensions without requiring more forward model evaluations. For example, in the Gaussian likelihood setting, once the simulation $\target(\Par)$ is obtained, the 
likelihood $\Gaussian(\obs \given \target(\Par), \likPar)$ can now be evaluated cheaply at different values of $\likPar$.
Alternatively, specific likelihood choices may admit a sufficient statistic which can be emulated independently of the likelihood parameters. \citet{FerEmulation}
adopt this approach for a homoscedastic Gaussian likelihood $\Gaussian(\obs \given \fwd(\Par), \sigma^2 I)$ by 
emulating the map $\Par \mapsto \norm{\obs - \fwd(\Par)}_2^2$.

Log-likelihood emulators have also seen use in calibrating stochastic simulators \citep{OakleyllikEm,llikEmABC,VehtariParallelGP,gpEmMCMC}, developing active learning 
algorithms \citep{JosephMinEnergy,ActiveLearningMCMC,quantileApprox,AlawiehIterativeGP}, 
and performing Bayesian quadrature \citep{BayesQuadrature,BayesQuadRatios}. Applications to 
ecological modeling are considered in \citet{FerEmulation,FATES_CES}. \citep{GP_PDE_priors}
compares forward model and log-likelihood emulators for PDE-constrained inverse problems.
Other works instead opt for the closely-related strategy of emulating the unnormalized log-posterior density
\citet{emPostDens,Kandasamy_2017,gp_surrogates_random_exploration,landslideCalibration}.
\citep{wang2018adaptive,adaptiveMultimodal} present a related method in which surrogates are constructed 
to approximate a sequence of functions designed to be more regular than the log-likelihood.

\begin{examplebox}{Log-Likelihood Surrogate, Gaussian Setting}{ldens-em}
In the case that the emulator is fit to the log-likelihood, the induced unnormalized posterior approximation
is of the form 
\begin{align}
\postDens(\Par; \targetEm) &= \priorDens(\Par) \Exp{\targetEm(\Par)}.
\end{align}
Under the assumption $\targetEm(\Par) \sim \Gaussian(\emMean(\Par), \emVar(\Par))$, this
quantity is log-normally distributed, with moments
\begin{align*}
\emE\left[\postDens(\Par; \targetEm) \right] 
&= \priorDens(\Par)\Exp{\emMean(\Par) + \frac{1}{2} \emVar(\Par)} \\
\Var_{\emDist}\left[\postDens(\Par; \targetEm) \right]
&= \priorDens^2(\Par) \left[\Exp{\emVar(\Par)} - 1 \right] \Exp{2\emMean(\Par) + \emVar(\Par)}
\end{align*}
\end{examplebox}

\subsubsection{Log-Likelihood vs. Log-Posterior Emulation.} \label{sec:llik_vs_lpost}
The literature summary above indicates that both log-likelihood and log (unnormalized) posterior
emulators are utilized, with the former being more common. 
We are not aware of any cases in which the performance of the two methods is compared. 
Indeed, the choice appears inconsequential, as one emulator can easily be converted into the other 
by adding or subtracting the log-prior density, which represents a deterministic shift to the predictive 
distribution. Despite the similarity, there are potential tradeoffs from 
a modeling standpoint. One benefit of emulating the log-posterior is the qualitative knowledge 
that the tails of the target function must decay, which can (and should) be leveraged in designing 
an appropriate surrogate model. The tail behavior of the log-likelihood is not always well-known a priori, 
which can present more of a modeling challenge. The challenge of predicting the log-likelihood versus 
the sum of the log-likelihood and log-prior depends on the particular problem at hand; when the data is
highly informative the likelihood will dominate and thus the difference in difficulty will be small. A downside
of log-posterior emulation is that the regularizing effect of the prior cannot be relied upon to tame 
surrogate predictions in the tails. The importance of the surrogate tail behavior is further discussed in 
\todo{add cross-ref}.

% Surrogate-Based Posterior Approximation
\section{Surrogate-Based Posterior Approximation}
The primary goal of Bayesian inference is to characterize the posterior distribution $\postDensNorm$,
which is then used for downstream analysis and decision making. Therefore, a central question in surrogate-based
inference is how to utilize the emulator in approximating $\postDensNorm$ \citep{StuartTeck1,SinsbeckNowak,VehtariParallelGP}.
Error in the emulator approximation will induce error in the posterior approximation, yielding 
biased posterior estimates. In the ideal setting, this bias can be eliminated by iteratively refining the 
surrogate \todo{cross-ref}, but computational constraints often place practical limits on such procedures.
It is thus crucial to acknowledge the surrogate uncertainty within the posterior approximation
in order to properly calibrate posterior uncertainty estimates
\citep{BilionisBayesSurrogates,BurknerSurrogate,StuartTeck1,FerEmulation,BurknerTwoStep}. 
However, there is no single objectively correct method for propagating the uncertainty captured by the surrogate predictive 
distribution \citep{BurknerSurrogate}. Rather, a variety of methods have been proposed, each with their 
own assumptions and practical limitations. It is important for practitioners to understand these 
considerations in order to determine the best approach for a particular application. In this section, we survey 
the various posterior approximations that have been proposed, highlighting overarching themes and 
conceptual considerations. See \todo{cross-ref} for recommendations in choosing a particular method.

\subsection{Plug-In Mean}
Before discussing methods to propagate surrogate uncertainty, we establish the baseline method of simply 
ignoring this uncertainty. A deterministic emulator can be defined by utilizing only the predictive mean function
of the random surrogate model. Plugging the predictive mean $\emMean$
in place of the true target map induces the deterministic posterior approximation
\begin{equation}
\postApproxNormMean(\Par) \Def \postDens(\Par; \emMean) / \normCst(\emMean),
\label{eq:mean-approx}
\end{equation}
which we refer to as the \inlinedef{plug-in mean} approximation.
The plug-in mean approximation has been applied in various contexts
\citep{VehtariParallelGP,trainDynamics,emPostDens,BurknerSurrogate,CLMBayesianCalibration,Lueckmann2018LikelihoodfreeIW,BilionisBayesSurrogates} 
and analyzed theoretically 
\citep{StuartTeck1,StuartTeck2,random_fwd_models,TeckHyperpar,gp_surrogates_random_exploration}.
If the emulator predictive mean is known to be highly accurate then this approximation may be reasonable,
but in general ignoring the surrogate uncertainty can lead to posterior approximations that are 
both inaccurate and overly confident \citep{BurknerSurrogate,BilionisBayesSurrogates}.

\subsection{Frameworks for Constructing Posterior Estimators}
To transition to uncertainty-aware posterior approximations that leverage the full surrogate
predictive distribution, we establish four conceptual frameworks that provide the basis for
deriving such estimators.

\subsubsection{Summarizing a Random Measure} \label{sec:random-measure}
Recall that $\postNormEm(\Par) = \postEm(\Par) / \normCstEm$ is a random density
\footnote{More generally, this is a random probability measure. We work with densities to avoid measure-theoretic technicalities.},
with randomness in the numerator and denominator induced by $\targetEm$.
 One approach to deriving posterior approximations is to construct
a deterministic estimate that summarizes the uncertainty in $\postNormEm$.
\citet{ourSurrPropPaper} formalize this as an optimization problem by defining a loss
$\loss(\qDensNorm, \qDensNorm^\prime)$ that quantifies the difference between two densities. 
A deterministic estimate can then be defined as a minimizer of the expected loss
\begin{equation}
\qDensNormOpt \Def \argmin_{\qDensNorm \in \qSpaceNorm} \emE[\loss(\qDensNorm, \postNormEm)],
\label{eq:random-measure-variational}
\end{equation}
over a candidate space of densities $\qSpaceNorm$.
An estimator derived under this perspective will naturally acknowledge the coupling between
$\postEm(\Par)$ and $\normCstEm$ induced by the shared dependence on $\targetEm(\Par)$.
While conceptually coherent, the dependence of $\normCstEm$ on the entire random function
$\targetEm$ introduces practical difficulties.
The random measure perspective is introduced in \citet{StuartTeck1} and adopted in 
\citet{ourSurrPropPaper,StuartTeck2,random_fwd_models,TeckHyperpar}.

\subsubsection{Decision Theory for Unnormalized Densities} \label{sec:decision-theory}
A practical strategy that circumvents the challenges associated with the random normalizing 
constant is to instead derive an estimate of the \textit{unnormalized} density $\postEm$
and then normalize the estimate post-hoc. This is computationally convenient since
 $\postEm(\Par)$, unlike $\postNormEm(\Par)$, depends only on the marginal distribution of
 $\targetEm(\Par)$, rather than the entire surrogate $\targetEm$.
Such \inlinedef{pointwise estimators} ignore any predictive correlation structure in the surrogate,
thus failing to acknowledge the coupling between $\postEm(\Par)$ and $\normCstEm$. 
A standard approach to constructing pointwise estimators is to adopt a Bayesian decision theoretic
viewpoint, defining a loss function $\loss(\qDens, \qDens^\prime)$ that quantifies the 
distance between two \textit{unnormalized} densities. The unnormalized posterior estimate is then 
defined as the minimizer of the expected loss
\begin{equation}
\qDensOpt \Def \argmin_{\qDens \in \qSpace} \emE[\loss(\qDens, \postEm)],
\end{equation}
over a set of candidate functions $\qSpace$. The final posterior estimate is the normalized version
of $\qDensOpt$. This decision theoretic approach was originally proposed in 
\citet{SinsbeckNowak} and subsequently utilized in 
\citet{VehtariParallelGP,gpEmMCMC,StuartTeck2}.

\subsubsection{Generalized Bayesian Inference} \label{sec:generalized-bayes}
Alternatively, pointwise estimators may be motivated through the lens of generalized Bayesian inference.
Assume the surrogate appears only through the likelihood function (thus excluding log-posterior emulators).
In this case, we define a pointwise loss $\gibbsloss(\Par, \targetTraj)$ quantifying model-data agreement
given a particular parameter $\Par$ and surrogate realization $\targetTraj$. 
Let $\risk$ denote a risk functional mapping $\Par$ to a deterministic summary
of the random variable $\gibbsloss(\Par, \targetEm)$. A posterior approximation can then be defined as 
the optimizer
\begin{align}
\qDensNormOpt \Def 
\mathrm{arginf}_{\qDensNorm \in \qSpaceNorm} 
\left\{\int \risk(\Par) \qDensNorm(\d\Par) + \frac{1}{\gibbsrate} \KL{\qDensNorm}{\priorDens} \right\},
\end{align}
over the space of densities $\qSpaceNorm$. The \textit{learning rate} $\gibbsrate > 0$ controls the size of the 
prior-to-posterior update. Under conditions detailed in \todo{add Bissiri reference}, the optimum assumes the form
\begin{align}
\qDensNormOpt \propto \priorDens(\Par) \Exp{-\gibbsrate \risk(\Par)}.
\end{align}
As we will see, with $\gibbsrate = 1$ and particular definitions of $\risk$, this framework is equivalent to the 
decision theoretic construction in the preceding section.
\todo[inline]{Refine: benefits/motivation of this approach}

\subsubsection{Uncertainty Propagation via Computation} \label{sec:unc-prop-computation}
Finally, we consider algorithmic approaches to uncertainty propagation. Instead of explicitly 
defining a target posterior approximation, one can consider propagating the surrogate uncertainty
through standard inference algorithms (e.g., MCMC). The posterior approximation is thus 
implicitly defined as the output of such an algorithm. \citet{gpEmMCMC} conceptualize 
a Metropolis-Hastings algorithm as a deterministic map from $\postDens$ to
a set of samples (conditional on the internal random variables used for Metropolis proposals
and acceptance decisions). Since the surrogate model induces a distribution over $\postDens$,
approximate posterior inference can be viewed as a standard problem of forward uncertainty propagation
through the deterministic map. While the authors ultimately deem the implementation of such
a procedure impractical, it serves as conceptual inspiration for practical approximations.
\citet{FerEmulation} also adopt a purely algorithmic approach, randomly sampling a realization of the 
surrogate at each iteration of an MCMC algorithm. Approaches of this sort often have close connections
with the so-called noisy MCMC literature \citep{noisyMCSurvey,noisyMCMC}.  

\section{Concrete Posterior Estimators}
We now define several explicit posterior approximations, highlighting their interpretations within 
the above conceptual frameworks.

\subsubsection{The Expected Posterior}
Adopting the random measure viewpoint from \Cref{sec:random-measure}, 
a natural estimate follows from considering the mean of the random density, yielding
the \inlinedef{expected posterior (EP)},
\begin{align}
\postApproxEP(\Par) \Def \int \postDensNorm(\Par; \targetTraj) \emDist(\d\targetTraj).
\label{eq:ep}
\end{align}
\citet{ourSurrPropPaper} argues for the EP as a principled default choice in most analyses.
They adopt the variational formulation in \Cref{eq:random-measure-variational}, showing
that the EP minimizes the expected Kullback-Leibler (KL) divergence and expected 
$L_2$ error with respect to $\postNormEm$.
The terminology \textit{expected posterior} comes from 
\citet{BurknerSurrogate}, in which the EP is empirically compared to alternative approximations.
The EP is a continuous mixture of posterior realizations $\postDensNorm(\Par; \targetTraj)$
induced by trajectories $\targetTraj \sim \emDist$ of the underlying emulator. This immediately 
suggests the following direct sampling scheme for EP inference.

\begin{algorithm}[H]
    \caption{Direct sampling from $\postApproxEP$}
    \label{alg:ep}
    \begin{algorithmic}[1]
    \Function{sampleEP}{$\postNormEm, \NSample, M$}     
        \For{$\sampleIndex \gets 1, \dots, \NSample$} 
        		\State $\targetTraj^{(\sampleIndex)} \sim \emDist$ \Comment{Sample emulator trajectory}
		\State $\Par^{(\sampleIndex, 1)}, \dots, \Par^{(\sampleIndex, M)} \sim \postDensNorm(\cdot; \targetTraj^{(\sampleIndex)})$ \Comment{Sample posterior given trajectory}
	\EndFor
	\State \Return $\{\Par^{(\sampleIndex, m)}\}_{1 \leq \sampleIndex \leq \NSample, \ 1 \leq m \leq M}$
	\EndFunction
    \end{algorithmic}
\end{algorithm}

In general, it is not possible to directly sample from $\postDensNorm(\cdot; \targetTraj)$ and thus it is common to replace the inner sampling
step in \Cref{alg:ep} with an MCMC algorithm. The resulting approximate sampling scheme, known as \inlinedef{Metropolis within Monte Carlo (MwMC)},
is investigated in \citet{garegnani2021NoisyMCMC,BurknerSurrogate,BurknerTwoStep}. 
The outer sampling step requires the ability to 
sample surrogate trajectories and is thus problematic 
when the surrogate model is infinite-dimensional (e.g., a GP), likely explaining why early work in this area discounted the practicality
of the EP \citep{StuartTeck1,StuartTeck2,SinsbeckNowak}. 
\citet{gpEmMCMC} adopt the algorithmic viewpoint discussed in \Cref{sec:unc-prop-computation},
noting that uncertainty could be pushed through the MCMC mapping by sampling surrogate trajectories
and feeding each through the MCMC scheme. While they do not explore this approach further, we note 
that the method they describe directly corresponds to a MwMC scheme for EP-based inference.
\citet{ourSurrPropPaper} discuss practical computation for the EP, presenting
an approximate MCMC scheme that is well-defined in the GP setting.
\citet{trainDynamics} alternatively suggest an approximate MwMC implementation tailored to
GP emulators. 

\subsubsection{The Expected Unnormalized Posterior}
The computational challenges associated with EP-based inference stem from the fact that
the EP considers the average of the \textit{normalized} random posterior $\postEm(\Par) / \normCstEm$.
To avoid such challenges, one could instead consider the ratio estimator defined by averaging
the numerator and denominator independently, yielding the \inlinedef{expected unnormalized posterior (EUP)}
\footnote{
\citep{StuartTeck1,StuartTeck2,GP_PDE_priors} refer to this as the \textit{marginal} approximation,
while \citep{BurknerSurrogate} instead uses the term \textit{expected likelihood}. We prefer 
\textit{expected unnormalized posterior}, as used in \citet{ourSurrPropPaper}, since it also encompasses
log-posterior emulators.
},
\begin{align}
\postApproxEUPNorm(\Par) \Def \frac{\emE[\postEm(\Par)]}{\emE[\normCstEm]}.
\label{eq:eup}
\end{align}
The EUP was first proposed in \citet{BilionisBayesSurrogates}, in which it is derived as 
the marginal posterior $p(\Par \given \obs)$ under the hierarchical model
\begin{equation}
\targetTraj  \sim \emDist, \qquad 
\Par \sim \priorDens, \qquad
\obs \given \targetTraj, \Par \sim \lik(\Par; \targetTraj, \d\obs),
\label{eq:eup-prob-model}
\end{equation}
a perspective also noted in \citet{ourSurrPropPaper,SinsbeckNowak,StuartTeck1,StuartTeck2}.
\citet{SinsbeckNowak} adopt the decision theory framework from
\Cref{sec:decision-theory}, showing that the EUP is optimal under an $L_2$ loss. 
\citet{StuartTeck1,StuartTeck2,random_fwd_models} establish Hellinger bounds between the EUP
and ground truth posterior. \citet{ourSurrPropPaper} sutdy the EUP as an approximation
to the EP, demonstrating that the two distributions can deviate when 
the distribution of $\postEm(\Par)$ varies significantly with $\Par$, especially when these pointwise
distributions are heavy-tailed. \Cref{tab:post-approx-comparison} compares the plug-in mean, EUP,
and EP estimators as (i) ratio estimators, and (ii) mixture distributions aggregating surrogate-induced
posterior trajectories. 

\begin{table}[h]
\centering
\begin{tabular}{>{\raggedright\arraybackslash}p{2.2cm} >{\centering\arraybackslash}p{3.8cm} >{\centering\arraybackslash}p{4.2cm} >{\centering\arraybackslash}p{4.2cm}}
\toprule
& \textbf{Plug-In Mean} & \textbf{EUP} & \textbf{EP} \\
\midrule
\textbf{Ratio Estimator} & 
$\displaystyle \frac{\postDens(\Par; \emE[\targetEm])}{\normCst(\emE[\targetEm])}$ &
$\displaystyle \frac{\emE[\postDens(\Par; \targetEm)]}{\emE[\normCst(\targetEm)]}$ &
$\displaystyle \emE\left[\frac{\postDens(\Par; \targetEm)}{\normCst(\targetEm)}\right]$ \\ [4ex]

\textbf{Mixture Dist.} & 
$\int \postDensNorm(\Par; \targetTraj) \delta_{\emMean}(\d\targetTraj)$ & 
$\int \postDensNorm(\Par; \targetTraj) \emDist(\d\targetTraj \given \obs)$ & 
$ \int \postDensNorm(\Par; \targetTraj) \emDist(d\targetTraj)$ \\
\bottomrule
\end{tabular}
\caption{Different perspectives on normalized density approximations defined by various forms of averaging.
	     The top row highlights interpretations as ratio estimators; only the EP considers the 
	     coupling between the numerator and denominator. The second row shows that each
	     approximation can be viewed as a weighted mixture over surrogate-induced posterior 
	     trajectories. We write $\emDist(\d\targetTraj \given \obs)$ to denote the distribution
	     proportional to $\normCst(\targetTraj) \emDist(\d\targetTraj)$, and $\delta_{\emMean}$
	     the Dirac measure centered at $\emMean$.}
\label{tab:post-approx-comparison}
\end{table}
 
The EUP is typically more computationally convenient relative to the EP. 
This is especially true in special cases where the expectation
$\emE[\postEm(\Par)]$ is available in closed-form (see \Cref{ex:eup-fwd-em,ex:eup-ldens-em}), 
which allows for the application of standard 
Bayesian inference algorithms. Alternatively, if $\targetEm(\Par)$ can be directly sampled pointwise,
then $\emE[\postEm(\Par)]$ can be unbiasedly estimated, enabling the use of pseudo-marginal 
MCMC \citep{pseudoMarginalMCMC}. The psuedo-marginal approach is studied in 
\citet{garegnani2021NoisyMCMC}, and \citet{ourSurrPropPaper} notes that correlated pseudo-marginal
methods \citep{corrPM} may be employed when $\targetEm$ is a GP.

\begin{examplebox}{EUP, Gaussian Forward Model Emulator}{eup-fwd-em}
Consider the setting from \Cref{ex:fwd-em}, where
$\postEm(\Par) = \priorDens(\Par) \Gaussian(\obs \given \targetEm(\Par), \likPar)$
and $\targetEm(\Par) \sim \Gaussian(\emMean(\Par), \emVar(\Par))$.
Under these assumptions, the EUP is given by
\begin{align}
\postApproxEUPNorm(\Par)
&\propto \emE\left[\priorDens(\Par)\Gaussian(\obs \given \targetEm(\Par), \likPar) \right] \nonumber \\
&= \priorDens(\Par) \Gaussian(\obs \given \emMean(\Par), \likPar + \emVar(\Par)). \label{eq:eup-gaussian}
\end{align}
Thus, in this setting the EUP admits a natural data space interpretation. 
The original inverse problem $\obs = \fwd(\Par) + \noise$ is replaced by
$\obs = \emMean(\Par) + \eta(\Par) + \noise$, with the parameter-dependent
noise term $\eta(\Par) \sim \Gaussian(0, \emVar(\Par))$ accounting for the 
uncertainty in the forward model \citep{CES,StuartTeck1}. Observe that
$\postApproxEUP(\Par) \to \priorDens(\Par)$ as $\emVar(\Par) \to \infty$,
implying that ignorance regarding the true forward model output results in 
prior reversion \citep{ourSurrPropPaper}. The particular EUP estimator in \Cref{eq:eup-gaussian}
is utilized in \citet{Surer2023sequential,weightedIVAR,StuartTeck2,GP_PDE_priors,CES,
idealizedGCM,villani2024posteriorsamplingadaptivegaussian,hydrologicalModel,hydrologicalModel2}.
\end{examplebox}

\begin{examplebox}{EUP, Gaussian Log-Likelihood Emulator}{eup-ldens-em}
Recall the setup from \Cref{ex:ldens-em}, where $\postEm(\Par) = \priorDens(\Par)\Exp{\targetEm(\Par)}$
and $\targetEm(\Par) \sim \Gaussian(\emMean(\Par), \emVar(\Par))$.
Under these assumptions, the EUP is given by
\begin{align}
\postApproxEUPNorm(\Par)
&\propto \emE\left[\priorDens(\Par)\Exp{\targetEm(\Par)} \right] \nonumber \\
&= \priorDens(\Par) \Exp{\emMean(\Par) + \frac{1}{2} \emVar(\Par)} \label{eq:eup-ldens-gauss} \\
&= \postApproxMean(\Par) \Exp{\frac{1}{2} \emVar(\Par)}. \nonumber
\end{align}
The final expression demonstrates that, in this setting, the EUP inflates the plug-in mean estimator
where uncertainty is large \citep{StuartTeck1,StuartTeck2,VehtariParallelGP}. 
The estimator scales very quickly as surrogate uncertainty increases, with 
$\postApproxEUP(\Par) \to \infty$ as $\emVar(\Par) \to \infty$.
Thus, unlike the forward model analog in \Cref{ex:eup-fwd-em}, the EUP does not exhibit prior
reversion under surrogate ignorance \citep{ourSurrPropPaper}.
Due to the exponential dependence in \Cref{eq:eup-ldens-gauss}, this distribution can be highly 
sensitive to small changes in $\emMean(\Par)$ and $\emVar(\Par)$, making it particularly susceptible to 
extreme concentration in small regions with large uncertainty \citep{ourSurrPropPaper,VehtariParallelGP}.
\end{examplebox}

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.48\textwidth} % lpost dist [fwd]
         \centering
         \includegraphics[width=\textwidth]{lpost_dist_fwdem.png}
         \caption{\texorpdfstring{$\log\left\{\priorDens(\Par) \lik(\Par; \targetEm)\right\}$}{Log Post. Approx., Forward Model Em.}}
         \label{fig:lpost_dist_fwdem}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.48\textwidth} % post norm approx [fwd]
         \centering
         \includegraphics[width=\textwidth]{post_approx_fwdem.png}
         \caption{$\postDensNorm$ approx}
         \label{fig:post_norm_approx_fwdem}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.48\textwidth} % lpost dist [ldens]
         \centering
         \includegraphics[width=\textwidth]{gp_dist_ldensem.png}
         \caption{\texorpdfstring{$\log\left\{\priorDens(\Par)\right\} + \targetEm(\Par)$}{Log Post. Approx., Log-Lik Em.}}
         \label{fig:lpost_dist_llikem}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.48\textwidth} % post norm approx [ldens] 
         \centering
         \includegraphics[width=\textwidth]{post_approx_ldensem.png}
         \caption{$\postDensNorm$ approx}
         \label{fig:post_norm_approx_llikem}
     \end{subfigure}
        \caption{A continuation of the example in \Cref{fig:em_dist_1d}. The top and bottom rows correspond
        to the forward model and log-likelihood emulation settings, respectively. The first column summarizes
        the distributions of the log-posterior approximations induced by the underlying emulators, with 
        the predictive mean in blue and the shaded region containing 90\% of the mass. The second column 
        plots compares various (normalized) posterior approximations derived from the log-posterior 
        emulator. Note that even though  the emulators interpolate the design points, the posterior
        approximations do not owing to the normalization.}
        \label{fig:post_norm_approx_1d}
\end{figure}
 
\subsubsection{Other Pointwise Estimators}
Various alternative estimators have been proposed for the unnormalized posterior density. 
Instead of computing pointwise expectations, one can consider summarizing $\postEm(\Par)$
using other statistics. Such estimators have primarily been considered for log-density
emulators (\Cref{ex:eup-ldens-em}), motivated by the lack of robustness of the EUP in this setting.
\citet{VehtariParallelGP,quantileApprox,FATES_CES} consider the use of pointwise quantiles as 
a more robust alternative to the mean. 
\Cref{ex:quantile-pw-ldens-em} details the particular form 
of these estimators for log-likelihood emulators with Gaussian predictions. 
Instead of the median, \citet{gpEmMCMC} utilize the pointwise mode of $\postEm(\Par)$, which
has the effect of penalizing surrogate uncertainty; i.e., the posterior approximation at a particular point strictly decreases
when surrogate uncertainty increases at that point. This has the desirable effect of encouraging 
tail decay in the posterior estimate as distance form the design points increases, but fails to produce 
an uncertainty-aware posterior approximation.

In the forward model emulation setting, \citet{BurknerSurrogate} also consider an \textit{expected log-likelihood}
approximation of the form $\priorDens(\Par) \Exp{\emE[\log \lik(\Par; \targetEm)]}$ and draw 
a connection with power-scaled likelihoods. However, the authors ultimately recommend the EP and EUP
as preferred alternatives to this method.

\begin{examplebox}
{Quantile Estimator, Gaussian Log-Likelihood Emulator}
{quantile-pw-ldens-em}
We return to the setting from \Cref{ex:ldens-em} with a Gaussian log-likelihood emulator. 
Let $\emQ(\cdot)$ denote the $\quantileProb \in (0, 1)$ quantile of its argument with respect to $\emDist$. 
A quantile-based estimate in this setting takes the form
\begin{align*}
\postApproxQuantileNorm(\Par) \propto
\priorDens(\Par) \emQ(\Exp{\targetEm(\Par)})
&= \priorDens(\Par) \Exp{\emMean(\Par) + \GaussianCDF^{-1}(\quantileProb) \emSD(\Par)} \\
&= \postApproxMean(\Par) \Exp{\GaussianCDF^{-1}(\quantileProb) \emSD(\Par)},
\end{align*}
where $\GaussianCDF$ is the standard Gaussian distribution function. This expression is of the same form 
as the EUP in \Cref{ex:eup-ldens-em}, but the uncertainty inflation term scales more slowly as a function
of the surrogate uncertainty. The special case $\quantileProb = 1/2$ (i.e., the median) 
reduces to the plug-mean approximation, while values $\quantileProb > 1/2$ imply 
the density will be inflated in regions of higher surrogate uncertainty. The quantile approximation
arises from the decision theoretic viewpoint by considering losses of the $L_1$ variety
\citep{VehtariParallelGP,gpEmMCMC}.
\end{examplebox}

\section{Sequential Strategies for Surrogate Construction}
Outside of simple problems, achieving a desired level of surrogate accuracy using a single 
round of simulator runs typically requires an impractically large number of design points. 
This stems from the fact that the posterior distribution may occupy a small subset of the prior support.
Initial designs sampled from the prior may completely miss the region of $\parSpace$ where 
the posterior concentrates. A natural remedy to address this challenge is to proceed iteratively,
refining the posterior approximation in a sequence of steps. Such algorithms can assume many 
forms, but all share the property that simulator runs are spread across multiple rounds of computation, 
with earlier rounds used to inform the selection of future design points. The number of rounds and 
number of simulations per round are dependent on the computational cost of the simulator and the 
availability of parallel computing resources. The limiting \inlinedef{pure sequential} setting in which 
runs are conducted one after the other offers no opportunity to exploit parallelism, but allows for 
maximal information in selecting design points for new simulations. This serial strategy may be 
ideal for inverse problems of modest computational cost, but becomes intractable as simulator
cost increases. By contrast, a one-shot design allows for maximal parallelism, but relies only 
on prior information to inform the design point selection. In many problems, the optimal balance 
falls between these extremes.

A wide variety of sequential inference strategies have been proposed for Bayesian inverse problems with
computationally expensive posterior densities. We consider the broad class of posterior inference algorithms 
that (i) leverage surrogate models, and (ii) sequentially construct the set of design points used by the surrogate.
Such schemes can be said to be addressing the challenge of \inlinedef{active learning} for the solution of
a Bayesian inverse problem. Our presentation highlights three (non mutually exclusive) active learning strategies:
\begin{enumerate}
\item \inlinedef{Design Optimization}
\item \inlinedef{Tempering}
\item \inlinedef{MCMC-based Exploration}
\end{enumerate}

Each of these strategies attempts to make efficient use of the limited computational budget,
leveraging the current information in the surrogate model to actively target promising regions
of $\parSpace$. However, the design point selection criteria must avoid placing too much trust
in the (imperfect) surrogate. In other words, effective active 
learning algorithms must target promising regions (according to the current surrogate) but also explore
areas where the surrogate is uncertain.
This ``exploration vs. exploitation'' balancing act is familiar in fields such as 
Bayesian optimization \citep{reviewBayesOpt}, Bayesian quadrature 
\citep{BayesQuadrature,BayesQuadratureAL,BayesQuadRatios,quadratureLogGP}, 
reinforcement learning \citep{BadiaRL,LiuRL}, and bandit algorithms \citep{banditsEmpirical,LattimoreBandits}.

\subsection{Design Optimization}
\subsection{Tempered Approximations}
\subsection{MCMC-based Exploration}


\begin{comment}

For GP surrogates, a variety of design criteria (i.e., acquisition functions) have been 
proposed that seek to strike this balance in the context of solving Bayesian inverse problems \citep{SinsbeckNowak,Surer2023sequential,KandasamyActiveLearning2015,weightedIVAR,
VehtariParallelGP,VillaniAdaptiveGP,AlawiehIterativeGP}.

The exploration--exploitation question is one of decision making under uncertainty.   
Even if one had perfect knowledge about the true posterior, there remains the question concerning the optimal
placement of design points for surrogate-based posterior approximation. Insights into this question can guide
the development of improved design algorithms.
Various papers informally remark that accurate approximation requires design points only in the region where the 
posterior is large \citep{AlawiehIterativeGP} [\todo add other citations].
This statement is somewhat misleading, and should be amended as follows:
achieving an accurate posterior approximation
requires an accurate emulator in the subset of $\parSpace$ where the posterior is large, while also
containing enough global information to know where the posterior is small. This informal statement is 
put on rigorous footing in \citet{StuartTeck2}, with theoretical results suggesting designs based on 
an over-dispersed version of $\postDensNorm$.
The notion of oversampling the tails has also been proposed to construct designs
for numerical integration \citep{briol2017sampling}. These results are consistent with the notion of 
constraining the global surrogate behavior, while also fine-tuning the local fit in high-probability regions.
Therefore, in addition to balancing exploration and 
exploitation when selecting design points, one must also consider this local-global tradeoff
\citep{StuartTeck2, gp_surrogates_random_exploration,emPostDens,SinsbeckNowak,Surer2023sequential,adaptiveMultimodal}.
The choice of design algorithm to navigate this tradeoff is problem-specific. For example, 
\citet{adaptiveMultimodal} propose an active learning strategy that specifically targets multimodal posteriors.
The choice will also be determined by the particular surrogate model being used. [\todo: didn't finish edits here]

The manner in which this tradeoff is navigated depends on the particular problem setup and 
the surrogate model itself. For example, \citet{adaptiveMultimodal} propose an active learning strategy 
targeting multimodal posteriors. Another promising line of research consists of adapting local approximations, 
avoiding the challenging task of fitting a single global surrogate \citep{Li_2014,ConradLocalExactMCMC}. 

In the following, we outline the general structure of an active learning algorithm and review design strategies 
that have been proposed for surrogate-based Bayesian inference. We place particular emphasis on 
the batch sequential design setting, where multiple design points are acquired simultaneously [\todo: use problem-solution here].
We conclude this section by briefly noting connections to so-called ``exact-approximate'' MCMC algorithms.
\end{comment}



%%%
\begin{comment}
%%%

\section{Modular Surrogate-Based Bayesian Workflow}
% maybe discuss the KOH joint model in the intro here?
\subsection{Initial Design}
\subsection{Surrogate Target}
\subsection{Posterior Approximation}
\subsection{Surrogate Refinement}

\section{Posterior Approximation}


% stuff to include in MCMC section
The pseudo-marginal approach to EUP-based inference is noted in \citep{StuartTeck1} and studied 
in depth in \citep{garegnani2021NoisyMCMC}. \citet{BurknerSurrogate} propose targeting the 
distribution proportional to $\hat{\postDens}^M(\Par; \targetTraj_{1:M})$, where $\targetTraj_{1:M}$
is fixed across all MCMC iterations. This does not target the EUP exactly, and can be viewed
as an analog of the sample average approximation from the optimization literature \citep{SAA}.
To improve MCMC efficiency, \citet{garegnani2021NoisyMCMC} also considers ``noisy'' approximations
of the EUP. In contrast to pseudo-marginal algorithms, these methods re-sample both 
$\targetTraj_{1:M}$ and $\tilde{\targetTraj}_{1:M}$ each iteration. 
\citet{FerEmulation} utilize a similar noisy algorithm with $M = 1$, adopting an
approximate computation viewpoint rather than explicitly trying to target $\postApproxEUPNorm$.

\paragraph{Infinite-Dimensional Model.} For an infinite-dimensional model, no such 
finite-dimensional parameter $\theta_{\Ndesign}$ exists. Typical examples include 
GPs and deep GPs. In this setting, a generic view of a 
surrogate model is as a map from finite sets of inputs $\parMat$ to a predictive distribution 
over the associated responses $\func(\parMat)$. This viewpoint has formed the basis 
for the implementation of surrogate models in software packages such as 
\verb+BoTorch+ \citep{botorch}. It is therefore feasible to sample the finite-dimensional distributions
$\funcEm[\Ndesign](\parMat)$ for finite input sets $\parMat$, but sampling trajectories
$\func_{\mathrm{samp}}(\cdot) \sim \mathrm{law}(\funcEm[\Ndesign])$ would require 
infinite computing resources. Practical techniques to sample approximate trajectories have been
extensively studied when $\funcEm[\Ndesign]$ is a GP, including work in 
Bayesian inverse problems \citep{dimRedPolyChaos,functionSpaceMCMC} 
and Bayesian optimization \citep{pathwiseConditioning,samplingGPPosts}.
Common approaches construct finite-rank approximations of the form  
in \Cref{eq:finite-basis}.


\footnote{This is in contrast to other surrogate modeling strategies (e.g., reduced-order modeling)
that exploit the specific structure of the forward model; see \citet{multifidelityReview} for a detailed review.}

 \subsection{Gaussian Processes} \label{gp_review}
 Since Gaussian processes will serve as our primary example of a probabilistic surrogate,
 we provide a brief overview here; for in-depth treatments, we refer to 
 \cite{gramacy2020surrogates, StuartTeck2, gpML}.
 

% Initial Design and Surrogate Models
\section{Initial Design and Surrogate Models} \label{sec:surrogate-models}
We begin our review by summarizing the surrogate modeling workflow in the context of solving
Bayesian inverse problems. We focus exclusively on a modular workflow \citep{modularization}, 
such that the surrogate is trained only on data produced by the simulator, as opposed to jointly 
learning the surrogate with the parameters in a unified Bayesian model 
(e.g., as in the seminal work \citet{KOH}). Fitting the surrogate requires 
generating training data by evaluating the simulator at a chosen set of input parameters
$\designIn \Def \{\Par_1, \dots, \Par_{\Ndesign}\}$, referred to as the \textit{initial design}.
The design points are then used for training a model to predict some output quantity of interest 
as a function of $\Par$. We refer to this output quantity as the \textit{emulator target}, 
and discuss several targets commonly used in surrogate-based Bayesian inference. 
Many different regression and interpolation models have been used as emulators. 
Our aim is not to investigate any specific model in depth; rather, we generally focus 
on models that provide a probabilistic representation of emulator uncertainty. 
This uncertainty can then be propagated when constructing a posterior approximation 
(\Cref{sec:post-approx}) and leveraged to guide the selection of new design points (\Cref{sec:seq-design}).

\subsection{Initial Design}
Initially, one typically has limited information regarding the structure of the emulator target and thus
chooses the initial design $\designIn$ to satisfy some sort of ``space-filling'' criterion; canonical examples 
include latin hypercube designs and Sobol sequences \citep{initDesignReview}.
In the Bayesian inference setting, a natural approach is to sample $\designIn$ from the prior $\priorDens$, 
either via simple Monte Carlo or deterministic alternatives \citep{supportPoints, SteinPoints}.
One of the central challenges of surrogate-based Bayesian inference is the well-documented fact that
the posterior is often highly concentrated relative to the prior \citep{StuartTeck2,Li_2014,PCEBIP}.
This implies that initial designs sampled from the prior may contain few or no points in the region of 
high posterior mass. Therefore, initial emulator fits may simultaneously produce reasonable approximations
in a prior-averaged sense but poor approximations to the posterior. This challenge motivates
the use of active learning algorithms to iteratively construct the design in order to target high-posterior
regions (see \Cref{sec:seq-design}).

Another approach to this problem is to first run an alternative algorithm (e.g., an approximate 
sampler or optimizer) to produce design points in regions of high posterior mass, which can then 
be used as part of an initial design to fit an emulator. This general strategy is exemplified by the 
\textit{calibrate, emulate, sample} workflow \citep{CES,idealizedGCM,CESSoftware,FATES_CES,adaptiveMultimodal}, 
which uses Ensemble Kalman methods to produce the initial design. In similar spirit, the earlier work 
\citet{emPostDens} utilizes a sequence of importance sampling steps to construct a Gaussian 
approximation of the posterior, which is then sampled from to produce an initial surrogate design.
\citet{JosephMEDSampling} instead proposes the use of deterministic sampling methods to generate 
the initial design. While we do not focus on these methods further in this review, continued 
methodological development investigating such workflows is a promising avenue for future research. 

 
\section{Posterior Approximation} \label{sec:post-approx}

\subsection{Expected Likelihood}

The \textit{unnormalized} expected likelihood approximation $\postApproxMarg[\Ndesign]$ 
 may be justified from a Bayesian decision-theoretic viewpoint as the minimizer of an $L^2$ risk. However, this does not 
 confer the same optimality on the normalized approximation $\postApproxNormMarg[\Ndesign]$;
 see \citep{SinsbeckNowak,StuartTeck2,VehtariParallelGP} for details. 
 Alternatively, under a forward model emulator, $\postApproxNormMarg[\Ndesign]$ can be viewed as
 the $\Par$-marginal of the joint posterior $p(\Par, \fwdEm[\Ndesign](\Par) \given \obs)$; by contrast, recall
 the interpretation of $\postApproxEP[\Ndesign]$ as the marginal of $p(\Par, \fwdEm[\Ndesign] \given \obs)$.
 This extended parameter space viewpoint is adopted in \citet{BilionisBayesSurrogates}, who 
 to our knowledge are the first to propose the expected likelihood approximation to propagate 
 surrogate uncertainty.
 \footnote{\citet{BilionisBayesSurrogates} only consider the forward model emulation setting, 
 and call $\postApproxNormMarg[\Ndesign]$ the 
 $\mathcal{D}$-restricted posterior, in reference to the finite computational budget
 $\mathcal{D} = \{\designIn, \fwd(\designIn)\}$.} 
They explore several variants of the approximation, which differ based on the treatment of surrogate 
hyperparameters. The works by \citet{SinsbeckNowak,StuartTeck1} follow shortly thereafter, 
providing a Bayesian decision theoretic perspective and lending theoretical support to the expected
likelihood approximation.

 If the pointwise expectation 
 $\E_{\Ndesign}[\postEm[\Ndesign](\Par)]$ is computable in closed-form, then 
the expected likelihood approximation can be sampled using standard MCMC software.
In cases where this expectation is intractable, pseudo-marginal MCMC 
\citep{pseudoMarginalMCMC} may be employed, so long as 
samples can be drawn from the surrogate predictive distribution $\postEm[\Ndesign](\Par)$
at any input $\Par$. The pseudo-marginal approach is discussed in \Cref{sec:MH-approx}.
\citet{BurknerSurrogate} alternatively propose to replace  $\E_{\Ndesign}[\postEm[\Ndesign](\Par)]$
with a fixed Monte Carlo estimate derived from surrogate samples (i.e., a sample average approximation). 
Their method differs from the 
pseudo-marginal algorithm in that the Monte Carlo samples are simulated once 
and then fixed throughout the MCMC run; this is similar to the particle approximation 
previously proposed in \citet{BilionisBayesSurrogates}.
This approach allows for the application of standard 
MCMC methods, but targets an approximation to $\postApproxNormMarg[\Ndesign]$
and is only directly implementable in the finite-dimensional setting.
In the infinite-dimensional case, most previous literature 
has focused on the Gaussian settings from \Cref{eq:fwd-em-Gaussian-post,eq:fwd-em-Gaussian} 
and \Cref{eq:llik-em-Gaussian} due to their analytic tractability. We summarize these special cases below.

\begin{examplebox}[Gaussian Forward Model Emulation Setting]
In the Gaussian forward model emulation setting from \Cref{eq:fwd-em-Gaussian-post,eq:fwd-em-Gaussian}, the
expected likelihood approximation is given by 
\begin{align}
\postApproxMarg[\Ndesign](\Par) 
&= \priorDens(\Par) \Gaussian\left(\obs \given \emMean[\Ndesign]{\fwd}(\Par), \likPar + \emKer[\Ndesign]{\fwd}(\Par) \right). 
\label{eq:post-approx-fwd-EL-Gaussian}
\end{align}
Moreover, \Cref{eq:post-approx-fwd-EL-Gaussian} is the unnormalized posterior corresponding to the modified
Bayesian inverse problem
\begin{align}
&\obs = \emMean[\Ndesign]{\fwd}(\Par) + \eta_{\Ndesign}(\Par) + \noise
&&\noise \sim \Gaussian(0, \likPar)  \label{inv_prob_Gaussian_modified} \\
&\eta_{\Ndesign}(\Par) \sim \Gaussian(0, \emKer[\Ndesign]{\fwd}(\Par))
&&\Par \sim \priorDens  \nonumber
\end{align}
where $\noise$, $\Par$, and $\eta_{\Ndesign}(\Par)$ are pairwise a priori independent for all $\Par$.
The approximate likelihood retains a Gaussian form, where the surrogate predictive mean
$\emMean[\Ndesign]{\fwd}$ has replaced the true forward model $\fwdEm[\Ndesign]$. The surrogate uncertainty
is incorporated via the addition of $\emKer[\Ndesign]{\fwd}(\Par)$ to the noise covariance $\likPar$.
We emphasize that even if the prior $\priorDens$ is Gaussian, the posterior approximation will typically be non-Gaussian
due to the nonlinearity of $\emMean[\Ndesign]{\fwd}(\Par)$ and the fact that the likelihood covariance depends on 
$\Par$ through $\emKer[\Ndesign]{\fwd}(\Par)$. The modified inverse problem viewpoint 
in \Cref{inv_prob_Gaussian_modified} is noted in \citet{SinsbeckNowak} and \citet{StuartTeck1},
representing a special case of the extended parameter space perspective taken in \citet{BilionisBayesSurrogates}.
The closed-form expression in \Cref{eq:post-approx-fwd-EL-Gaussian} is also noted in both
\citet{SinsbeckNowak, StuartTeck1} and has been used in many subsequent studies 
\citep{weightedIVAR,StuartTeck2,GP_PDE_priors,CES,idealizedGCM,
villani2024posteriorsamplingadaptivegaussian,hydrologicalModel,hydrologicalModel2}. 
\citet{Surer2023sequential} derive the special case of \Cref{eq:post-approx-fwd-EL-Gaussian}
under the multi-output basis vector model in \Cref{basis_func_GPs,basis_func_noise}, while 
\citet{Takhtaganov2018AdaptiveBayesianGP} give the analogous formula when the 
predictive distribution is a finite Gaussian mixture.
\end{examplebox}

\begin{examplebox}[Gaussian Log-Density Emulation Setting]
Consider the Gaussian log-density emulation setting from \Cref{eq:llik-em-Gaussian}
with a log-likelihood emulator. With this setup, the expected likelihood approximation is given by 
\begin{align}
\postApproxMarg[\Ndesign](\Par) 
&= \priorDens(\Par) \Exp{\emMean[\Ndesign]{\llik}(\Par) + \frac{1}{2}\emKer[\Ndesign]{\llik}(\Par)}
= \postApproxMean(\Par) \Exp{\frac{1}{2}\emKer[\Ndesign]{\llik}(\Par)}. 
\label{eq:post-approx-llik-EL-Gaussian}
\end{align}
The log-posterior emulation case is very similar. From \Cref{eq:post-approx-llik-EL-Gaussian},
we see that $\postApproxMarg[\Ndesign]$ inflates the mean approximation at points
where the emulator is uncertain. It is notable that the uncertainty inflation factor 
$\Exp{\frac{1}{2}\emKer[\Ndesign]{\lpost}(\Par)}$ scales very quickly as the surrogate variance 
increases. \citet{VehtariParallelGP} note this fact, emphasizing that using the expectation can
be a misleading summary of the log-normal random variable $\postEm[\Ndesign](\Par)$.
In practice, we also find this to be the case; the heavy-tailed nature of log-normal distributions
can lead $\postApproxNormMarg[\Ndesign]$ to be heavily concentrated in small regions with high 
predictive variance. In \Cref{rec:bound-constraints} and \Cref{sec:case-study-lpost-em} we 
describe how enforcing bound constraints can avoid these pathologies.
The EL approximation in the Gaussian log-density emulation setting is analyzed theoretically
in \citet{StuartTeck1,StuartTeck2,GP_PDE_priors,random_fwd_models,TeckHyperpar}.
\end{examplebox}

\subsection{Other Unnormalized Density Approximations}
Various alternative approximations have been proposed for the unnormalized posterior density. 
Instead of computing pointwise expectations, one can consider summarizing $\postEm[\Ndesign](\Par)$
by computing pointwise quantiles \citep{VehtariParallelGP,quantileApprox}. In the log-likelihood 
emulation setting with a GP emulator, \cite{VehtariParallelGP} considers the $\quantileProb$-quantile of 
the likelihood surrogate
\begin{equation}
\mathrm{Quantile}_{\quantileProb}(\Exp{\llikEm[\Ndesign](\Par)})
= \Exp{\emMean[\Ndesign]{\llik}(\Par) + \GaussianCDF^{-1}(\quantileProb) \sqrt{\emKer[\Ndesign]{\llik}(\Par)}},
\label{eq:post-approx-quantile}
\end{equation}
where $\GaussianCDF$ denotes the standard Gaussian distribution function. This expression is of the same form 
as the expected likelihood in \Cref{eq:post-approx-llik-EL-Gaussian}, but the uncertainty inflation term 
$\Exp{\GaussianCDF^{-1}(\quantileProb) \sqrt{\emKer[\Ndesign]{\llik}(\Par)}}$ scales more slowly than 
$\Exp{\frac{1}{2} \emKer[\Ndesign]{\llik}(\Par)}$. The special case $\quantileProb = 1/2$ (i.e., the median) 
reduces to the mean approximation in \Cref{eq:mean-approx-llik}, while values $\quantileProb > 1/2$ imply 
the density will be inflated in regions of higher surrogate uncertainty. \citet{FATES_CES} also utilize the 
approximation in \Cref{eq:post-approx-quantile}, though they do not explicitly draw the connection to 
the quantile estimator.

In the forward model emulation setting, \citet{BurknerSurrogate} also consider an \textit{expected log-likelihood}
approximation of the form $\priorDens(\Par) \Exp{\E_{\Ndesign}[\llik(\Par; \fwdEm[\Ndesign])]}$ and draw 
a connection with power-scaled likelihoods. However, the authors ultimately recommend the expected 
posterior and expected likelihood as preferred alternatives to this method.

\subsection{Noisy MCMC Approximations} \label{sec:MH-approx}
Outside of special cases, many of the above approximate posteriors can pose computational
challenges for inference (e.g., requiring closed-form density
approximations or sampling trajectories). It is thus desirable to consider general-purpose 
algorithms that can be easily
implemented for any surrogate. We thus consider a class of MCMC algorithms 
that only require the ability to draw samples from the emulator predictive distribution at finite 
sets of inputs. Such algorithms are therefore agnostic to the predictive distribution
or the particular likelihood, and are also applicable to infinite-dimensional emulators.
These approaches focus on constructing approximations to MCMC algorithms, as opposed to 
approximations of the unnormalized posterior density.
Some of these methods provide algorithms for sampling from approximate posteriors already 
defined above, while others represent new approaches to inference.

To start, we recall the standard Metropolis-Hastings (MH) algorithm, which is defined by a proposal 
kernel with density $\propDens(\Par, \cdot)$. If the Markov chain is in the current state 
$\Par \in \parSpace$ then the next state is defined by sampling the proposal
 $\propPar \sim \propDens(\Par, \cdot)$, which is accepted with probability
\begin{align}
&\accProbMH(\Par, \propPar) \Def 
\min\left\{1, \frac{\postDens(\propPar)\propDens(\propPar, \Par)}{\postDens(\Par) \propDens(\Par, \propPar)} \right\}.
\label{MH_acc_prob_exact}
\end{align}
If accepted, the next state is defined to be $\propPar$, else it is set to the current state $\Par$. 
This procedure is summarized in \Cref{alg:MH}. 

\begin{figure}[ht]
\centering
\begin{minipage}[t]{0.495\textwidth}
    \floatname{algorithm}{Alg.}
    \captionsetup{type=algorithm}
    \caption{Metropolis-Hastings}
    \label{alg:MH}
    \begin{algorithmic}[1]
    \Function{MH}{$\Par_0, \NMCMC$}     
        \For{$k \gets 0, \dots, \NMCMC$} 
            \State $\tilde{\Par} \sim q(\Par_{k}, \cdot)$
            \State $\alpha \gets \min\left\{1, \frac{\pi(\tilde{\Par}) q(\tilde{\Par}, \Par_k)}{\pi(\Par_k) q(\Par_k, \tilde{\Par})} \right\}$
            \State $b \sim \text{Bernoulli}(\alpha)$
            \If{$b = 1$}
                \State $\Par_{k+1} \gets \tilde{\Par}$ 
            \Else
                \State $\Par_{k+1} \gets \Par_k$
            \EndIf
        \EndFor
    \EndFunction
    \end{algorithmic}
\end{minipage}
\hfill
\begin{minipage}[t]{0.495\textwidth}
    \floatname{algorithm}{Alg.}
    \captionsetup{type=algorithm}
    \caption{Noisy Metropolis-Hastings}
    \label{alg:MH-noisy}
    \begin{algorithmic}[1]
    \Function{MH-Noisy}{$\Par_0, \NMCMC, \postSampleKernel$}
        \State $\hat{\pi}_{\text{curr}} \sim \mathrm{law}(\postEm[\Ndesign](\indexMCMC[0]{\Par}))$
        \For{$k \gets 0, \dots, \NMCMC$} 
            \State $\tilde{\Par} \sim q(\Par_k, \cdot)$
            \State $[\hat{\pi}_{\Par}, \hat{\pi}_{\tilde{\Par}}] \sim \postSampleKernel([\Par_k, \tilde{\Par}, \hat{\pi}_{\text{curr}}], \cdot)$
            \State $\hat{\alpha} \gets \min\left\{1, \frac{\hat{\pi}_{\tilde{\Par}} \cdot q(\tilde{\Par}, \Par_k)}{\hat{\pi}_{\Par} \cdot q(\Par_k, \tilde{\Par})} \right\}$
            \State $b \sim \text{Bernoulli}(\hat{\alpha})$
            \If{$b = 1$}
                \State $\Par_{k+1} \gets \tilde{\Par}$
                \State $\hat{\pi}_{\text{curr}} \gets \hat{\pi}_{\tilde{\Par}}$
            \Else
                \State $\Par_{k+1} \gets \Par_k$
            \EndIf
        \EndFor
    \EndFunction
    \end{algorithmic}
\end{minipage}
\caption{\textbf{(Left)} A standard Metropolis-Hastings MCMC algorithm with proposal density $\propDens(\Par, \cdot)$.
\textbf{(Right)} A generic noisy Metropolis-Hastings algorithm. The choice of Markov kernel $\postSampleKernel$ 
defines particular algorithms.}
\end{figure}

We consider a family of algorithms that change $\accProbMH(\Par, \propPar)$ by
substituting the exact densities $\postDens(\Par)$  and $\postDens(\propPar)$ 
with approximations sampled from a specified distribution. The particular choice of 
this distribution yields different algorithms, all of which are ``noisy'' in the sense that 
an additional Monte Carlo step has been injected within the standard MH scheme
\citep{noisyMCSurvey,noisyMCMC,stabilityNoisyMH}. In particular, we assume 
that the approximation of $[\postDens(\Par), \postDens(\propPar)]$ is sampled as
\begin{equation}
[\hat{\postDens}_{\Par}, \hat{\postDens}_{\propPar}] \sim \postSampleKernel([\Par, \propPar, \postDens^\prime], \cdot),
\end{equation}
where $\postSampleKernel$ is a Markov kernel mapping from source $\parSpace^2 \times \R_+$
to target $\R^2_{+}$. The generic noisy MH algorithm is stated in \Cref{alg:MH-noisy}. 
We consider three special cases below.

\paragraph{Pseudo-Marginal.}
We first consider the choice 
\begin{equation}
\postSampleKernel([\Par, \propPar, \postDens^\prime], \cdot)
\Def \delta_{\postDens^\prime} \otimes \mathrm{law}(\postEm[\Ndesign](\propPar)),
\end{equation}
which implies that at each iteration only the density value at the proposed point 
$\postEm[\Ndesign](\propPar)$  is sampled, while the value at the current point 
is recycled from the previous iteration. This is a pseudo-marginal algorithm 
targeting the stationary distribution $\postApproxNormMarg[\Ndesign]$ \citep{pseudoMarginalMCMC}.
In principle, it provides an exact MCMC scheme to sample from the expected likelihood 
approximation even when the expectation $\E_{\Ndesign}[\postEm[\Ndesign](\Par)]$ is intractable, 
a fact noted in \citet{StuartTeck1}. The key property ensuring invariance with respect to 
$\postApproxNormMarg[\Ndesign]$ is that the value $\hat{\postDens}_{\propPar}$ sampled from 
$\postSampleKernel$ is an unbiased estimate of $\E_{\Ndesign}[\postEm[\Ndesign](\propPar)]$.
Therefore, the method remains valid for estimators of the form 
\begin{align}
&\hat{\postDens}_{\tilde{\Par}}^{J} \Def \frac{1}{J} \sum_{j=1}^{J} \hat{\postDens}_{\tilde{\Par}}^{(j)},
&&\hat{\postDens}_{\tilde{\Par}}^{(j)} \overset{\mathrm{iid}}{\sim} \mathrm{law}(\postEm[\Ndesign](\propPar)). \label{eq:pm-unbiased-est}
\end{align}
It is well-known that pseudo-marginal methods
can suffer from slow mixing, but that efficiency can be improved by reducing the variance 
in the estimate of $\E_{\Ndesign}[\postEm[\Ndesign](\propPar)]$; e.g., by increasing $J$ in
\Cref{eq:pm-unbiased-est} \citep{pseudoMarginalMCMC,pseudoMarginalEfficiency}.
The pseudo-marginal approach to sampling $\postApproxNormMarg[\Ndesign]$ is studied 
in \citet{garegnani2021NoisyMCMC}.

\paragraph{Monte Carlo within Metropolis Hastings.}
We next consider the Markov kernel 
\begin{equation}
\postSampleKernel([\Par, \propPar, \postDens^\prime], \cdot)
\Def \mathrm{law}(\postEm[\Ndesign](\Par)) \otimes \mathrm{law}(\postEm[\Ndesign](\propPar)),
\end{equation}
which independently re-samples the density values at both the current and proposed locations
at each iteration (the kernel does not depend on $\postDens^\prime$). Algorithms of this form are 
typically referred to as Monte Carlo within Metropolis Hastings (MCwMH), and have been studied as an
efficient alternative to the pseudo-marginal algorithm \citep{noisyMCMC,stabilityNoisyMH}.
The sampled density values can also be replaced with sample means as in \Cref{eq:pm-unbiased-est},
though the efficiency of MCwMH is generally less sensitive to the variance in the estimate
\citep{garegnani2021NoisyMCMC,stabilityNoisyMH}.
The MCwMH is typically referred to as inexact, in the sense that it does not admit 
$\postApproxNormMarg[\Ndesign]$ as an invariant distribution. However, in the present setting
$\postApproxNormMarg[\Ndesign]$ is itself an approximation of $\postDensNorm$ so we might
view MCwMH as an alternative method for propagating surrogate uncertainty
on equal footing with $\postApproxNormMarg[\Ndesign]$. This perspective is taken in 
\citet{surrogateNoisyMCMC}, while \citet{garegnani2021NoisyMCMC} studies MCwMH
as an approximation to $\postApproxNormMarg[\Ndesign]$. A variant of MCwMH
is employed in \citet{FerEmulation}.

\paragraph{Expected Acceptance Probability.}
Finally, we consider
\begin{equation}
\postSampleKernel([\Par, \propPar, \postDens^\prime], \cdot)
\Def \mathrm{law}(\postEm[\Ndesign](\Par), \postEm[\Ndesign](\propPar)),
\end{equation}
implying that both density values are re-sampled each iteration, but now from
the joint distribution implied by the surrogate $\postEm[\Ndesign]$. 
We refer to this as the \textit{expected acceptance probability (E-Acc)} approximation,
as it can be viewed as marginalizing the MH acceptance probability with respect
to the surrogate. Indeed, by inserting $\postEm[\Ndesign]$
in place of $\postDens$ in $\accProbMH(\Par, \propPar)$, the surrogate induces a random 
approximation
\begin{equation}
\accProbMHEm[\Ndesign](\Par, \propPar) 
\Def \min\left\{1, \frac{\postEm[\Ndesign](\propPar)\propDens(\propPar, \Par)}{\postEm[\Ndesign](\Par) \propDens(\Par, \propPar)} \right\}
\label{eq:MH-prob-surrogate}
\end{equation}
of the MH acceptance probability. The E-Acc algorithm can thus be viewed as a modification of the
MH scheme in \Cref{alg:MH} with $\E_{\Ndesign}[\accProbMHEm[\Ndesign](\Par, \propPar)]$
replacing $\accProbMH(\Par, \propPar)$. Many of the other posteriors introduced above can also
be viewed as invoking particular approximations of $\accProbMH(\Par, \propPar)$, as summarized
in \Cref{tab:acc-prob-comparison}. \citet{surrogateNoisyMCMC} propose the E-Acc algorithm, 
and explore connections to the expected posterior approximation.

\begin{table}[h]
\centering
\small % (optional) shrink slightly if needed
\renewcommand{\arraystretch}{1.6} % row height
\setlength{\tabcolsep}{10pt} % column separation
\newcolumntype{C}[1]{>{\centering\arraybackslash}m{#1}} % centered column of width #1

\begin{tabular}{lC{10cm}}
\toprule
\textbf{Posterior Approximation} & \textbf{MH Approximation} \\
\midrule
Plug-In Mean & 
\(\displaystyle \min\left\{1, \frac{\Exp{\E[\lpostEm[\Ndesign](\propPar)]}}{\Exp{\E[\lpostEm[\Ndesign](\Par)]}} \right\}\) \\ 
Expected Likelihood & 
\(\displaystyle \min\left\{1, \frac{\E \left[\Exp{\lpostEm[\Ndesign](\propPar)}\right]}{\E\left[\Exp{\lpostEm[\Ndesign](\Par)}\right]} \right\}\) \\
Expected Acc. Prob. & 
\(\displaystyle \E\left[\min\left\{1, \frac{\Exp{\lpostEm[\Ndesign](\propPar)}}{\Exp{\lpostEm[\Ndesign](\Par)}} \right\}\right]\) \\
\bottomrule
\end{tabular}
\caption{The approximations to the Metropolis-Hastings (MH) acceptance probability implied by different posterior approximations using a log-posterior surrogate $\lpostEm[\Ndesign]$. All expectations are with respect to 
the underlying surrogate predictive distribution. For brevity, the acceptance probabilities 
are presented for the case of a symmetric proposal distribution.}
\label{tab:acc-prob-comparison}
\end{table}

\subsection{Existence and Integrability} \label{sec:existence}
We have so far implicitly assumed that the surrogate-induced posterior approximations 
introduced above are well-defined. Consideration of this question points to important 
practical issues in constructing emulators for use in posterior approximation (see
\Cref{sec:recs}). The primary concern
is that the tail behavior of the surrogate may lead to approximations of $\postDens$ that 
are not integrable. Such pathologies can easily arise if utilizing a stationary surrogate, where 
the predictive mean and variance stabilize at constant values as distance from the design points 
increases. This issue is especially a concern if emulating the log-posterior density, as the prior 
density is being modeled and hence cannot be relied upon to ensure integrability \citep{emPostDens}.
Figure \todo illustrates simple examples where such pathologies can occur.
In order to avoid issues related to
tail behavior, previous work tends to restrict to the setting where $\parSpace$
is a compact subset of $\R^{\dimPar}$ \citep{StuartTeck1, VehtariParallelGP}.
Other applications have not directly addressed this issue, but in numerical experiments focus on 
prior distributions with compact support \citep{trainDynamics,FATES_CES} or truncate an unbounded
prior to achieve compact support \citep{gp_surrogates_random_exploration,FerEmulation}. 
\citet{emPostDens} address this issue in depth, describing how the use of stationary log-posterior
surrogates can lead to divergent MCMC chains when performing approximate posterior inference.
Theoretical treatments have also explored conditions to ensure existence over generic unbounded
domains \citep{random_fwd_models,garegnani2021NoisyMCMC}. We refer to 
\citep{StuartTeck1,StuartTeck2} for a comprehensive theoretical treatment in the GP setting.
Ideally, the surrogate ought to be constructed such that every realization of $\postEm[\Ndesign]$
is integrable (i.e., $\normCstEm$ exists almost surely). This assumption is implicit in \Cref{alg:ep}, 
which assumes that each sampled trajectory of $\postEm[\Ndesign]$ induces a valid probability 
distribution from which samples can be drawn. This condition can be weakened for other 
approximations; for example, in \Cref{eq:llik-em-Gaussian} we observe the requirement is that
$\log\left[\priorDens(\Par)\right] + \emMean[\Ndesign]{\llik}(\Par) + \frac{1}{2}\emKer[\Ndesign]{\llik}(\Par)$
decays sufficiently quickly as $\norm{\Par} \to \infty$. 

\section{Sequential Design} \label{sec:seq-design}


The manner in which this tradeoff is navigated depends on the particular problem setup and 
the surrogate model itself. For example, \citet{adaptiveMultimodal} propose an active learning strategy 
targeting multimodal posteriors. Another promising line of research consists of adapting local approximations, 
avoiding the challenging task of fitting a single global surrogate \citep{Li_2014,ConradLocalExactMCMC}. 

\subsection{Sequential Design Loop}
Given a current surrogate fit to design inputs $\designIn[\Ndesign] \in \parSpace^{\Ndesign}$,
our goal is to select a new batch of inputs $\designBatchIn \in \parSpace^{\Nbatch}$
to form the augmented design $\designIn[\Naugment] \Def \designIn[\Ndesign] \cup \designBatchIn$.
After running the simulator at the new points $\designBatchIn$ and updating the emulator, we obtain
an updated posterior surrogate $\postEm[\Naugment]$. We therefore seek to select $\designBatchIn$
to yield the best possible improvement in the approximate posterior, which is naturally cast as 
an optimization problem with respect to some objective function $\acq[]: \parSpace^{\Nbatch} \to \R$, typically
called the \textit{acquisition function} or \textit{design criterion}:
\begin{equation}
\designBatchIn \in \argmin_{\parMat \in \parSpace^{\Nbatch}} \acq[](\parMat).
\label{eq:acq-opt}
\end{equation}
Depending on computational resources, this optimization can be repeated over a sequence of 
$\Nrounds$ rounds, yielding the sequential design loop summarized in \Cref{alg:seq-des-loop}.

We state the algorithm for a generic probabilistic model $\funcPrior$. 
This model is first fit to an initial design $\{\designIn[\Ndesign], \func(\designIn[\Ndesign])\}$ and then 
updated at each iteration $\designIndex$ by augmenting the existing design with newly 
acquired points $\{\designBatchIn^{(\designIndex)}, \func(\designBatchIn^{(\designIndex)})\}$.
\footnote{One could of course consider varying the batch size $\Nbatch$ across the $\Ndesign$ iterations but to simplify notation
we keep $\Nbatch$ constant.}
For GPs, these updates involve conditioning and potentially also re-fitting hyperparameters. 
The special case $\Nbatch = 1$ corresponds to the 
pure sequential design setting in which the function $\func$ is evaluated at each acquired point before
considering the subsequent acquisition. The more challenging batch sequential design setting
$\Nbatch > 1$ requires selection of inputs without observing the responses for the other points
in the batch. In practice, batch selection may be a necessity when simulations are costly but can 
be run in parallel. Though it accommodates batch acquisitions, \Cref{alg:seq-des-loop} is
still ``myopic'' in the sense that it disregards the potential for acquisitions in future rounds. 
Non-myopic strategies have been considered
through a dynamic programming lens, though they typically come at the cost of significant 
computational expense \citep{SURThesis, supermartingaleSUR}.

\subsection{Goal-Oriented Acquisition Functions}
We now make \Cref{alg:seq-des-loop} concrete by introducing several acquisition functions
that explicitly target the goal of posterior approximation. We draw a distinction between 
acquisition criteria restricted to the pure sequential ($\Nbatch = 1$) setting
and those naturally defined in the batch setting. It is still possible to perform 
batch acquisition with criteria of the former type, as discussed in \Cref{sec:greedy-opt}.

\subsubsection{Single Point Criteria} \label{sec:acq-single-point}
When optimizing for a single design point, a natural strategy is to simply select the input
where the uncertainty in $\postEm[\Ndesign](\Par)$ is largest. If predictive variance
is used as the measure of uncertainty, this yields the \textit{maximum variance} criterion
\begin{equation}
\acq[](\Par) \Def -\Var_{\Ndesign}[\postEm[\Ndesign](\Par)], \label{eq:acq-maxvar}
\end{equation}
which is negated to align with our convention of minimizing acquisition functions.
Alternative ``maximum uncertainty'' criteria can be defined by changing the measure
of uncertainty (e.g., variance, entropy, interquartile range) and the target quantity
(e.g., $\postEm[\Ndesign]$, $\funcEm[\Ndesign]$). For example, targeting the 
maximum variance of $\funcEm[\Ndesign](\Par)$ yields a classical criterion 
for exploring the parameter space \citep[Section 6.2.1]{gramacy2020surrogates}.
However, this criterion tends not to perform well in the Bayesian inference setting
since it does not take into account the magnitude of the posterior density. 
It may be that $\funcEm[\Ndesign](\Par)$ is highly uncertain, but 
$\postDens(\Par; \funcEm[\Ndesign])$ concentrates on a very small value.  

The predictive variance of $\postEm[\Ndesign](\Par)$
is given in closed-form in \Cref{eq:fwd-em-Gaussian,eq:llik-em-Gaussian} for 
forward model and log-density emulators in the Gaussian settings. For example, 
when $\lpostEm[\Ndesign](\Par) \sim \Gaussian(\emMean[\Ndesign]{\lpost}(\Par), \emKer[\Ndesign]{\lpost}(\Par))$
we have
\begin{equation}
\Var\left[\postEm[\Ndesign](\Par; \lpostEm[\Ndesign])\right] &= 
\left[\Exp{\emKer[\Ndesign]{\lpost}(\Par)} - 1\right] \Exp{2\emMean[\Ndesign]{\lpost}(\Par) + \emKer[\Ndesign]{\lpost}(\Par)},
\end{equation}
which demonstrates that the criterion favors inputs where both the expected log-posterior
$\emMean[\Ndesign]{\lpost}(\Par)$ and epistemic uncertainty $\emKer[\Ndesign]{\lpost}(\Par)$ are large, encoding an exploration-exploitation
tradeoff. The maximum variance criterion is utilized in \citet{Lueckmann2018LikelihoodfreeIW,Kandasamy_2017,AlawiehIterativeGP}. 
In the GP log-density emulator setting (\Cref{eq:llik-em-Gaussian})
$\postEm[\Ndesign](\Par)$ is log-normal. Given the heavy tails and asymmetry of a log-normal random variable, 
\citep{VehtariParallelGP,wang2018adaptive} argue that the variance provides a misleading measure
of uncertainty in this setting, instead favoring the entropy or interquartile range. 
As an alternative to these maximum uncertainty criteria, \citet{gp_surrogates_random_exploration}
suggest explicitly decoupling exploration and exploitation by selecting one point 
that maximizes $\emMean[\Ndesign]{\lpost}(\Par)$ and randomly sampling a second point from 
$\priorDens$. \citet{Takhtaganov2018AdaptiveBayesianGP} employs the expected improvement
criterion from Bayesian optimization to target the placement of new design points in high-posterior regions.

\subsubsection{Multipoint Criteria} \label{sec:acq-multipoint}
We next consider acquisition functions that can be evaluated at batches of multiple inputs. In particular,
we focus on a class of acquisition functions that we call \textit{expected conditional uncertainty (ECU)} 
criteria. Criteria falling within this general class have been explored in various contexts 
\citep{ALC,Roy2001,Mercer_kernels_IVAR,Binois_2018,deepGPAL,
ALExpErrReduction,parallelSURExcursionSet,SurerStochasticIVAR}
\footnote{Many names have been used for such criteria, including \textit{expected error reduction}, 
\textit{active learning Cohn}, \textit{integrated mean squared prediction error}, \textit{integrated variance}, 
and generically \textit{integral criteria}.},
but we focus on examples geared specifically towards surrogate-induced posterior approximation.

ECU acquisitions arise from the following logic: we would like to select an input batch 
$\parMat \in \parSpace^{\Nbatch}$ that induces an updated surrogate $\postEm[\Naugment]$ with the largest 
possible reduction in uncertainty on average over $\parSpace$. This uncertainty reduction is not, in general,
computable without observing the response $\func(\parMat)$. However, it can be approximated by modeling
$\func(\parMat)$ as a random vector $\gamma \sim \mathrm{law}(\funcEm[\Ndesign](\parMat))$. Let
$\funcEm[\Naugment]^{\parMat,\gamma} \Def \funcEm[\Ndesign] \given [\funcEm[\Ndesign](\parMat) = \gamma]$
denote $\funcEm[\Ndesign]$ conditioned on new data $\{\parMat, \gamma\}$. In computing ECU, we marginalize
over $\gamma$ in addition to averaging over $\parSpace$. If we again choose variance as our measure of 
uncertainty, we have
\begin{equation}
\acq[](\parMat) \Def 
\int_{\parSpace} \E_{\gamma} \left\{\Var_{\Naugment}[\postDens(\Par; \funcEm[\Naugment]^{\parMat,\gamma}) \given \gamma]\right\} \ \weightDens(\Par) d\Par,
 \label{eq:acq-intvar}
\end{equation}
where $\weightDens$ is a measure on $\parSpace$ that we are free to choose.
Notice that in contrast to the pointwise 
criteria, ECU acquisition functions are ``global'' in that they account for the effect of the 
new batch $\parMat$ on the surrogate uncertainty over the entire space $\parSpace$. Variations of 
ECU criteria can be created by changing the measure of uncertainty (e.g., variance, entropy, interquartile range),
the target quantity (e.g., $\postEm$, $\lpostEm$, $\funcEm$), and the weighting measure $\weightDens$.
For example, targeting the variance of $\funcEm$ with uniform weighting measure yields the
classical integrated mean squared prediction error \citep{Mercer_kernels_IVAR}.

Outside of special cases \citep{Binois_2018,MakTargetedVar,Koermer2024} the outer integral (over $\parSpace$) 
in ECU criteria is not tractable. This is especially the case in our present setting,
and thus we focus on the sample average approximation \citep{Mercer_kernels_IVAR,botorch},
\begin{align}
&\acq[](\parMat) \Def \frac{1}{J}
\sum_{j=1}^{J} \E_{\gamma} \left\{\Var_{\Naugment}[\postDens(\Par_j; \funcEm[\Naugment]^{\parMat,\gamma}) \given \gamma]\right\},
&&\Par_j \overset{\mathrm{iid}}{\sim} \weightDens[\Ndesign].
 \label{eq:acq-intvar-saa}
\end{align}
The $\Par_j$ are sampled at the beginning of the sequential design round and then fixed, so that
\Cref{eq:acq-intvar-saa} is viewed as a deterministic objective function. 
The expected variance terms in the summands admit closed forms in the Gaussian 
settings of \Cref{eq:fwd-em-Gaussian,eq:llik-em-Gaussian}, as shown below. As an alternative to 
\Cref{eq:acq-intvar-saa}, we can consider an ECU criterion that targets uncertainty in the underlying
emulator $\funcEm[\Ndesign]$, but acknowledges the goal of posterior approximation through the choice
of $\weightDens[\Ndesign]$; i.e., 
\begin{align}
&\acq[](\parMat) \Def \frac{1}{J}
\sum_{j=1}^{J} \Var_{\Naugment}[\funcEm[\Naugment](\Par_j)],
&&\Par_j \overset{\mathrm{iid}}{\sim} \postNormEm[\Ndesign]^{\mathrm{approx}},
 \label{eq:acq-intvar-lartaud-saa}
\end{align}
where $\postNormEm^{\mathrm{approx}}$ is any of the approximate posteriors from \Cref{sec:post-approx}.
An acquisition function of this form is proposed in \citet{weightedIVAR}, and compares 
favorably against \Cref{eq:acq-intvar-saa}.

\begin{examplebox}[Gaussian Forward Model Emulation Setting]
In the Gaussian forward model emulation setting from \Cref{eq:fwd-em-Gaussian-post,eq:fwd-em-Gaussian}, 
the ECU-variance criterion in \Cref{eq:acq-intvar-saa} reduces to
\begin{align}
\acq[](\parMat) &= \frac{1}{J}
\sum_{j=1}^{J} \priorDens^2(\Par_j) \bigg[\frac{\Gaussian\left(\obs \given \emMean{\fwd}(\Par_j), \CovComb(\Par_j) - \frac{1}{2}\likPar \right)}{2^{\dimObs/2} \det(2\pi \likPar)^{1/2}} - \label{eq:acq-intvar-saa-fwd} \\
&\qquad\qquad \frac{\Gaussian\left(\obs \given \emMean{\fwd}(\Par_j), \CovComb(\Par_j) - \frac{1}{2}\CovComb[\Naugment](\Par_j) \right)}{2^{\dimObs/2} \det(2\pi \CovComb[\Naugment](\Par_j))^{1/2}} \bigg], \nonumber
\end{align}
where $\CovComb(\Par) \Def \likPar + \emKer{\fwd}(\Par)$ and $\CovComb[\Naugment](\Par) \Def \likPar + \emKer[\Naugment]{\fwd}(\Par)$.  
\citet{SinsbeckNowak} are the first to propose an ECU-variance criterion in the forward model emulation setting,
and briefly note the above closed-form expression in the Gaussian special case.
\citet{Surer2023sequential} also derive this expression, but in the particular case of the multi-output basis vector model
in \Cref{basis_func_model}.

\citet{weightedIVAR} consider an alternative ECU-variance criterion in the Gaussian forward model emulator setting:
\begin{align}
&\acq[](\parMat) \Def \frac{1}{J}
\sum_{j=1}^{J} \emKer[\Naugment]{\fwd}(\Par_j),
&&\Par_j \sim \postApproxNormMarg.
 \label{eq:acq-intvar-lartaud}
\end{align}
The summands target uncertainty in $\fwdEm[\Ndesign]$ rather than $\postEm[\Ndesign]$, while the weighting measure
$\weightDens = \postApproxNormMarg$ is chosen to target the goal of posterior approximation. This has the 
benefit of being much easier to compute, since the GP variance $\emKer[\Naugment]{\fwd}(\Par)$ is independent of the 
unseen response $\fwd(\parMat)$. \citet{weightedIVAR} establish asymptotic convergence results for this criterion
using the stepwise uncertainty reduction framework \citep{BectSUR}. 
\end{examplebox}

\begin{examplebox}[Gaussian Log-Density Emulation Setting]
Consider the Gaussian log-density emulation setting from \Cref{eq:llik-em-Gaussian}
with a log-likelihood emulator. With this setup, the ECU-variance criterion in 
\Cref{eq:acq-intvar-saa} reduces to
\begin{equation}
\acq[](\parMat) = \frac{1}{J}
\sum_{j=1}^{J} \Var\left[\postEm(\Par_j) \given \llikEm(\parMat) = \emMean[\Ndesign]{\llik}(\parMat) \right] \varInflation_{\Ndesign}(\Par_j; \parMat)   
\label{eq:acq-intvar-saa-ldens}
\end{equation}
where
\begin{align*}
\Var\left[\postEm(\Par) \given \llikEm(\parMat) = \emMean[\Ndesign]{\llik}(\parMat) \right]
&= \priorDens(\Par)^2 \Exp{2\emMean[\Ndesign]{\llik}\left(\Par\right) + \emKer[\Naugment]{\llik}(\Par)} \cdot \\
&\qquad\qquad\qquad \left[\Exp{\emKer[\Naugment]{\llik}(\Par)} - 1 \right] \\
\varInflation_{\Ndesign}(\Par; \parMat)
&= \Exp{2\left(\emKer[\Ndesign]{\llik}(\Par) - \emKer[\Naugment]{\llik}(\Par)\right)}.
\end{align*}

Notice that the first term in \Cref{eq:acq-intvar-saa-ldens} is the variance of $\postEm[\Ndesign](\Par_j)$ conditioned on
$\{\parMat, \emMean[\Ndesign]{\llik}(\parMat)\}$; i.e., the current GP prediction is treated as if it were the true response.
The second term accounts for the uncertainty in the true response; in particular, the penalty
$\emKer[\Ndesign]{\llik}(\Par) - \emKer[\Naugment]{\llik}(\Par)$ is large when the input batch $\parMat$ is highly 
``influential.''

\Cref{eq:acq-intvar-saa-ldens} is derived in \citet{VehtariParallelGP}, but the authors ultimately recommend
an alternative criterion that uses the interquartile range in place of the variance. The interquartile range
is more robust to the heavy tails of the log-normal predictive distribution, a benefit that translates to 
improved empirical performance in their experiments.
\end{examplebox}

\subsection{Batch Design Strategies}
When simulation cost is high but runs can be parallelized, batch acquisition is often essential. For example, in large-scale
geoscience applications the batch size may be in the hundreds ($\Nbatch \approx 100$), with only a few rounds 
of acquisition possible ($\Nrounds < 10$) \citep{FerEmulation}. This is in stark contrast to much of the sequential 
design literature, which focuses on the behavior of single-point acquisition algorithms as $\Nrounds$ grows large.
The challenge of batch acquisition has gained interest in the active learning and Bayesian 
optimization literature \citep{Ginsbourger2010,LOEPPKY20101452,Chevalier2013,batchBOThesis}. We begin 
by highlighting ideas from this broader literature, and then discuss some promising approaches
well-suited to the particular goal of posterior approximation.

\subsubsection{Joint Optimization}
The task of minimizing $\acq[](\parMat)$ requires an optimization over $\dimPar\Nbatch$ variables, and is thus
difficult to scale as the parameter dimension or batch size increases. \citet{Mercer_kernels_IVAR} investigate
the performance of gradient-based continuous optimization over $\parSpace^\Nbatch$ for integrated variance
criteria, demonstrating favorable performance for small values of $\dimPar$ and $\Nbatch$. 
\citep{botorch} describes the gradient-based optimization framework using sample average approximations
implemented in the \verb+BoTorch+ package. A large portion of the literature eschews continuous optimization in 
favor of discrete methods. These algorithms take the form of a subset selection problem; the optimal batch
is sought from within a finite set of candidate points $\parMatCand \subset \parSpace$. This presents a 
challenging combinatorial optimization problem, commonly solved by employing stochastic exchange 
algorithms (i.e., Federov exchange) to find a local minimum \citep{FederovExchange,WynnDiscreteExchange,LOEPPKY20101452}
\footnote{Exchange algorithms can also be employed to optimize over continuous space and leverage gradient information.}.

\subsubsection{Greedy Optimization} \label{sec:greedy-opt}
Motivated by the difficulty of joint optimization, greedy approximations are common in practice \citep{Ginsbourger2010}.
These methods seek to approximate the joint optimum using a sequence of $\Nbatch$ simpler optimization 
problems over $\parSpace$. Under this approach, at the beginning of round $\designIndex$ the first 
point in the batch $\Par^{(\designIndex,1)}$ is selected by optimizing $\acq[]^{(\designIndex)}(\Par)$ as 
in the pure sequential design setting. The remaining $\Nbatch - 1$ points are added sequentially via
\begin{align}
&\Par^{(\designIndex, b)} \Def \argmin_{\Par \in \parSpace} \acq[]^{(\designIndex,b)}(\parMat^{(\designIndex,1:b-1)} \cup \{\Par\}),
&&b = 2, \dots, \Nbatch. 
\label{eq:greedy-acq-opt}
\end{align}
In pure sequential design, the acquisition function changes every iteration owing to the addition of a new
observation $(\Par, \func(\Par))$. Greedy batch design differs in that the criterion is updated to reflect
the new input $\Par$ only, as we do not observe $\func(\Par)$ until the entire batch is acquired.
The superscript in $\acq[]^{(\designIndex,b)}$ indicates that the objective is approximated to account for
these unobserved responses. \citep{Ginsbourger2010} introduce several heuristics for this approximation.
At each iteration, the \textit{Kriging believer} strategy updates the surrogate with a pseudo-observation;
the current emulator predictive mean is used in place of the truth $\func(\Par^{(\designIndex, b)})$.
Believing the surrogate prediction over a sequence of iterations can be problematic, so the popular 
\textit{constant liar} alternative consists of fixing the pseudo-observation to a constant value throughout the 
entire round. \citep{Ginsbourger2010} refer to this constant value as a ``lie'' and investigate the empirical 
performance of different choices for the lie. A related alternative consists of using the predictive mean of 
$\funcEm[\Ndesign]$ to generate the pseudo-observation over the course of the round, rather than using the 
updated predictive mean function after each iteration as in the Kriging believer approach \citep{VehtariParallelGP}.
Both \citep{VehtariParallelGP,Surer2023sequential} consider such greedy heuristics in the context of
solving a Bayesian inverse problem.

An unappealing aspect of the greedy approach is that the potential for batch acquisitions to assess within-batch
interactions is not fully leveraged. In order to make better use of a batch acquisition, one idea consists of generating
multiple candidate batches of points and then using the batch criterion to select among the competitors. This is
exemplified by the \textit{constant liar mix} strategy, where the candidate batches are generated using the constant
liar heuristic with different choices of the lie \citep{Chevalier2013}.
Finally, note that since the optimization in \Cref{eq:greedy-acq-opt} proceeds one point at a time then the single point criteria
in \Cref{sec:acq-single-point} can be combined with greedy heuristics to enable batch optimization (e.g., \citet{VehtariParallelGP}).

\subsubsection{Sampling-Based Approaches}
The batch design methods discussed above are generic active learning techniques, not unique to our particular
context. However, the specific goal of posterior approximation suggests a natural alternative: select the batch by sampling from the 
current approximate posterior. \citep{hydrologicalModel,quantileApprox} both adopt this strategy.
\citet{FerEmulation} instead sample from a mixture of the current approximate posterior and the prior, with the mixture weights 
representing a user-defined tuning parameter. \citet{turbulenceModelAdaptiveLHS} considers a 
similar prior-posterior mixture, with a latin hypercube adjustment to encourage the new design 
points to be spread out. 
\citet{adaptiveMultimodal} samples from the current approximate posterior, and
then updates these samples with an iteration of an ensemble Kalman algorithm; this method is 
closely related to the \textit{calibrate, emulate, sample} workflow \citep{CES}.
\citet{hydrologicalModel2} consider a similar strategy, using parameters sampled from an MCMC
proposal as additional design points.

These sampling-based approaches enjoy the practical benefits of being inherently parallel and not requiring the solution
of a difficult optimization problem. In this sense, they are similar in spirit to Thompson sampling for
batch Bayesian optimization \citep{parallelBOThompson}. We conjecture that such approaches may be superior to 
alternatives in the large $\Nbatch$, small $\Nrounds$ setting. We expect the performance of this approach to be closely 
tied to the choice of approximate posterior; e.g., samples from the plug-in mean posterior will likely under-explore the 
parameter space. The \citet{FerEmulation} approach of sampling from a mixture of the prior and approximate posterior might
be viewed as a more scalable analog of the method in \citet{gp_surrogates_random_exploration}, in the sense of 
explicitly decoupling exploration and exploitation. We believe further work is warranted to better understand the 
behavior of these methods, and their applicability to large-scale batch design.

\subsection{Adaptive Local Surrogates}
Local in the sense of only using design points in region of high posterior: \citep{hydrologicalModel2}
Tempering approaches: \citep{JosephMEDSampling,Li_2014}


\subsection{Exact-Approximate MCMC}
Throughout this section, we have framed the question of surrogate refinement through a standard active 
learning lens, in which the selection of design points proceeds over a sequence of rounds. We briefly
highlight related methods that stray from this framework; in particular, algorithms that 
perform sequential design within a single MCMC run, often with the goal of converging 
to the true target $\postDensNorm$. Such methods are sometimes referred to as \textit{exact-approximate}
MCMC. The papers \citet{Li_2014,ConradLocalExactMCMC} 
adaptively construct local polynomial surrogates within an MCMC algorithm, and are able to establish asymptotic 
exactness by showing the polynomial approximation error diminishes over time.
\citep{ActiveLearningMCMC}
also conduct sequential design within a MCMC run, using emulator predictions at points where the 
surrogate is confident, and running exact simulations at points that exceed a user-defined uncertainty tolerance.
We note that it is possible to ensure convergence to $\postDensNorm$ even with a fixed surrogate
by using the surrogate predictions to filter out poor proposals, avoiding the cost of unnecessary 
expensive model runs. This idea dates back to the delayed acceptance mechanism of \citep{DelayedAcceptance}
for Metropolis-Hastings algorithms.
In \citet{MCMC_GP_proposal}, a similar approach is used to accelerate Hamiltonian Monte Carlo.
These algorithms all leverage a surrogate in various ways with the goal of reducing the simulation load, while
maintaining asymptotic exactness. The cost of exactness is the requirement of more simulator runs, often 
performed serially. We therefore view such approaches as well-suited to inverse problems with moderately 
expensive forward models. Convergence to $\postDensNorm$ will typically be impractical as the computational
costs increase, especially in the large $\Nbatch$, small $\Nrounds$ setting.

\todo: add references;
Design within MCMC but not asymptotically exact: \citep{hydrologicalModel2}


\section{Practical Recommendations} \label{sec:recs}
We now provide a set of practical recommendations for building surrogate models, constructing
posterior approximations, and sequentially refining the surrogate. \Cref{sec:case-study}
highlights these recommendations through a numerical case study.

\begin{rec} \label{rec:prop-uncertainty}
The choice of surrogate model and uncertainty propagation method should be conducted jointly.
\end{rec}

In general, we emphasize the importance of propagating surrogate uncertainty in 
the posterior approximation, but are not convinced of a single ``correct'' uncertainty 
propagation method. Instead we find a few different approaches to be reasonable, but
emphasize that the empirical success of any particular method will be closely tied to the
surrogate model itself. The expected posterior approximation is conceptually appealing
as a direct summary of the random posterior $\postNormEm[\Ndesign]$, but is often 
challenging to implement and computationally expensive. 
Therefore, we tend to prefer the noisy MCMC methods defined in \Cref{sec:MH-approx},
which show empirical promise, require only a single MCMC run, and are applicable to 
generic probabilistic surrogates.
However, in choosing these methods one needs to appreciate how the behavior of the posterior
approximation will vary based on the properties of the surrogate predictive distribution.
For example, in log-density emulation the expected likelihood approximation can concentrate in very 
small regions of parameter space where the surrogate is uncertain, in which case a pseudo-marginal 
MCMC run will almost certainly fail. However, in this case we have found that the simple adjustment 
of incorporating a bound constraint in the emulator can solve this problem and produce reasonable 
results. Alternatively, the E-acc method tends to be more robust with respect to 
heavy-tailed surrogate predictions, but requires stronger requirements to ensure 
existence (\Cref{sec:existence}). 

\begin{rec} \label{rec:multiscale}
Treat density emulation as a multiscale problem.
\end{rec}

In many applications, it is common for log-likelihoods and log-posteriors to exhibit various
properties that render log-density emulation a challenging task. They tend to have very 
large dynamic ranges over the support of the prior distribution, even when their range 
may be relatively small over the posterior support. In addition, their values may drop sharply 
in certain directions while asymptoting in others. In general, we find that traditional stationary 
surrogates perform quite poorly in approximating such response surfaces.
\todo: finish this recommendation

\begin{rec} \label{rec:oversample-tails}
The design should oversample the tails.
\end{rec}
As discussed in \Cref{sec:seq-design}, it is natural to aim to place design points in regions
where $\postDensNorm(\Par)$ is large. However, it is often critical to also include sufficient
points in regions where $\postDensNorm(\Par)$ is small, and at least initially, where 
$\priorDens(\Par)$ is small as well. Intuitively, such points are required to 
learn the global trend of the response surface (see \Cref{rec:multiscale}) and to ``pin down''
regions of negligible posterior mass. In constructing the initial design, we often find it helpful
to sample design points from an over-dispersed version of $\priorDens$. In the 
case study in \Cref{sec:case-study} we sample the initial design from the prior, but also
explicitly include additional points in the tails of the prior. We also suggest that sequential
acquisition schemes are designed to ensure sufficient exploration. This can be encoded
in an acquisition function (e.g., via the choice of $\weightDens[\Ndesign]$ in \Cref{eq:acq-intvar})
or via the explicit selection of exploratory points \citep{gp_surrogates_random_exploration}.  
For example, at each active learning iteration \citet{gp_surrogates_random_exploration,FerEmulation}. 
We note that these recommendations are in line with the theoretical results of \citet{StuartTeck2}, who 
suggest designs based on an over-dispersed version of $\postDensNorm(\Par)$.
The notion of oversampling the tails has also been proposed to construct designs
for numerical integration \citep{briol2017sampling}.

\begin{rec} \label{rec:pred-check-tails}
Conduct goal-oriented predictive checks of the induced posterior density surrogate.
\end{rec}
As discussed in \Cref{sec:existence}, one must take care in designing emulators that
induce well-defined posterior approximations. In MCMC-based inference, this is crucial for
avoiding divergent MCMC chains. \Cref{rec:multiscale,rec:oversample-tails}
offer modeling suggestions to help avoid such issues, but they do not provide certified 
guarantees. We suggest an explicit prior predictive check to diagnose problematic 
tail behavior in the induced posterior surrogate $\postEm[\Ndesign]$. A simple graphical
check consists of plotting an upper quantile of $\mathrm{law}(\lpostEm[\Nesign](\Par))$ 
as $\Par$ varies over the parameter space. One should ensure that $\Par$ is allowed to 
vary well past the extent of the design points in order to assess the extrapolation behavior 
of the surrogate. A high quantile (say, 95\% or 99\%) is chosen to assess whether 
the distribution of $\lpostEm[\Ndesign](\Par)$ appears to be converging almost surely 
to $-\infty$ in the limit. For multidimensional input spaces we suggest varying one 
parameter at a time, projecting onto different fixed values of the other parameters.
Performing this simple check does not require any additional 
evaluations of the expensive simulator, and can prevent wasting resources by having
to wait to uncover issues with the surrogate during inference (for example, 
\citet{emPostDens} use divergent MCMC chains as a sort of surrogate diagnostic check).
 See \Cref{fig:vsem-prior-check-lpostem} in the below case study for an example
 of this predictive check.

\begin{rec} \label{rec:bound-constraints}
Enforce bound constraints.
\end{rec}

\todo: Recommend rectified adjustment.

\begin{rec} \label{rec:multimodal-post-approx}
Embrace multi-modal posterior approximations.
\end{rec}

In utilizing a flexible statistical model to approximate a complex response surface, one expects
the approximation to feature local modes. Given that the surface corresponds to a
log-posterior density in this setting, it is natural to anticipate that even a deterministic emulator
may induce multimodal posterior approximations, even when the true posterior is unimodal. 
Multimodality is even more common when propagating surrogate uncertainty, as the uncertainty 
level will vary over the input space (e.g., consider the ``sausage-shaped'' confidence 
bands in \Cref{fig:em_dist_1d}). For example, modes in the approximate posterior may reflect
that the surrogate expects high posterior mass in a certain region, or that the surrogate is simply 
uncertain in the region. This uncertainty quantification is essential for acknowledging surrogate 
inadequacies and for guiding future improvements (\Cref{sec:seq-design}). However, it does
present computational challenges in performing inference. While specialized algorithms 
can be employed \citep{adaptiveMultimodal}, we typically prefer practical heuristic approaches
in the spirit of \citep{multimodalYao}. In particular, we run multiple MCMC chains in parallel with 
the aim of characterizing the dominant modes of the distribution. We perform within-chain 
convergence diagnostics to validate that the chains are well-mixed locally, and then 
utilize heuristics to assign weights to each chain.

\vspace

\todo: Add active learning recommendation

\section{Numerical Case Study} \label{sec:case-study}
We present a numerical illustration of a surrogate-assisted Bayesian inference workflow, highlighting
the practical recommendations given in the previous section.
Our illustrative example is motivated by the problem of producing near-term forecasts of the 
terrestrial carbon cycle \citep{nearTermForecasts,FerEmulation}. In this setting, both model parameters 
and initial conditions are typically unknown and must be learned from observational data. Performing 
such parameter estimation runs into computational challenges for large-scale land surface models, 
underscoring the potential for surrogates in this domain \citep{paramLSM}. 

\subsection{Model Setup}
We start by introducing the mechanistic simulator model, and then define a Bayesian inverse 
problem with respect to this model.

\subsubsection{Mechanistic Model}
As a simple concrete example, we utilize the \textit{Very Simple Ecosystem Model} (VSEM), a toy model capturing the basic 
structure of more complex land surface models, thus ideally suited for algorithm evaluation \citep{vsem}. The model 
describes the evolution of the state vector
\begin{align*}
\state(\Time) \Def [\stateV(\Time), \stateR(\Time), \stateS(\Time)]^\top \in \R_{\geq 0}^{3}, 
\end{align*}
with the state variables representing the quantity of carbon (\textrm{kg C/$m^2$}) in above-ground vegetation, below-ground 
vegetation (roots), and soil reservoirs, respectively. The VSEM model is given by the system of coupled 
ordinary differential equations
\begin{align}
\dstateV(\Time) &= \alphaV \NPP(\stateV(\Time), \forcing(\Time)) - \frac{\stateV(\Time)}{\tauV} \\
\dstateR(\Time) &= (1.0 - \alphaV) \NPP(\stateV(\Time), \forcing(\Time)) - \frac{\stateR(\Time)}{\tauR} \nonumber \\ 
\dstateS(\Time) &= \frac{\stateR(\Time)}{\tauR} + \frac{\stateV(\Time)}{\tauV} - \frac{\stateS(\Time)}{\tauS}, \nonumber
\end{align}
where the model forcing $\forcing(\Time)$ is provided by photosynthetically active radiation 
(\textrm{MJ/$m^2$/day}), and the dynamics rely on the following parameterized model of 
Net Primary Productivity (NPP; \textrm{kg C/$m^2$/day}),
\begin{align}
\NPP(\stateV, \forcing) &= (1 - \fracRespiration) \GPP(\stateV, \forcing) \\
\GPP(\stateV, \forcing) &= \forcing \cdot \LUE \cdot \left[1 - \exp\left\{-\KEXT \cdot \LAI(\stateV) \right\} \right] \nonumber \\
\LAI(\stateV) &= \LAR \cdot \stateV, \nonumber
\end{align} 
where $\GPP(\stateV, \forcing)$ and $\LAI(\stateV)$ model Gross Primary Productivity (GPP; \textrm{kg C/$m^2$/day})
and Leaf Area Index (LAI; \textrm{$m^2/m^2$}), respectively.
Note that the ODE is of the form \ref{ode_ivp}, with the caveat that the dynamics $\odeRHS$ additionally depend on a 
time-dependent forcing $\forcing(\Time)$. Given a value of $\Par$, we numerically solve the ODE at a daily time step
via the basic Euler scheme implemented in the R \verb+BayesianTools+ package \citep{vsem}. We recall the discretized 
parameter-to-state map 
$\solutionOp: \Par \mapsto \left[\indexTime[0]{\state}(\Par), \dots, \indexTime[\NTimeStep]{\state}(\Par) \right]^\top$, 
as defined in \Cref{eq:ode-solution-op}.

Potential calibration parameters in this model include 
$\{\alphaV, \tauV, \tauR, \tauS, \LUE, \KEXT, \fracRespiration, \LAR\}$, as well as the initial conditions for the three state
variables $\{\stateV(0), \stateR(0), \stateS(0)\}$.
Noting that the model is over-parameterized, we will focus on estimating 
$\Par \Def \{\KEXT, \fracRespiration, \tauV, \stateV(0)\}$ with the remaining parameters held fixed.

\subsubsection{Statistical Model}
We consider estimating the parameters $\Par$ given noisy monthly averages of LAI over a two year period.
We assume an additive Gaussian noise model
\begin{align}
\obs &= \fwd(\Par) + \noise \label{eq:vsem-inv-prob} \\
\noise &\sim \Gaussian(0, \sigma^2 I) \nonumber 
\end{align}
where $\fwd: \parSpace \to \R^{24}$ maps to the twenty-four LAI averages; i.e., the first entry of $\fwd(\Par)$
is given by 
\begin{equation}
\fwd_{1}(\Par) \Def \frac{\LAR}{30} \sum_{\timeIndex=1}^{30} \state_{\textrm{v},\timeIndex}(\Par),
\end{equation}
and the remaining entries simply change the indices of the summation. For simplicity, we fix $\sigma^2$
and assume a priori independence over the entries of $\Par$. Synthetic data $\obs$ is simulated
using \Cref{eq:vsem-inv-prob} with fixed ground truth values $\{\Par_{\star}, \sigma^2_{\star}\}$. The same 
model is used when solving the inverse problem, but the values of the fixed parameters (those not
being estimated) and the noise variance are changed, implying the presence of parametric misspecification.
Table \todo compares these misspecified values relative to the ground truth, while
table \todo summarizes the prior distribution $\Par \sim \priorDens$. As a baseline for comparison, we 
draw samples from the posterior using exact MCMC. \Cref{fig:vsem_prior_post} compares the prior 
and posterior marginal distributions, while \Cref{fig:vsem_pred_dists} compares the prior and 
posterior predictive distributions over LAI trajectories.

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.24\textwidth} % Cv 
         \centering
         \includegraphics[width=\textwidth]{{vsem/prior_post_par_Cv.png}}
         \caption{$\stateV(0)$}
         \label{fig:vsem_prior_post_Cv}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.24\textwidth} % GAMMA
         \centering
         \includegraphics[width=\textwidth]{{vsem/prior_post_par_GAMMA.png}}
         \caption{$\gamma$}
         \label{fig:vsem_prior_post_GAMMA}
     \end{subfigure}
      \begin{subfigure}[b]{0.24\textwidth} % tauV
         \centering
         \includegraphics[width=\textwidth]{{vsem/prior_post_par_tauV.png}}
         \caption{$\tauV$}
         \label{fig:vsem_prior_post_tauV}
     \end{subfigure}
          \begin{subfigure}[b]{0.24\textwidth} % KEXT
         \centering
         \includegraphics[width=\textwidth]{{vsem/prior_post_par_KEXT.png}}
         \caption{$\KEXT$}
         \label{fig:vsem_prior_post_KEXT}
     \end{subfigure}
        \caption{Marginal prior (black dashed) and exact posterior (red) distributions for the four
        calibration parameters.}
        \label{fig:vsem_prior_post}
\end{figure}


\begin{figure}
     \centering
     \begin{subfigure}[b]{0.48\textwidth} % Prior predictive distribution
         \centering
         \includegraphics[width=\textwidth]{{vsem/prior_pred_dist.png}}
         \caption{Prior Predictive}
         \label{fig:vsem_prior_pred}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.48\textwidth} % Posterior predictive distribution
         \centering
         \includegraphics[width=\textwidth]{{vsem/post_pred_dist.png}}
         \caption{Posterior Predictive}
         \label{fig:vsem_post_pred}
     \end{subfigure}
        \caption{(Left) The distribution over LAI trajectories induced by $\Par \sim \priorDens$. 
        The red points are the observed noisy observations of monthly LAI averages, with the 
        vertical bars indicating $\pm \sigma$ observation noise. The blue shaded region captures 
        90\% prior predictive probability. The gray lines are prior predictive samples, and the black 
        line is the ground truth LAI trajectory used to generate the data. (Right) The analogous plot
        for the posterior predictive distribution; i.e., the distribution over LAI trajectories induced 
        by $\Par \sim \postDens$.}
        \label{fig:vsem_pred_dists}
\end{figure}

\subsection{Initial Surrogate Fits}
For this problem, we compare GP emulators for both the forward model and log-posterior.
Let $\funcEm[\Ndesign]$ denote the underlying GP prediction of $\func$.
To evaluate these emulators we consider both prior and posterior averaged continuous
ranked probability score (CRPS; \citep{scoringRules})
\begin{align}
\mathrm{crps}(\funcEm[\Ndesign]) &\Def \int_{\parSpace} \mathrm{crps}(\funcEm[\Ndesign](\Par), \func(\Par)) \weightDens[](\Par) d\Par
\end{align}
and multivariate log-score (i.e., predictive deviance; \citep{scoringRules})
\begin{align}
\mathrm{logS}(\funcEm[\Ndesign]) 
&\Def \log \Gaussian(\func(\parMat) \given \emMean[\Ndesign]{}(\parMat), \emKer[\Ndesign]{}(\parMat)),
&&\parMat \overset{\mathrm{iid}}{\sim} \weightDens[].
\end{align}

The choice $\weightDens[] \in \{\priorDens, \postDensNorm\}$ determines whether error is assessed with
respect to the prior or true posterior; both scores are approximated by sampling $1000$ points 
from the relevant distribution. We similarly estimate 
\begin{align}
\mathrm{mae}(\postEm[\Ndesign]) &\Def 
\int_{\parSpace} \abs{\postApproxMean[\Ndesign](\Par) - \postDens(\Par)} \weightDens[](\Par) d\Par,
\end{align}
to evaluate the quality of the plug-in mean posterior approximation.

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.49\textwidth} % lpost em, prior evaluation
         \centering
         \includegraphics[width=\textwidth]{{vsem/pred_scatter_prior_lpostem.png}}
         \caption{$\lpostEm[\Ndesign], \weightDens[] = \priorDens$}
         \label{fig:vsem_pred_scatter_prior_lpostem}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth} % lpost em, posterior evaluation
         \centering
         \includegraphics[width=\textwidth]{{vsem/pred_scatter_post_lpostem.png}}
         \caption{$\lpostEm[\Ndesign], \weightDens[] = \postDensNorm$}
         \label{fig:vsem_pred_scatter_post_lpostem}
     \end{subfigure}
          \begin{subfigure}[b]{0.49\textwidth} % fwd em, prior evaluation
         \centering
         \includegraphics[width=\textwidth]{{vsem/pred_scatter_prior_lpostem.png}}
         \caption{$\fwdEm[\Ndesign], \weightDens[] = \priorDens$}
         \label{fig:vsem_pred_scatter_prior_fwdem}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth} % fwd em, posterior evaluation
         \centering
         \includegraphics[width=\textwidth]{{vsem/pred_scatter_post_lpostem.png}}
         \caption{$\fwdEm[\Ndesign], \weightDens[] = \postDensNorm$}
         \label{fig:vsem_pred_scatter_post_fwdem}
     \end{subfigure}
        \caption{Emulator predictions based on the initial design. The top and bottom rows correspond
        to the forward model and log-posterior emulator, respectively. The left and right columns correspond
        to evaluation inputs sampled from the prior and exact posterior, respectively. The points summarize
        emulator mean predictions, while vertical bars are 90\% emulator predictive intervals. The orange 
        bars indicate that the 90\% interval does not contain the truth.}
        \label{fig:vsem_pred_scatter}
\end{figure}

\subsubsection{Forward Model Emulator}
\subsubsection{Log-Posterior Emulator} \label{sec:case-study-lpost-em}
This inverse problem presents several challenges for log-density emulators: the dynamic 
range of the log-likelihood over the prior support is quite large, the parameter space is 
unbounded, and the likelihood remains relatively flat along certain directions in parameter
space. One must therefore take care to control the tails of the emulator in order to produce well-defined
posterior approximations. This situation is not uncommon in applications, as it may simply reflect the 
fact that the simulator predictions asymptote in certain directions of parameter space. 
In general, we find a stationary GP performs quite poorly in such contexts. One could argue that 
the placement of design points in the tails of the prior distribution could alleviate this issue, 
as it would force the GP predictions downward. Although the GP would revert to its prior
as the distance from the design points increases, the hope is  
that an MCMC algorithm would never reach such regions, as the design points in the tail
would effectively create a ``moat'' of low probability.
Moreover, if emulating the log-likelihood then one could also rely on the prior to drive the posterior 
density emulator to zero.

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.49\textwidth} % tauV
         \centering
         \includegraphics[width=\textwidth]{{vsem/extrap_q95_lpostem_tauV.png}}
         \caption{$\tauV$}
         \label{fig:vsem-prior-check-lpostem-tauv}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth} % Cv
         \centering
         \includegraphics[width=\textwidth]{{vsem/extrap_q95_lpostem_Cv.png}}
         \caption{$\stateV(0)$}
         \label{fig:vsem-prior-check-lpostem-cv}
     \end{subfigure}
        \caption{The prior predictive check recommended in \Cref{rec:pred-check-tails} 
        for the log-posterior emulator, focusing on the two parameters with unbounded support. 
        The lines correspond to the $95^{\mathrm{th}}$ percentile of the log-posterior surrogate 
        $\mathrm{Quantile}_{0.95}(\lpostEm[\Ndesign](\Par))$ as only one parameter in $\Par$ 
        is varied. Different lines correspond to different fixed values of the remaining parameters,
        which have been sampled from $\priorDens$. Dashed vertical lines indicate the extent of 
        the design points in that dimension, with inputs outside of these bounds representing
        pure extrapolation.}
        \label{fig:vsem-prior-check-lpostem}
\end{figure}

\subsection{Active Learning}
\todo: note that different active learning algorithms can be combined with different acquisition 
functions to define many algorithms. Mention this is too many combs to test, so we instead
first run active learning algorithms, then focus on the best performing algorithm to compare
the posterior approximation.



\section{Related Work and Extensions} \label{sec:related-work}

\subsection{Computer Model Calibration} \label{sec:computer-model-calibration}
The challenge of emulating a black-box computer model has received widespread attention 
well beyond the scope of Bayesian inference. The design of surrogate models for Bayesian 
inverse problems may be informed by the vast literature from the computer experiments, 
engineering, applied math, machine learning, and statistics communities. As a starting point, 
we refer readers to \citet{gramacy2020surrogates,design_analysis_computer_experiments,SanterCompExp,UQpredCompSci} 
and the references therein. It is worth taking a moment to clarify the scope of our review 
with respect to related work in the computer experiments literature in particular.
Indeed, early work in this field addressed the challenge of learning 
model parameters  $\Par$ from observational data via the use of a surrogate for $\fwd$, a problem 
commonly referred to as \textit{computer model calibration} (see \citet{computerModelCalibrationReview}
for a review). When cast as a problem of Bayesian inference, the calibration problem falls within the 
framework considered in this article. However, much of this early calibration work focused on 
the added challenge of learning a discrepancy term between the computer model $\fwd$ and the 
true underlying system \citep{ModelDiscrepancy,emPostDens,OakleyllikEm}. 
For example, the pioneering work \citet{KOH} considers jointly learning 
a forward model emulator, calibration parameters, and a discrepancy function within a single 
Bayesian model. By contrast, we do not consider discrepancy modeling in this review, and moreover
focus on the alternative modular workflow, where the surrogate is fit offline 
without seeing the calibration data $\obs$ \citep{modularization}. 
\footnote{This point is specific to the forward model emulation setting. Log-density emulators 
do depend on $\obs$, since the log-likelihood is a function of the data.}
This modular two-stage approach naturally leads to 
the question of how to propagate the surrogate uncertainty in the calibration stage, which is one 
of the central questions motivating this review.

\subsection{Probabilistic Numerics} \label{sec:prob-numerics}
See Sullivan, Hennig papers; and Teckentrup random forward models paper section 5

\subsection{Stochastic Simulators and Simulation-Based Inference} \label{sec:sbi}
\citet{Lueckmann2018LikelihoodfreeIW,VehtariParallelGP,ABCApproxLik,
BurknerAmortized,llikEmABC,ABCGP}

\subsection{Other}
Multifidelity methods? Active subspaces? Data subsampling/randomized misfits?

\section{Conclusion} \label{sec:conclusion}


% Appendix 
\section{Appendix}

\subsection{Surrogate-Induced Posterior Distributions}
This section proves \Cref{eq:fwd-em-Gaussian,eq:llik-em-Gaussian}, which characterize the distribution 
of $\postEm[\Ndesign]$ in the Gaussian forward model and log-density emulation settings, respectively.
The latter result is immediate, but the former requires proving some preliminary Gaussian identities.

\subsubsection{Forward Model Emulator}
We start by deriving the convolution of two Gaussians.

\begin{prop} \label{Gaussian_convolution}
Let $\Gaussian(A \mu, \likPar)$ and $\Gaussian(m, C)$ be Gaussian distributions on $\R^{\dimObs}$ and $\R^{\dimPar}$, 
respectively, with $A \in \R^{\dimObs \times \dimPar}$ and $\likPar, C$ symmetric, positive definite matrices. Then 
\begin{align*}
\int_{\R^{\dimPar}} \Gaussian(\obs \given A \mu, \likPar) \Gaussian(\mu \given m, C) d\mu
&= \Gaussian(\obs \given Am, \likPar + ACA^\top). 
\end{align*}
\end{prop}

\begin{proof} 
\todo
\end{proof}

We next prove a lemma that will be used in calculating $\Var[\postDens(\Par; \fwdEm[\Ndesign])]$.
\begin{lemma} \label{lemma:squared_Gaussian_density}
Let $\Gaussian(m, C)$ be a Gaussian distribution on $\R^{\dimObs}$ with $C$ a symmetric, positive-definite 
matrix. Then, for $\obs \in \R^{\dimObs}$, 
\begin{align*}
\Gaussian(\obs \given m, C)^2 
&= 2^{-\dimObs/2} \det(2\pi C)^{-1/2} \Gaussian\left(\obs \given m, \frac{1}{2}C\right). 
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\Gaussian(\obs \given m, C)^2 
&= \det(2\pi C)^{-1} \Exp{-\frac{1}{2} (\obs - m)^\top \left[\frac{1}{2}C \right]^{-1}(\obs - m)} \\
&= \det(2\pi C)^{-1} \det(2\pi (1/2)C)^{1/2} \Gaussian\left(\obs \given m, \frac{1}{2}C\right) \\
&= 2^{-\dimObs/2} \det(2\pi C)^{-1/2} \Gaussian\left(\obs \given m, \frac{1}{2}C\right). 
\end{align*}
\end{proof}

\Cref{eq:fwd-em-Gaussian} follows directly from the following result.

\begin{prop} \label{prop:Gaussian_marginal_moments}
Assume $\obs \given \mu \sim \Gaussian(A \mu, \likPar)$ and $\mu \sim \Gaussian(m, C)$, where $\mu \in \R^{\dimPar}$, 
$A \in \R^{\dimObs \times \dimPar}$, and $\likPar$, $C$ are both symmetric, positive definite. Then 
\begin{align*}
\E\left[\Gaussian(\obs \given A \mu, \likPar) \right] &= \Gaussian(\obs \given Am, \likPar + ACA^\top) \\
\Var\left[\Gaussian(\obs \given A \mu, \likPar) \right] 
&= \frac{\Gaussian\left(\obs \given Am, \frac{1}{2} \likPar + ACA^\top \right)}{2^{\dimObs/2} \det(2\pi \likPar)^{1/2}} - 
\frac{\Gaussian\left(\obs \given Am, \frac{1}{2}[\likPar + ACA^\top] \right)}{2^{\dimObs/2} \det(2\pi[\likPar + ACA^\top])^{1/2}}
\end{align*}
\end{prop}

\begin{proof} 
The first result follows immediately from \Cref{Gaussian_convolution}. For the variance, we have 
\begin{align}
\Var\left[\Gaussian(\obs \given A \mu, \likPar) \right] 
&= \E\left[\Gaussian(\obs \given A \mu, \likPar)^2 \right] - \E\left[\Gaussian(\obs \given A \mu, \likPar) \right]^2 \nonumber \\
&= \E\left[\Gaussian(\obs \given A \mu, \likPar)^2 \right] - \Gaussian(\obs \given Am, \likPar + ACA^\top)^2. \label{two_terms_variance}
\end{align}
Starting with the first term, we apply \Cref{lemma:squared_Gaussian_density} and 
\Cref{Gaussian_convolution}, respectively, to obtain 
\begin{align*}
\E\left[\Gaussian(\obs \given A \mu, \likPar)^2 \right]
&= 2^{-\dimObs/2} \det(2\pi \likPar)^{-1/2} \E\left[\Gaussian\left(\obs \given A\mu, \frac{1}{2}\likPar \right)\right] \\
&= 2^{-\dimObs/2} \det(2\pi \likPar)^{-1/2} \Gaussian\left(\obs \given Am, \frac{1}{2}\likPar + ACA^\top \right).
\end{align*}
For the second term in \ref{two_terms_variance}, another application of \Cref{lemma:squared_Gaussian_density} gives
\begin{align*}
\Gaussian(\obs \given Am, \likPar + ACA^\top)^2
&= 2^{-\dimObs/2} \det(2\pi[\likPar + ACA^\top])^{-1/2} \Gaussian\left(\obs \given Am, \frac{1}{2}[\likPar + ACA^\top]\right).
\end{align*}
Plugging these expressions back into \ref{two_terms_variance} completes the proof. 
\end{proof}

\subsubsection{Log-Density Emulator}




\subsection{Marginal Approximation with Gaussian Likelihood: Forward Model Emulation}
The closed-form computations related to the marginal approximation with a Gaussian 
likelihood follow from standard results regarding the convolution of Gaussian densities.  








\subsection{Marginal Acceptance Probability}
In this section we derive an expression for 
\begin{align}
\llikEmJointMarg[\Ndesign]{\accProbMH}(\Par, \propPar) 
&= \E_{\llikEm[\Ndesign]} \left[\min\left\{1, \Em[\Ndesign]{\accProbRatio}(\Par, \propPar)\right\} \right], 
\end{align}
as considered in \ref{acc_prob_joint_marg}. We start by noting 
\begin{align}
\Em[\Ndesign]{\accProbRatio}(\Par, \propPar)
&\sim \LN\left(\log C + \emMean[\Ndesign]{\llik}(\propPar) - \emMean[\Ndesign]{\llik}(\Par), \Var\left[\llikEm[\Ndesign](\propPar) - \llikEm[\Ndesign](\Par) \right] \right),
\label{acc_ratio_LN}
\end{align}
where 
\begin{align*}
C \Def \frac{\priorDens(\propPar) \propDens(\propPar, \Par)}{\priorDens(\Par) \propDens(\Par, \propPar)}.
\end{align*}
Thus, the required computation reduces to computing the expectation of $\min\left\{1, Y \right\}$, where $Y$ is a log-normally distributed 
random variable. 

\begin{lemma} \label{lemma:exp_max_one_LN}
Let $Y \sim \LN(m, s^2)$. Then, 
\begin{align}
\E\left[\min\left\{1, Y \right\} \right] &= \GaussianCDF\left(\frac{m}{s} \right) + \GaussianCDF\left(-\frac{m + s^2}{s} \right) e^{m + \frac{1}{2}s^2}
\end{align}
\end{lemma}

\begin{proof}
We have 
\begin{align}
\E\left[\min\left\{1, Y \right\} \right]
&= \int_{0}^{\infty} \min\{1, y\} \LN(y | m, s^2) dy \nonumber \\
&= \int_{-\infty}^{\infty} \min\{1, e^x\} \Gaussian(x | m, s^2) dx \nonumber \\
&= \int_{0}^{\infty} \Gaussian(x | m, s^2) dx +  \int_{-\infty}^{0} e^x \Gaussian(x | m, s^2) dx \nonumber \\
&= \GaussianCDF(m/s) + \int_{-\infty}^{0} e^x \Gaussian(x | m, s^2) dx. \nonumber \\
&= \GaussianCDF(m/s) + \int_{-\infty}^{0} \frac{1}{\sqrt{2\pi s^2}} e^x \Exp{-\frac{1}{2s^2} (x - m)^2} dx.  
\label{second_integral} 
\end{align}
For the integral in \ref{second_integral} we combine the exponential terms and complete the square. 
This yields 
\begin{align*}
&\int_{-\infty}^{0} \frac{1}{\sqrt{2\pi s^2}} e^x \Exp{-\frac{1}{2s^2} (x - m)^2} dx \\
&= \Exp{-\frac{m^2}{2s^2}} \int_{-\infty}^{0} \frac{1}{\sqrt{2\pi s^2}} \Exp{-\frac{1}{2} \left[\frac{x^2}{2} - 2\left(\frac{m}{s^2} + 1\right)x  \right]} dx \\
&= \Exp{-\frac{m^2}{2s^2} + \frac{[m + s^2]^2}{2s^2}} \int_{-\infty}^{0} \frac{1}{\sqrt{2\pi s^2}} \Exp{-\frac{1}{2s^2}(x - [m+s^2])^2} dx \\
&= \Exp{m + \frac{1}{2}s^2} \GaussianCDF\left(-\frac{m+s^2}{s}\right).
\end{align*}
Plugging this back into \ref{second_integral} completes the proof. 
\end{proof}

We now apply \Cref{lemma:exp_max_one_LN} to obtain the expression for the marginal acceptance probability. 
\begin{prop} \label{prop:joint-marg-accept-prob}
\begin{align*}
\llikEmJointMarg[\Ndesign]{\accProbMH}(\Par, \propPar) 
&= \E_{\llikEm[\Ndesign]} \left[\min\left\{1, \Em[\Ndesign]{\accProbRatio}(\Par, \propPar)\right\} \right] 
= w_1 + w_2 \llikEmJointMarg[\Ndesign]{\accProbRatio}(\Par, \propPar), 
\end{align*}
where 
\begin{align*}
w_1 &= \Prob(\Em[\Ndesign]{\accProbRatio}(\Par, \propPar) \geq 1) \\
w_2 &= \Prob\left(\Em[\Ndesign]{\accProbRatio}(\Par, \propPar) \leq \Exp{-\Var\left[\llikEm[\Ndesign](\propPar) - \llikEm[\Ndesign](\Par) \right]}\right).
\end{align*}
\end{prop}

\begin{proof}
We recall from \ref{acc_ratio_LN} that $\Em[\Ndesign]{\accProbRatio}(\Par, \propPar) \sim \LN(m, s^2)$, with 
\begin{align*}
m &= \log C + \emMean[\Ndesign]{\llik}(\propPar) - \emMean[\Ndesign]{\llik}(\Par) \\
s^2 &= \Var\left[\llikEm[\Ndesign](\propPar) - \llikEm[\Ndesign](\Par) \right]. 
\end{align*}
We thus have 
\begin{align*}
e^{m + \frac{1}{2}s^2} = \E_{\llikEm}\left[\Em[\Ndesign]{\accProbRatio}(\Par, \propPar) \right] 
=  \llikEmJointMarg[\Ndesign]{\accProbRatio}(\Par, \propPar). 
\end{align*}
It remains to verify the expressions for the weights $w_1$ and $w_2$. Letting $Z \sim \Gaussian(0,1)$, 
we apply \Cref{lemma:exp_max_one_LN} to obtain
\begin{align*}
w_1 &= \GaussianCDF(m/s) = \Prob(Z \leq m/s) = \Prob(\Exp{m+sZ} \geq 1) = \Prob(\Em[\Ndesign]{\accProbRatio}(\Par, \propPar) \geq 1) \\
w_2 &= \GaussianCDF(-(m+s^2)/s) = \Prob(\Exp{m + sZ} \leq e^{-s}) = \Prob(\Em[\Ndesign]{\accProbRatio}(\Par, \propPar) \leq e^{-s}).
\end{align*}
\end{proof}

\subsection{Transition Kernels of Approximate MCMC Algorithms} \label{transition_kernel_derivations}
We derive the expression for the \textit{MCWMH-joint} transition 
kernel $\llikEmJointMCWMH[\Ndesign]{\MarkovKernel}$ given in \ref{MCWMH-joint-kernel}. 
Let $\Par \in \parSpace$ and $A \subset \parSpace$ a Borel set. 
We recall that the kernel for a standard MH algorithm is given by 
\begin{align}
\MarkovKernel(\Par, A)
&= \int_{A} \propDens(\Par, \propPar) \accProbMH(\Par, \propPar) d\propPar
+ [1 - \avgAccProbMH(\Par)] \delta_{\Par}(A) \label{MH-kernel}, 
\end{align}
where $\avgAccProbMH(\Par)$ is the overall acceptance probability, averaged over all proposals,
\begin{align}
\avgAccProbMH(\Par)
&= \int_{\parSpace} \propDens(\Par, \propPar) \accProbMH(\Par, \propPar) d\propPar. 
\end{align}
Denote $\parMat \Def \{\Par, \propPar\}$. 
The \textit{MCWMH-joint} algorithm replaces the exact log-likelihood evaluations 
$\llik(\parMat) \Def [\llik(\Par), \llik(\propPar)]^\top$ used to define $\propDens(\Par, \propPar)$ by 
sampled approximate values 
\begin{align}
\llikSamp_{\parMat} \Def [\llikSamp, \llikSampProp]^\top \sim \Gaussian(\emMean[\Ndesign]{\llik}(\parMat), \emKer[\Ndesign]{\llik}(\parMat)). 
\end{align}
We let $\Em[\Ndesign]{\accProbMH}(\Par, \propPar | \llikSamp_{\parMat})$ denote the approximate acceptance probability defined using 
the sampled values $\llikSamp_{\parMat}$. The probability of accepting a state in the set $A$, conditional on the sample $\llikSamp_{\parMat}$, 
is thus 
\begin{align}
\Prob(\indexMCMC[\mcmcIndex+1]{\Par} \in A | \Par, \llikSamp_{\parMat})
&=  \int_{A} \propDens(\Par, \propPar) \Em[\Ndesign]{\accProbMH}(\Par, \propPar | \llikSamp_{\parMat}) d\propPar. 
\end{align}
The unconditional probability follows from the law of total probability:
\begin{align}
\Prob(\indexMCMC[\mcmcIndex+1]{\Par} \in A | \Par)
&= \int_{\R^2} \Prob(\indexMCMC[\mcmcIndex+1]{\Par} \in A | \Par, \llikSamp_{\parMat}) \Gaussian(\llikSamp_{\parMat} | \emMean[\Ndesign]{\llik}(\parMat), \emKer[\Ndesign]{\llik}(\parMat)) d\llikSamp_{\parMat} \\
&= \int_{\R^2} \int_{A} \propDens(\Par, \propPar) \Em[\Ndesign]{\accProbMH}(\Par, \propPar | \llikSamp_{\parMat})  
\Gaussian(\llikSamp_{\parMat} | \emMean[\Ndesign]{\llik}(\parMat), \emKer[\Ndesign]{\llik}(\parMat)) d\propPar \ d\llikSamp_{\parMat} \\
&= \int_{A} \propDens(\Par, \propPar) \int_{\R^2}  \Em[\Ndesign]{\accProbMH}(\Par, \propPar | \llikSamp_{\parMat})  
\Gaussian(\llikSamp_{\parMat} | \emMean[\Ndesign]{\llik}(\parMat), \emKer[\Ndesign]{\llik}(\parMat)) d\llikSamp_{\parMat} \ d\propPar \label{flip_integral_order} \\
&= \int_{A} \propDens(\Par, \propPar) \llikEmJointMarg[\Ndesign]{\accProbMH}(\Par, \propPar)  d\propPar
\end{align}
where \ref{flip_integral_order} follows from Tonelli's theorem, and using the definition of $\llikEmJointMarg[\Ndesign]{\accProbMH}(\Par, \propPar)$
in \ref{acc_prob_joint_marg}. Setting $A \Def \parSpace$ in the above integral yields the overall acceptance probability 
\begin{align}
\llikEmJointMarg[\Ndesign]{\avgAccProbMH}(\Par) \Def \int_{\parSpace} \propDens(\Par, \propPar) \llikEmJointMarg[\Ndesign]{\accProbMH}(\Par, \propPar)  d\propPar. 
\end{align}
These quantities thus give 
\begin{align}
\llikEmJointMCWMH[\Ndesign]{\MarkovKernel}(\Par, A)
&= \int_{A} \propDens(\Par, \propPar) \llikEmJointMarg[\Ndesign]{\accProbMH}(\Par, \propPar) d\propPar
+ [1 - \llikEmJointMarg[\Ndesign]{\avgAccProbMH}(\Par)] \delta_{\Par}(A) \label{MH-kernel}, 
\end{align}
which follows from same derivations for the standard MH kernel \ref{MH-kernel} with the marginal acceptance probabilities substituted for
the original ones. The transition kernel for the \textit{MCWMH-ind} algorithm follows immediately by marginalizing with respect 
to $\Gaussian(\emMean[\Ndesign]{\llik}\left(\parMat), \diag\left\{\emKer[\Ndesign]{\llik}(\Par), \emKer[\Ndesign]{\llik}(\propPar) \right\}\right)$
in place of the full joint distribution. 

\subsection{Sequential Design Calculations}
We start by stating an identity for the inversion of partitioned matrices, which is very useful in updating GPs by 
conditioning on new design points. The generic result can be found in the lecture notes \cite{MinkaMatrixLectures}, 
but we specialize the statement to the GP setting.  

\subsubsection{Useful Lemmas}

\begin{prop} \label{partitioned-matrix-inverse}
Let $\funcPrior \sim \GP(\gpMeanPrior, \gpKerPrior)$ be a GP prior, with 
$\funcEm[\Ndesign] \Def \funcPrior | [\funcPrior(\designIn) = \func(\designIn)] \sim \GP(\gpMean[\Ndesign], \gpKer[\Ndesign])$  
the GP predictive distribution after conditioning on the design $(\designIn, \func(\designIn))$. Let 
$\designBatchIn$ be a set of $\Nbatch$ new design points. Define 
$\kerMat[\Ndesign] \Def \gpKerPrior(\designIn)$, $\kerMat[\Nbatch] \Def \gpKerPrior(\designBatchIn)$,
and $\kerMat[\Ndesign,\Nbatch] \Def \gpKerPrior(\designIn[\Ndesign], \designBatchIn)$.  
Then, letting 
$\designIn[\Naugment] \Def \designIn \cup \designBatchIn$, the inverse of the kernel matrix 
evaluated on the augmented design satisfies 
\begin{align}
\gpKerPrior(\designIn[\Naugment])^{-1}
&= \begin{pmatrix} \kerMat[\Ndesign] & \kerMat[\Ndesign,\Nbatch] \\
\kerMat[\Ndesign,\Nbatch]^\top & \kerMat[\Nbatch] \end{pmatrix}^{-1}
=  \begin{pmatrix} \tilde{K} & -\kerMat[\Ndesign]^{-1} \kerMat[\Ndesign,\Nbatch] \gpKer[\Ndesign](\designBatchIn)^{-1} \\
-\gpKer[\Ndesign](\designBatchIn)^{-1} \kerMat[\Ndesign,\Nbatch]^\top  \kerMat[\Ndesign]^{-1} & \gpKer[\Ndesign](\designBatchIn)^{-1} \end{pmatrix},
\end{align}
where 
\begin{align}
\tilde{K} = \kerMat[\Ndesign]^{-1} + \kerMat[\Ndesign]^{-1} \kerMat[\Ndesign,\Nbatch] \gpKer[\Ndesign](\designBatchIn)^{-1} \kerMat[\Nbatch,\Ndesign] \kerMat[\Ndesign]^{-1}.
\end{align}
Thus, assuming $\kerMat[\Ndesign]^{-1}$ has already been computed, $\gpKerPrior(\designIn[\Naugment])^{-1}$ can be constructed in an additional 
$\BigO(\Nbatch^3 + \Nbatch \Ndesign^2 + \Nbatch^2 \Ndesign)$ operations. 
\end{prop}

We repeatedly use the fact that $\funcPrior|[\funcPrior(\designIn[\Naugment]) = \func(\designIn[\Naugment])]$ and 
$\funcEm[\Ndesign] | [\funcEm[\Ndesign](\designBatchIn) = \func(\designBatchIn)]$ are equal in distribution ; 
i.e., conditioning the GP prior on the entire design 
is equivalent to sequentially conditioning on subsets of the design. For the sake of completeness, we provide the rigorous justification for this below.

\begin{lemma} \label{lemma:gp-condition-order}
Let $\funcPrior \sim \GP(\gpMeanPrior, \gpKerPrior)$ be a GP prior. Consider a set of $\Naugment$ design points $\{\designIn[\Naugment], \funcVal[\Naugment]\}$
partitioned as $\designIn[\Naugment] = \designIn[\Ndesign] \cup \designBatchIn$ and $\funcVal[\Naugment] = \funcVal[\Ndesign] \cup \funcVal[\Nbatch]$.
Let $\funcEm[\Ndesign] \Def \func | [\func(\designIn[\Ndesign]) = \funcVal[\Ndesign]] \sim \GP(\gpMean[\Ndesign], \gpKer[\Ndesign])$. 
Then the random process $\funcPrior | [\funcPrior(\designIn[\Naugment]) = \funcVal[\Naugment]]$ is equal in distribution to the random process
$\funcEm[\Ndesign] | [\funcEm[\Ndesign](\designIn[\Nbatch]) = \funcVal[\Nbatch]]$. 
\end{lemma} 

\begin{proof} 
Since both processes in question are Gaussian it suffices to check that 
\begin{align*}
\E[\funcPrior(\parMat) | \funcPrior(\designIn[\Naugment]) = \funcVal[\Naugment]] 
&= \E[\funcEm[\Ndesign](\parMat) | \funcEm[\Ndesign](\designIn[\Nbatch]) = \funcVal[\Nbatch]] \\
\Cov[\funcPrior(\parMat) | \funcPrior(\designIn[\Naugment]) = \funcVal[\Naugment]] 
&= \Cov[\funcEm[\Ndesign](\parMat) | \funcEm[\Ndesign](\designIn[\Nbatch]) = \funcVal[\Nbatch]],
\end{align*}
for an arbitrary finite set of inputs $\parMat \subset \parSpace$. The quantities on the lefthand side are 
$\gpMean[\Naugment](\parMat)$ and $\gpKer[\Naugment](\parMat)$, by definition. We begin by expanding 
the expression $\gpKerPrior(\parMat, \designIn[\Naugment]) \kerMat[\Naugment]^{-1}$, noting that we 
are borrowing the notation from \Cref{partitioned-matrix-inverse}. Applying the partitioned matrix 
inversion identity from \Cref{partitioned-matrix-inverse} yields 
\begin{align*}
\gpKerPrior(\parMat, \designIn[\Naugment]) \kerMat[\Naugment]^{-1}
&= \begin{pmatrix} \gpKerPrior(\parMat, \designIn[\Ndesign]) &  \gpKerPrior(\parMat, \designIn[\Nbatch]) \end{pmatrix}
\begin{pmatrix} \tilde{K} & -\kerMat[\Ndesign]^{-1} \kerMat[\Ndesign,\Nbatch] \gpKer[\Ndesign](\designBatchIn)^{-1} \\
-\gpKer[\Ndesign](\designBatchIn)^{-1} \kerMat[\Ndesign,\Nbatch]^\top  \kerMat[\Ndesign]^{-1} & \gpKer[\Ndesign](\designBatchIn)^{-1} \end{pmatrix}.
\end{align*}
Denoting $\funcVal[\Ndesign]^\prime \Def \funcVal[\Ndesign] - \gpMeanPrior(\designIn[\Ndesign])$ and 
$\funcVal[\Nbatch]^\prime \Def \funcVal[\Nbatch] - \gpMeanPrior(\designIn[\Nbatch])$, the predictive mean $\gpMean[\Naugment](\parMat)$ is thus given by 
\begin{align*}
\gpMean[\Naugment](\parMat)
&= \gpMeanPrior(\parMat) + \gpKerPrior(\parMat, \designIn[\Naugment]) \kerMat[\Naugment]^{-1}[\funcVal[\Naugment] - \gpMeanPrior(\designIn[\Naugment])] \\
&= \gpMeanPrior(\parMat) + \begin{pmatrix} \gpKerPrior(\designIn[\Ndesign], \parMat) \\  \gpKerPrior(\designIn[\Nbatch], \parMat) \end{pmatrix}^\top
\begin{pmatrix} \tilde{K} & -\kerMat[\Ndesign]^{-1} \kerMat[\Ndesign,\Nbatch] \gpKer[\Ndesign](\designBatchIn)^{-1} \\
-\gpKer[\Ndesign](\designBatchIn)^{-1} \kerMat[\Ndesign,\Nbatch]^\top  \kerMat[\Ndesign]^{-1} & \gpKer[\Ndesign](\designBatchIn)^{-1} \end{pmatrix} 
\begin{pmatrix}  \funcVal[\Ndesign]^\prime \\  \funcVal[\Nbatch]^\prime \end{pmatrix} \\
&= \gpMeanPrior(\parMat) + \gpKerPrior(\parMat, \designIn[\Ndesign])\kerMat[\Ndesign]^{-1}\funcVal[\Ndesign]^\prime + 
\gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1} \funcVal[\Nbatch]^\prime - 
\gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1} \kerMat[\Ndesign,\Nbatch]^\top \kerMat[\Ndesign]^{-1} \funcVal[\Ndesign]^\prime \\
&= \gpMean[\Ndesign](\parMat) + \gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1}[\funcVal[\Nbatch]^\prime - \kerMat[\Ndesign,\Nbatch]^\top \kerMat[\Ndesign]^{-1} \funcVal[\Ndesign]^\prime] \\
&= \gpMean[\Ndesign](\parMat) + \gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1}[\funcVal[\Nbatch]^\prime - \gpMean[\Ndesign](\designIn[\Nbatch]) + \gpMeanPrior(\designIn[\Nbatch])] \\
&= \gpMean[\Ndesign](\parMat) + \gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1}[\funcVal[\Nbatch] - \gpMean[\Ndesign](\designIn[\Nbatch])] \\
&= \E[\funcEm[\Ndesign](\parMat) | \funcEm[\Ndesign](\designIn[\Nbatch]) = \funcVal[\Nbatch]] 
\end{align*}
where we have used the fact that the predictive covariance of the GP $\funcEm[\Ndesign]$ gives 
\[
\gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) = \gpKerPrior(\parMat, \designIn[\Nbatch]) - 
\gpKerPrior(\parMat, \designIn[\Ndesign])\kerMat[\Ndesign]^{-1} \gpKerPrior(\designIn[\Ndesign], \parMat).
\]
The covariance calculation proceeds similarly by replacing $\funcVal[\Ndesign]^\prime$ and $\funcVal[\Nbatch]^\prime$ with 
$\gpKerPrior(\designIn[\Ndesign], \parMat)$ and $\gpKerPrior(\designIn[\Nbatch], \parMat)$, respectively. We obtain 
\begin{align*}
\gpKer[\Naugment](\parMat)
&= \gpKerPrior(\parMat) - \gpKerPrior(\parMat, \designIn[\Naugment]) \kerMat[\Naugment]^{-1}[\funcVal[\Naugment] - \gpMeanPrior(\designIn[\Naugment])] \\
&= \gpKerPrior(\parMat) - \begin{pmatrix} \gpKerPrior(\designIn[\Ndesign], \parMat) \\  \gpKerPrior(\designIn[\Nbatch], \parMat) \end{pmatrix}^\top
\begin{pmatrix} \tilde{K} & -\kerMat[\Ndesign]^{-1} \kerMat[\Ndesign,\Nbatch] \gpKer[\Ndesign](\designBatchIn)^{-1} \\
-\gpKer[\Ndesign](\designBatchIn)^{-1} \kerMat[\Ndesign,\Nbatch]^\top  \kerMat[\Ndesign]^{-1} & \gpKer[\Ndesign](\designBatchIn)^{-1} \end{pmatrix} 
\begin{pmatrix}  \gpKerPrior(\designIn[\Ndesign], \parMat) \\  \gpKerPrior(\designIn[\Nbatch], \parMat) \end{pmatrix} \\
&= \gpKer[\Ndesign](\parMat) - 
\gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1} [\gpKerPrior(\designIn[\Nbatch], \parMat) - \kerMat[\Ndesign,\Nbatch]^\top \kerMat[\Ndesign]^{-1}\gpKerPrior(\designIn[\Ndesign], \parMat)] \\
&= \gpKer[\Ndesign](\parMat) -  \gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1} \gpKer[\Ndesign](\designIn[\Nbatch], \parMat) \\
&= \Cov[\funcEm[\Ndesign](\parMat) | \funcEm[\Ndesign](\designIn[\Nbatch]) = \funcVal[\Nbatch]].
\end{align*}

\end{proof}

\subsubsection{Uncertainty in GP Predictive Mean Due to Unobserved Response}

\begin{proof} [Proof of \Cref{lemma:pred-mean-dist}]
Though the result is only required for a single input $\Par$, it is no more difficult to establish for a set of inputs $\parMat$. 
We recall that 
\begin{align*}
\gpMean[\Ndesign](\parMat | \designBatchFunc) 
&= \E[\funcEm[\Ndesign](\parMat) | \funcEm(\designBatchIn) = \designBatchFunc] \\
&= \gpMean[\Ndesign](\parMat) + \gpKer[\Ndesign](\parMat, \designBatchIn) \gpKer[\Ndesign](\designBatchIn)^{-1} [\designBatchFunc - \gpMean[\Ndesign](\designBatchIn)],
\end{align*}
following from the GP predictive equations \ref{kriging_eqns}. Since, $\designBatchFunc|\parMat \sim \Gaussian(\gpMean[\Ndesign](\designBatchIn), \gpKer[\Ndesign](\designBatchIn))$, 
we see that $\gpMean[\Ndesign](\parMat | \designBatchFunc)$ is a linear function of a Gaussian random variable. It is thus Gaussian distributed, with mean and covariance
\begin{align*}
\E_{\designBatchFunc}[\gpMean[\Ndesign](\parMat | \designBatchFunc)]
&= \gpMean[\Ndesign](\parMat) + \gpKer[\Ndesign](\parMat, \designBatchIn) \gpKer[\Ndesign](\designBatchIn)^{-1} [\gpMean[\Ndesign](\designBatchIn) - \gpMean[\Ndesign](\designBatchIn)] = \gpMean[\Ndesign](\parMat) \\
\Cov_{\designBatchFunc}[\gpMean[\Ndesign](\parMat | \designBatchFunc)]
&= \gpKer[\Ndesign](\parMat, \designBatchIn) \gpKer[\Ndesign](\designBatchIn)^{-1}  \gpKer[\Ndesign](\designBatchIn) \gpKer[\Ndesign](\designBatchIn)^{-1} \gpKer[\Ndesign](\designBatchIn, \parMat) \\
&=  \gpKer[\Ndesign](\parMat, \designBatchIn) \gpKer[\Ndesign](\designBatchIn)^{-1} \gpKer[\Ndesign](\designBatchIn, \parMat) \\
&= \gpKer[\Ndesign](\parMat) - \gpKer[\Naugment](\parMat).
\end{align*}
\end{proof}

\subsubsection{Integrated Conditional Variance Calculations: Log-Likelihood Emulation}

\begin{proof} [Proof of \Cref{lemma:evar}]
We start by noting that 
\begin{align*}
\Var[\llikEmRdmDens[\Ndesign](\Par) | \llikEm[\Ndesign](\designBatchIn) = \designBatchLlik]
&= \Var[\priorDens(\Par) \Exp{\llikEm(\Par)} | \llikEm[\Ndesign](\designBatchIn) = \designBatchLlik] \\
&= \priorDens(\Par)^2 \Var[\Exp{\llikEm(\Par)} | \llikEm[\Ndesign](\designBatchIn) = \designBatchLlik],
\end{align*}
so we will focus on the likelihood emulator, ignoring the prior for now. Since 
\begin{align*}
\Exp{\llikEm(\Par)} | [\llikEm[\Ndesign](\designBatchIn) = \designBatchLlik] \sim 
\LN(\emMean[\Ndesign]{\llik}(\Par| \designBatchLlik), \emKer[\Naugment]{\llik}(\Par)),
\end{align*}
we apply the formula for a log-normal variance to obtain 
\begin{align}
\Var[\Exp{\llikEm(\Par)} | \llikEm[\Ndesign](\designBatchIn) = \designBatchLlik]
&= \cst \Exp{2\emMean[\Ndesign]{\llik}(\Par | \designBatchLlik)}, \label{formula_plug_in}
\end{align}
where 
\begin{align*}
\cst \Def \left[\Exp{\emKer[\Naugment]{\llik}(\Par)} -1 \right] \Exp{\emKer[\Naugment]{\llik}(\Par)}
\end{align*}
is not a function of the random variable $\designBatchLlik$. \Cref{lemma:pred-mean-dist} gives 
\begin{align*}
\emMean[\Ndesign]{\llik}(\Par | \designBatchLlik)
&\sim \LN(\emMean[\Ndesign]{\llik}(\Par), \emKer[\Ndesign]{\llik}(\Par) - \emKer[\Naugment]{\llik}(\Par)), 
\end{align*}
which implies 
\begin{align*}
\Exp{2\emMean[\Ndesign]{\llik}(\Par | \designBatchLlik)}
&\sim \Gaussian(2\emMean[\Ndesign]{\llik}(\Par), 4[\emKer[\Ndesign]{\llik}(\Par) - \emKer[\Naugment]{\llik}(\Par)]).
\end{align*}
Applying the formula for a log-normal mean thus yields 
\begin{align*}
\E_{\designBatchLlik} \left[\Exp{2\emMean[\Ndesign]{\llik}(\Par | \designBatchLlik)} \right]
&= \Exp{2\emMean[\Ndesign]{\llik}(\Par)} \Exp{2[\emKer[\Ndesign]{\llik}(\Par) - \emKer[\Naugment]{\llik}(\Par)]} \\
&=  \Exp{2\emMean[\Ndesign]{\llik}(\Par)} \varInflation(\Par; \designBatchIn), 
\end{align*}
where $\varInflation(\Par; \designBatchIn)$ is defined in \ref{var_inflation_factor}. Plugging this expression back 
into \ref{formula_plug_in} gives 
\begin{align*}
\E_{\designBatchLlik} \Var[\Exp{\llikEm(\Par)} | \llikEm[\Ndesign](\designBatchIn) = \designBatchLlik]
&= \cst \Exp{2\emMean[\Ndesign]{\llik}(\Par)} \varInflation(\Par; \designBatchIn) \\
&= \Var[\Exp{\llikEm(\Par)} | \llikEm[\Ndesign](\designBatchIn) = \emMean[\Ndesign]{\llik}(\Par)] \varInflation(\Par; \designBatchIn).
\end{align*}
Multiplying both sides by $\priorDens(\Par)$ completes the proof, with the closed-form expression for the first term following 
immediately from the formula for a log-normal variance. 
\end{proof}

\subsubsection{Integrated Conditional Variance Calculations: Forward Model Emulation}

\begin{proof} [Proof of \Cref{prop:evar-fwd-emulation}]
We begin by noting that the squared prior density can be pulled out of the expectation as
\begin{align*}
\E_{\designBatchFwd} \Var[\postDens(\Par; \fwdEmCond{\designBatchFwd}) | \designBatchFwd]
&= \priorDens^2(\Par) \ \E_{\designBatchFwd}  \Var[\Gaussian\left(\obs |  \fwdEmCond{\designBatchFwd}(\Par), \likPar \right) | \designBatchFwd]. 
\end{align*}
The variance on the righthand side can be expanded as 
\begin{align}
\Var[\Gaussian\left(\obs |  \fwdEmCond{\designBatchFwd}(\Par), \likPar \right) | \designBatchFwd]
&= \frac{\Gaussian\left(\obs | \emMean[\Ndesign]{\fwd}(\Par|\designBatchFwd), \frac{1}{2}\likPar + \emKer[\Naugment]{\fwd}(\Par) \right)}{\det(2\pi \likPar)^{1/2}}
- \frac{\Gaussian\left(\obs | \emMean[\Ndesign]{\fwd}(\Par|\designBatchFwd), \frac{1}{2}\left[\likPar + \emKer[\Naugment]{\fwd}(\Par)\right]  \right)}{\det(2\pi [\likPar + \emKer[\Naugment]{\fwd}(\Par)])^{1/2}}
\end{align}
following from an application of \Cref{eq:fwd-em-Gaussian}. The denominators in the above expression can be 
pulled out of the outer expectation and are seen to equal the denominators in the desired expression. We thus complete the proof by 
computing the expectation of the numerators with respect to 
$\designBatchFwd | \designBatchIn \sim \Gaussian(\emMean[\Ndesign]{\fwd}(\designBatchIn), \emKer[\Ndesign]{\fwd}(\designBatchIn))$. 
These expectations can be computed by noting \Cref{lemma:pred-mean-dist} and then applying \Cref{prop:Gaussian_marginal_moments}.
This yields,
\begin{align*}
\E_{\designBatchFwd}\left[\Gaussian\left(\obs \bigg| \emMean[\Ndesign]{\fwd}(\Par|\designBatchFwd), \frac{1}{2}\likPar + \emKer[\Naugment]{\fwd}(\Par) \right)\right]
&= \Gaussian\left(\obs \big| \emMean[\Ndesign]{\fwd}(\Par), 
\left[\frac{1}{2}\likPar + \emKer[\Naugment]{\fwd}(\Par)\right] + \left[\emKer[\Ndesign]{\fwd}(\Par) - \emKer[\Naugment]{\fwd}(\Par)\right] \right) \\
&= \Gaussian\left(\obs \big| \emMean[\Ndesign]{\fwd}(\Par), \frac{1}{2}\likPar + \emKer[\Ndesign]{\fwd}(\Par) \right)
\end{align*}
and
\begin{align*}
\E_{\designBatchFwd}\left[\Gaussian\left(\obs \big| \emMean[\Ndesign]{\fwd}(\Par|\designBatchFwd), \frac{1}{2}\left[\likPar + \emKer[\Naugment]{\fwd}(\Par)\right]\right)\right] 
&= \Gaussian\left(\obs \big| \emMean[\Ndesign]{\fwd}(\Par), \frac{1}{2} \left[\likPar + \emKer[\Naugment]{\fwd}(\Par)\right] + \left[\emKer[\Ndesign]{\fwd}(\Par) - \emKer[\Naugment]{\fwd}(\Par)\right] \right) \\
&= \Gaussian\left(\obs \big| \emMean[\Ndesign]{\fwd}(\Par), \left[\frac{1}{2}\likPar + \emKer[\Ndesign]{\fwd}(\Par)\right] - \frac{1}{2} \emKer[\Naugment]{\fwd}(\Par)\right),
\end{align*}
which completes the derivation of \Cref{fwd_evar1}. To obtain \Cref{fwd_evar2} we rearrange the covariances of the above expressions to obtain 
\begin{align*}
\frac{1}{2}\likPar + \emKer[\Ndesign]{\fwd}(\Par) &= 
\left[\likPar +  \emKer[\Ndesign]{\fwd}(\Par) \right] - \frac{1}{2}\likPar 
= \CovComb(\Par) - \frac{1}{2}\likPar \\
\left[\frac{1}{2}\likPar + \emKer[\Ndesign]{\fwd}(\Par)\right] - \frac{1}{2} \emKer[\Naugment]{\fwd}(\Par)
&= \left[\likPar + \emKer[\Ndesign]{\fwd}(\Par) \right] - \frac{1}{2}\left[\likPar + \emKer[\Naugment]{\fwd}(\Par) \right] 
= \CovComb(\Par) - \frac{1}{2} \CovComb[\Naugment](\Par). 
\end{align*}

\end{proof}


% Questions and TODOs
\section{Questions and TODOs}
\subsection{Questions}
\begin{enumerate}
\item How to reliably use a log-normal emulator for Bayesian inference? 
	\begin{enumerate}
	\item Improve GP calibration (e.g., quadratic mean) 
	\item Use more robust statistics (e.g., interquartile range)
	\item Truncate proposal or prior. 
	\end{enumerate}
\item How to deal with highly concentrated/correlated posteriors? 
	\begin{enumerate}
	\item MALA or other samplers. 
	\end{enumerate}
\end{enumerate}

\subsection{Need to add}
\begin{enumerate}
\item Summary of results from noisy MCMC literature.
\item Try working out results that compare the ratio of the approx density at two points across different approximations; 
alternatively could consider deriving these results for the normalized densities. 
\item Include result that sample and marginal approx agree at the design points.
\item Include existence results (check existence result from that new paper)
\item Viewing noisy MCMC approaches as approximations to the sample-based posterior.
\item Different views of noisy MCMC approaches, including extending the state space. How does this alg compare to the 
marginal and mcwmh-ind algs?
\item Add some sort of theoretical result that demonstrates that the marginal approximation is extremely sensitive to the GP 
variance. Based on numerical experiments, seems like this result should be given with respect to the dynamic range of the 
log-likelihood. Also of course depends on how fast the GP variance grows away from the design points, so perhaps should 
consider fill distance or something like this as well.
\item Numerical experiment that considers the different ways to weight the integrated uncertainty criteria (i.e., targeting 
the unnormalized posterior density vs. using the approx posterior samples as weights).
\item Posterior consistency results for the noisy MCMC emulators; combine the noisy MCMC results with GP approximation 
results.
\item Evaluating calibration of GP-approximated posteriors relative to calibration of the underlying GP emulator.
\item Constrained GPs
\item Pathwise sampling approach to approximate the sample-based approximation.
\item Compare noisy MCMC vs. deterministic version that considers integrating over the acceptance prob. 
\item Analyze effect of incorporating GP covariance structure; does it result in posteriors closer to the sample-based posterior? 
\item Compare marginal and sample-based approx.
\item Compare marginal approx in log-likelihood vs. forward model setting. 
\item Analyze distribution of likelihood under forward model emulation [I think this is the exponential of a folded Gaussian random variable]. 
How does its tail compare to the lognormal tail? 
\end{enumerate}

\subsection{Emulator Ideas}
\begin{enumerate}
\item Sum of quadratic kernel, Gaussian kernel, and some sort of flat/linear kernel (i.e. something with very long lengthscales) to capture the 
part of the response surface that "flattens" out. 
\end{enumerate}

\subsection{Notation}
\begin{enumerate}
\item How to clean up notation for all of the different approximations being considered here? 
\end{enumerate}

\subsection{Numerical experiments:}
My plan is to have emulation in dynamical settings (ODEs) as the unifying theme here. VSEM can provide the core example but could also consider 
others, such as Lorenz-63 (see Hwanwoo Kim, Daniel Sanz-Alonso paper for the ODEs they consider). When introducing the dynamical setting,
cite Stuart/Schneider Earth System modeling 2.0 paper. Provide various examples of observation operators: time-averages (moments) of state 
variables, identity operator, many shorter time-averages (e.g., weekly/monthly averages), multi-objective settings of calibrating to multiple state 
variables. I should probably include Lorenz-63 to have a more familiar example to many audiences. 

\begin{enumerate}
\item 1D example with 1D output for basic illustration. 
	\begin{enumerate}
	\item VSEM with single varied parameter. 
	\item For 1D output, consider long time average of of a single state variable. This will allow us to compare forward model and log-likelihood emulation directly.
	\item Gaussian likelihood. 
	\item Compare emulator distributions, log-likelihood emulator distributions, and likelihood emulator distributions, and various posterior approximations. 
	\item Validation metrics: RMSE, MAE, CRPS, Log-Score, Coverage. 
	\end{enumerate}
\item 2D examples for basic illustration and consideration of different posterior characteristics: Gaussian, banana, unidentifiable, concentration level, bimodal. 
\item Extension of 2D densities to 6-10 dims (see Vehtari paper numerical experiments) 
\item Sequential design performance at different levels of posterior concentration. 
\item Integrated uncertainty criterion: incorporating the current posterior via the integrand or the measure?
\item Large batch, few iteration sequential design experiment. 
(4 different combinations we could consider) 
\end{enumerate}

\begin{enumerate}
\item 1D example for basic illustration. 
\item 2D examples for basic illustration and consideration of different posterior characteristics: Gaussian, banana, unidentifiable, concentration level, bimodal. 
\item Extension of 2D densities to 6-10 dims (see Vehtari paper numerical experiments) 
\item Sequential design performance at different levels of posterior concentration. 
\item Integrated uncertainty criterion: incorporating the current posterior via the integrand or the measure?
\item Large batch, few iteration sequential design experiment. 
(4 different combinations we could consider) 
\end{enumerate}

\subsection{Potential examples:}
\begin{enumerate}
\item Banana, unimodal, bimodal, unidentifiable
\item Heat equation (see Sinsbeck and Nowak) 
\item VSEM
\end{enumerate}

\subsection{Things to consider trying}
\begin{enumerate}
\item Perhaps give some context by discussing connections to Bayesian optimization and to log-likelihood approximation used in 
simulation-based inference. 
\item Hyperparameter marginalization: need to look into opportunities for closed-form hyperparameter marginalization during 
sequential design phase. 
\item Developing a design criterion that better aligns with the MHWMC procedure; e.g., something that targets the likelihood ratio. 
\item Implementing Higdon basis function approach for comparison. 
\item Nonnegative constrained GPs (may be able to do this by modifying the kergp optimization code and using nloptr's option to add constraints) 
\item GP-accelerated MALA 
\end{enumerate}

\subsection{Limitations of existing literature}
\begin{enumerate}
\item Very little discussion of case where likelihood parameters are unknown. 
\item Lack of emphasis on batch design (with some exceptions).
\item Little guidance on which approximation/design criterion to choose.
\item Vehtari fixes the marginal approx, and focuses instead on varying the design criterion, but notes that sampling from the marginal approx is problematic. 
\end{enumerate}

\subsection{Conjectures}
\begin{enumerate}
\item The MCWMH algorithms will perform better than sampling from the marginal approx in the log-likelihood emulation setting, especially when the GP is very uncertain. 
\end{enumerate}

\subsection{Consideration}
\begin{enumerate}
\item Literature typically focuses on convergence of the approx posterior. But in cases with very expensive computer models, one might have to stop pre-convergence. 
In these settings the comparison between the approximate posteriors becomes even more important. 
\end{enumerate}

\end{comment}

\bibliography{../shared/surrogates} 
\end{document}







