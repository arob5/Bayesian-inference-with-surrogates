\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,url,fancyhdr}
\usepackage[affil-it]{authblk}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{natbib}
\usepackage{bbm}
\usepackage{caption, subcaption}
\usepackage{fancyvrb}
\usepackage{float}
\usepackage[most]{tcolorbox}
\usepackage[hypertexnames=false]{hyperref}
\usepackage{cleveref}

% Bibliography
\bibliographystyle{plainnat}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools}
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Tables. 
\usepackage{multirow}

% Color boxes.
\tcbuselibrary{breakable} % ensure breakable capability is loaded

\newtcbtheorem[number within=section, crefname={example}{examples}, Crefname={Example}{Examples}]{examplebox}{Example}{
    before skip=12pt plus 2pt minus 2pt,
    after skip=12pt plus 2pt minus 2pt,
    breakable,
    enhanced,
    colback=white,
    colframe=gray!80!black,
    colbacktitle=gray!20,
    coltitle=black,
    fonttitle=\bfseries,
    fontupper=\normalfont,
    sharp corners,
    attach boxed title to top left={yshift=-2mm, xshift=2mm},
    boxed title style={colframe=gray!80!black, sharp corners},
}{ex}

% Local custom commands. 
\input{../shared/macros_general.tex}
\input{macros.tex}
\newcommand{\bphi}{\boldsymbol{\phi}}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{{./../../out/review_final/}}

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{remark}{Remark}
\newtheorem{rec}{Recommendation}

\crefname{prop}{Proposition}{Propositions}
\Crefname{prop}{Proposition}{Propositions}
\crefname{definition}{Definition}{Definitions}
\Crefname{definition}{Definition}{Definitions}
\crefname{lemma}{Lemma}{Lemmas}
\Crefname{lemma}{Lemma}{Lemmas}
\crefname{thm}{Theorem}{Theorems}
\Crefname{thm}{Theorem}{Theorems}
\crefname{corollary}{Corollary}{Corollaries}
\Crefname{corollary}{Corollary}{Corollaries}
\crefname{rec}{Recommendation}{Recommendations}
\Crefname{rec}{Recommendation}{Recommendations}
\crefname{remark}{Remark}{Remark}
\Crefname{remark}{Remark}{Remark}

% Title and author
\title{Probabilistic Surrogates for Bayesian Inverse Problems: Posterior Approximation and Active Learning}
\author[1]{Andrew Gerard Roberts\thanks{Emails: \texttt{arober@bu.edu}, \texttt{dietze@bu.edu}, \texttt{huggins@bu.edu}}}
\author[2]{Michael Dietze}
\author[1,3]{Jonathan H. Huggins}

\affil[1]{Faculty of Computing and Data Sciences, Boston University}
\affil[2]{Department of Earth and Environment, Boston University}
\affil[3]{Department of Mathematics and Statistics, Boston University}
\date{}

\begin{document}

\maketitle


\section{Introduction}
In fields ranging from climate science \citep{ESM_modeling_2pt0} \todo{one more citation} to astrophysics
\citep{VarmaBlackHole2019,npeAstrophysics}, the scientific process increasingly relies on complex, computationally
expensive computer simulations. Many such computer models contain parameters with values that cannot be specified
a priori or estimated experimentally. Therefore, a critical task in many scientific workflows is to estimate values
of these parameters that are consistent with observed data, a process sometimes called 
\textit{parameter calibration} \citep{paramLSM} \todo{one more citation}.
Bayesian inference offers a principled framework for parameter inference, providing mechanisms to 
quantify parameter uncertainty and balance prior information with observed data.
However, standard Bayesian inference algorithms (e.g., Markov chain Monte Carlo) 
require evaluating the likelihood function tens to hundreds of thousands of times. When a single simulation takes 
minutes or hours, this cost renders these standard approaches intractable.
To overcome this barrier, a rich literature has developed around \textit{surrogate modeling} (i.e., \textit{emulation}). The core 
idea is to replace the expensive simulator with a statistical approximation, trained on a sparse set of simulator runs, that is 
computationally cheap to evaluate \citep{KOH,gramacy2020surrogates}. By substituting this emulator into the inference pipeline, 
one seeks to characterize the posterior distribution at a fraction of the cost.

\subsection{Challenges in Surrogate-Based Bayesian Inference}
While conceptually straightforward, replacing the true model with an approximation introduces methodological
and conceptual challenges. While some of these difficulties are generic within the broader context of surrogate modeling,
others are unique to the use of emulators within a Bayesian workflow \citep{BurknerSurrogate}:

\begin{enumerate}
    \item \textbf{Concentrated Posteriors:} When data are informative, the posterior mass often concentrates in a small, 
    unknown subset of the prior support. A sparse set of simulator evaluations is likely to completely miss this 
    ``needle in a haystack'', yielding a surrogate that is uninformed in the most relevant regions. 
    \item \textbf{Non-Stationary Target Surfaces:} Surrogate models are often trained to emulate quantities such as 
    simulator outputs or the log-likelihood function. These target surfaces can be highly non-stationary and span many 
    orders of magnitude. Standard emulators (e.g., stationary Gaussian processes) often struggle to model such surfaces 
    sufficiently well to resolve the posterior geometry.
    \item \textbf{Uncertainty Propagation:} Surrogate error translates directly into posterior bias. Ignoring this error can lead to
    biased and overconfident inference, necessitating frameworks to construct uncertainty-aware posterior estimates.
    \item \textbf{The Chicken and Egg Problem:} A globally-accurate surrogate model is not necessarily required for accurate
    posterior inference. Rather, high surrogate accuracy is necessary in high-density regions. However, identifying these 
    regions requires the very knowledge of the posterior geometry that the surrogate is intended to provide.
\end{enumerate}

\subsection{Scope and Contributions}
This review synthesizes the methodological landscape of surrogate-based Bayesian inference, 
focusing on the dual goals of \textit{uncertainty propagation} (accounting for surrogate error) and 
\textit{uncertainty reduction} (surrogate refinement via active learning). 
We adopt a generic probabilistic perspective, encompassing both 
\textit{forward model emulation} (emulating simulator outputs) and 
\textit{log-density emulation} (directly emulating the log-likelihood or log-posterior surface).
Rather than focusing on a specific model class, we provide a unified treatment of the workflow, 
highlighting how sequential design and probabilistic uncertainty quantification can be leveraged to 
tackle the aforementioned challenges.

\todo[inline]{
\begin{enumerate}
\item Add paper organization here
\item Add section walking through surrogate-based modular Bayesian workflow, with a diagram.
\item Improve citations in introduction
\end{enumerate}
}

% Background
\section{Bayesian Inference with Expensive Models} \label{sec:background}
From a generic perspective, the scope of this paper concerns problems of Bayesian inference in which evaluation
of the (unnormalized) posterior density incurs significant computational expense. This situation is exceedingly common 
in large-scale scientific and engineering applications, where the goal is to infer latent parameters related to 
observations through a computationally expensive computer model. We begin by introducing such Bayesian inverse 
problems, and provide a concrete motivating example. 
 
\subsection{The Bayesian Inference Setting}
Many scientific problems require inferring unknown parameters $\Par \in \parSpace \subseteq \R^{\dimPar}$ using 
noisy observations $\obs \in \obsSpace \subseteq \R^{\dimObs}$. In statistical approaches to this problem, the link
between these quantities is modeled by specifying a likelihood $\lik(\Par; \obs) \Def p(\obs \given \Par)$, and a Bayesian 
completes the model with a prior distribution $\Par \sim \priorDens$ over the parameters. 
The central task of Bayesian inference is to characterize the posterior distribution
\begin{align}
&\postDensNorm(\Par) \Def p(\Par \given \obs) = \frac{1}{\normCst} \priorDens(\Par) \lik(\Par; \obs),
&&\normCst = \int_{\parSpace} \priorDens(\Par) \lik(\Par; \obs) \d\Par,
\end{align}
which encodes the uncertainty in the parameters after observing the data. Both the posterior density $\postDensNorm$
and normalizing constant $\normCst$ depend on $\obs$, but we suppress this in the notation as the data realization 
will remain fixed throughout. Typically, the integral defining $\normCst$ is intractable, so posterior inference algorithms
rely on pointwise evaluations of the \textit{unnormalized} posterior density $\postDens(\Par) \Def \priorDens(\Par)\lik(\Par; \obs)$.
A standard approach is to sample the posterior using a Markov chain Monte Carlo (MCMC) 
algorithm, often requiring $10^5 - 10^7$ serial evaluations of $\postDens(\Par)$. While not a problem for simple 
statistical models, this sequential computation renders MCMC infeasible when the cost of a density evaluation is high.

\subsection{Bayesian Inverse Problems} \label{sec:bip}
The inference challenge posed by expensive posterior densities commonly arises in the Bayesian approach to 
inverse problems \citep{Stuart_BIP}. In this setting, the observation $\obs$ typically corresponds to an 
observable quantity associated with a complex physical system. The goal is to recover latent parameters of interest
$\Par$ that gave rise to the observed data. The bulk of the modeling effort typically consists of constructing a
mechanistic model $\fwd: \parSpace \to \obsSpace$ encoding domain knowledge, which describes the forward 
process by which parameters produce observed quantities. We refer to $\fwd$ as the \textit{forward model}.
The task of solving the inverse problem entails
inverting the relationship, identifying parameter values consistent with a particular observation. This parameter recovery 
is commonly cast as a problem of Bayesian inference with a Gaussian noise model
\begin{equation}
\obs = \fwd(\Par) + \noise, \qquad
\noise \sim \Gaussian(0, \likPar), \label{eq:inv_prob_Gaussian} 
\end{equation}
implying the likelihood
\begin{equation}
\lik(\Par; \obs) = \det(2\pi\likPar)^{-\dimObs/2} \Exp{-\frac{1}{2} \norm{\obs - \fwd(\Par)}^{2}_{\likPar}}.
\footnote{We utilize the weighted norm notation $\norm{x}^{2}_{A} \Def x^\top A^{-1}x$, where $A$ is a positive definite matrix.}
\label{eq:Gaussian-likelihood}
\end{equation}
Computing $\lik(\Par; \obs)$ (and thus $\postDens(\Par)$) requires the forward model evaluation $\fwd(\Par)$,
which may involve running an expensive computer simulation (e.g., a numerical differential equation solver). Hence, in Bayesian
inverse problems the posterior density $\postDens(\Par)$ is often a computationally expensive, and potentially black box 
(i.e., difficult or impossible to differentiate), function. 

\begin{examplebox}{Parameter Estimation for ODEs}{ex:ode}
In modeling the Earth system, complex dynamical models are used to simulate trajectories
of various physical processes, such as temperature trends and carbon fluxes
 \citep{ESM_modeling_2pt0,paramLSM,idealizedGCM,FATES_CES,CLMBayesianCalibration,FerEmulation}.
These models often feature empirical parameters with unknown values that must be estimated from data.
As a simple illustrative example, we consider the problem of parameter estimation for an ordinary 
differential equation (ODE). While this example is simplified for clarity, the setup is structurally similar to many 
inverse problems faced in practice, such as parameter estimation for land surface models \citep{paramLSM}. 
Consider a parameter-dependent initial value problem 
\begin{align}
\frac{d}{d\Time} \state(\Time, \Par) &= \odeRHS(\state(\Time, \Par), \Par), &&x(\timeStart, \Par) = \stateIC, \label{ode_ivp}
\end{align}
describing the time evolution of $\dimState$ state variables 
$\state(\Time, \Par) \Def \left\{\indexState{\state}(\Time, \Par)\right\}_{\stateIndex=1}^{\dimState}$
with dynamics depending on $\Par \in \parSpace$. As our focus will be on estimating these parameters 
from observations, we consider the parameter-to-state map
\begin{align}
\Par &\mapsto \left\{\state(\Time, \Par) :  \Time \in [\timeStart, \timeEnd] \right\}.
\end{align}
In practice, the solution is typically approximated via a numerical discretization of the form 
\begin{align}
\solutionOp: \Par &\mapsto \left[\indexTime[0]{\state}(\Par), \dots, \indexTime[\NTimeStep]{\state}(\Par) \right]^\top. \label{eq:ode-solution-op}
\end{align}
Here, $\solutionOp: \parSpace \to \R^{\NTimeStep \times \dimState}$ represents the map induced by a numerical solver, 
and $\indexTime[0]{\state}(\Par), \dots, \indexTime[\NTimeStep]{\state}(\Par)$ are approximations of the state 
values $\state(\Time, \Par)$ at a finite set of time points in $[\timeStart, \timeEnd]$. 
Going forward, we focus on the discrete-time operator $\solutionOp$, neglecting discretization error
for simplicity. Finally, suppose we have observed data $\obs \in \obsSpace \subseteq \R^{\dimObs}$ that we model as a
noise-corrupted function of the state trajectory. This is formalized by the definition of an observation operator 
$\obsOp: \R^{\NTimeStep \times \dimState} \to \obsSpace$ mapping from the state trajectory to a 
$\dimObs$-dimensional observable quantity. Assuming the data generating process
\begin{align}
&\obs = (\obsOp \circ \solutionOp)(\ParTrue) + \noise, 
&&\noise \sim \Gaussian(0, \likPar) \label{ode_inv_prob} 
\end{align}
for some ``true'' parameter value $\ParTrue \in \parSpace$, we see that this problem is of the form in 
\Cref{eq:inv_prob_Gaussian} with forward model $\fwd \Def \obsOp \circ \solutionOp$.
In this case, the computational
cost of evaluating $\postDens(\Par)$ can be high, owing to the dependence on the numerical solver $\solutionOp(\Par)$.
\end{examplebox}

\section{Surrogate Models}
Given the inference bottleneck imposed by a computationally expensive posterior density, many methods have emerged
aiming to approximate the posterior using only a small set of density evaluations. Many such approaches 
consist of replacing a computationally-limiting component of the model with a cheap \inlinedef{surrogate}, thus enabling 
the use of standard inference schemes on the resulting approximate model. In this section, we introduce the particular
sub-class of surrogate models that form the focus of this article.

\begin{remark}
The term ``surrogate'' is widely used in varying contexts in which some baseline quantity is replaced by an 
approximation. The remainder of this section defines our precise usage of the word. In the interest of variety, we 
also use ``emulator'' as a synonym, with ``emulate'' referring to the process of constructing an emulator. 
\end{remark}

\subsection{Regression-Based Surrogates}
While there is a vast literature on surrogates designed for specific model structures, 
we instead focus on the broadly applicable strategy of learning regression-based emulators from black-box model 
evaluations. Even within this class of surrogates, the regression modeling setup can vary widely, 
with a key decision being the choice of response variable to approximate with the regression model. 
To formalize this notion, let $\target: \parSpace \to \targetRange$ denote the map that the surrogate seeks to 
approximate. When relevant, we will augment the notation from \Cref{sec:background} to emphasize the dependence
on this \inlinedef{target map}; e.g., $\postDens(\Par; \target)$, $\lik(\Par; \target, \obs)$, $\normCst(\target)$, etc. 
We make the assumption throughout that $\postDens(\Par; \target)$ depends on $\Par$ and $\target$ only as a 
function of $\target(\Par)$.
The implicit assumption here is that the target map has been chosen to alleviate the computational bottleneck; hence,
the density $\postDens(\Par; \target)$ is cheap to compute once the expensive computation $\target(\Par)$ is 
completed.

A regression-based surrogate is a regression model $\targetEm$ fit to training data 
$\{(\Par_{\designIdx}, \target(\Par_{\designIdx}))\}_{\designIdx=1}^{\Ndesign}$ constructed by evaluating the exact
target map at a set of \inlinedef{design points} $\design \Def \{\Par_{\designIdx}\}_{\designIdx=1}^{\Ndesign}$.
Substituting the exact map with its emulator induces an approximation of the posterior density 
$\postDensNorm(\Par; \targetEm) = \postDens(\Par; \targetEm) / \normCst(\targetEm)$. Provided that the 
emulator predictions can be computed relatively cheaply, the approximation $\postDens(\Par; \targetEm)$
can now be fed to standard inference algorithms (e.g., MCMC).

\begin{remark}
Throughout this article, we focus on the case where the target $\target$ is a deterministic function.
This implies the observed simulation outputs $\target(\Par_{\designIdx})$ are noiseless, and hence 
emulators commonly seek to (approximately) interpolate between design points.
Many of the ideas here are also relevant to the stochastic case, including to the simulation-based
inference setting where the likelihood takes the form of a black-box stochastic simulator. We discuss
connections to these topics in \Cref{sec:sbi}.
\end{remark}

\subsection{Probabilistic Surrogates}
In practice, fitting a highly accurate surrogate can be challenging. Since the induced posterior approximation
inherits imperfections from the underlying emulator, this raises the concern that the posterior estimate 
can be simultaneously biased and overconfident. To address this fundamental challenge and mitigate the problem 
of unquantified posterior approximation error, we argue that a Bayesian surrogate-based workflow should include
the following two steps:
\begin{enumerate}
\item \textit{Active learning}: while computational resources allow, augment the emulator design with additional 
runs of the simulator, targeting the design points with the greatest potential for improvement in the posterior
approximation or an alternative downstream goal.
\item \textit{Uncertainty propagation}: when the computational budget is exhausted, 
construct a final posterior estimate that propagates the remaining surrogate uncertainty. 
\end{enumerate}
Both of these steps require emulators that are equipped with a notion of predictive uncertainty. For this reason, 
we focus on \textit{probabilistic surrogates}---models that provide predictions in the form of probability
distributions.

\begin{remark}
Conceptually, we typically think of the randomness in the predictive distribution as quantifying \textbf{epistemic uncertainty} \citep{epistemicAleatoric}, which in principle could be reduced, were it computationally feasible to evaluate 
$\target$ at any given input. The predictive distribution may also quantify \textbf{aleatoric uncertainty}, 
irreducible uncertainty stemming from the inability of any parameterization of the surrogate to exactly 
represent the true target function. In the case that the target is stochastic, the predictive distribution will
also model the aleatoric uncertainty due to the inherent randomness of the simulator.
\citet{BurknerSurrogate} present a framework that incorporates both notions of uncertainty.
\end{remark}

\subsubsection{Definitions and Notation}
Concretely, we adopt the viewpoint of an emulator as a random function $\targetEm \sim \emDist$ that
approximates $\target$. Let $\emE$ denote expectation with respect to $\emDist$, and $\targetEm(\Par) \sim \emDist(\Par)$ the pointwise marginal predictive distributions of the surrogate. Supposing for the moment that
the surrogate predicts a scalar-valued quantity, define the pointwise 
predictive mean $\emMean(\Par) \Def \emE[\targetEm(\Par)]$ and variance 
$\emVar(\Par) \Def \Var_{\emDist}[\targetEm(\Par)]$. While some emulators provide only pointwise predictions,
many also encode correlational structure across input values. We thus denote the covariance
$\emKer(\Par, \Par^\prime) \Def \Cov_{\emDist}[\targetEm(\Par), \targetEm(\Par^\prime)]$, 
noting that $\emKer(\Par, \Par) = \emVar(\Par)$.
For a finite set of inputs $\ParBatch \Def \{\Par_b\}_{b=1}^{\Nbatch} \subset \parSpace^{\Nbatch}$, we use the 
vectorized notation $\target(\ParBatch) \Def [\target(\Par_1), \dots, \target(\Par_\Nbatch)]^\top$, with
$\targetEm(\ParBatch) \sim \emDist(\ParBatch)$ denoting the $\Nbatch$-dimensional joint predictive distribution with mean vector $\emMean(\ParBatch)$ and covariance matrix $\emVar(\ParBatch)$. Similarly, given another set
$\ParBatch^\prime$ of $\Nbatch^\prime$ inputs, we write $\emKer(\ParBatch, \ParBatch^\prime)$ to denote
the $\Nbatch \times \Nbatch^\prime$ cross covariance. In particular, we use the shorthand 
$\{\design, \target(\design)\}$ for the design points and the corresponding target function evaluations.

Of central importance to this work is the manner in which emulator uncertainty propagates to downstream 
quantities of interest. For example, the quantity $\postDensNorm(\Par; \targetEm)$ resulting from plugging
the surrogate in place of the true target map is a random density with a distribution that summarizes
surrogate-induced uncertainty in the true posterior. 
When discussing such pushforward distributions we make use of the 
notation $\postNormEm \Def \postDensNorm(\cdot; \targetEm)$ when explicit reference to the underlying emulator
is not necessary.

In many situations, the target $\target$ is a multi-valued function and hence $\targetEm$ is a multi-output
regression model. In this case, $\emMean(\Par)$ and $\emVar(\Par)$ denote the predictive mean vector and 
covariance matrix, respectively, over the different outputs. To avoid complicating notation, we do not extend
the above vectorized notation in the multi-output setting. We make clarifying remarks when necessary to 
avoid ambiguity.

\subsection{Common Surrogate Models}
In this section, we highlight several popular models that fall under our definition of 
\textit{probabilistic surrogate}.

\subsubsection{Gaussian Processes}
Gaussian processes (GPs) are widely used as surrogate models, with extensive applications in 
response surface modeling for computer experiments 
\citep{design_analysis_computer_experiments,SanterCompExp}, 
black-box optimization \citep{reviewBayesOpt}, reliability 
analysis \citep{contourEstimation,cole2021entropybased}, and parameter 
calibration \citep{KOH,computerModelCalibrationReview}. For in-depth treatments, we refer to
\citet{gramacy2020surrogates,gpML,StuartTeck2}.

A typical GP-based workflow consists of specifying a prior $\targetEm[0] \sim \GP(\emMean[0], \emKer[0])$ 
over the target function $\target$, defined by a prior mean function $\emMean[0](\cdot)$ and 
covariance function (i.e., kernel) $\emKer[0](\cdot, \cdot)$. The 
defining property of a GP is its Gaussian finite-dimensional marginal distributions
$\targetEm[0](\ParBatch) \sim \Gaussian(\emMean[0](\ParBatch), \emKer[0](\ParBatch))$
(using the notation $\emKer[0](\ParBatch) \Def \emKer[0](\ParBatch, \ParBatch)$).
Commonly, the hyperparameters defining the mean and kernel are optimized, though Bayesian 
treatments are also possible. With fixed hyperparameters, the surrogate is constructed by 
closed-form conditioning 
$\targetEm \Def \targetEm[0] \given [\targetEm[0](\design) = \target(\design)] \sim \GP(\emMean, \emKer)$,
with the conditional mean and kernel given by
\begin{align}
\emMean(\ParBatch) 
&= \emMean[0](\ParBatch) + \emKer[0](\ParBatch, \design) \emKer[0](\design)^{-1}[\target(\design) - \emMean[0](\design)] \\
\emKer(\ParBatch) 
&= \emKer[0](\ParBatch) - \emKer[0](\ParBatch, \design) \emKer[0](\design)^{-1} \emKer[0](\design, \ParBatch).
\nonumber
\end{align}
Thus, in their most basic form GP surrogates are Gaussian predictors 
$\targetEm(\ParBatch) \sim \Gaussian(\emMean(\ParBatch), \emKer(\ParBatch))$. 
Extensions of the GP methodology
can produce more flexible emulators with non-Gaussian predictive distributions. For example, fully Bayesian 
GPs \citep{fullyBayesianGPs} and deep GPs \citep{deepGPVecchia,deepGPAL}
typically yield predictions in the form of (infinite) mixtures of Gaussians.

\subsubsection{Polynomials}
Surrogates that consist of linear combinations of polynomial basis functions are 
commonly used in the engineering and applied math communities. 
Polynomial chaos expansions (PCEs; \citet[Chapter 9]{UQpredCompSci}) are a particular example whereby 
a polynomial basis is used to approximate a random variable $\target(\Par)$ as a function of
a random input $\Par \sim \priorDens$. In particular, the expansion is of the form
\begin{equation}
\targetEm[\dimBasis](\Par) = \sum_{\idxBasis=1}^{\dimBasis} c_{\idxBasis} \basisVec_{\idxBasis}(\Par),
\end{equation}
where $\basisVec_{1}, \dots, \basisVec_{\dimBasis}$ are orthogonal polynomials with respect 
to $\priorDens$. Once constructed, a PCE is often used to 
approximate moments of $\target(\Par)$. More relevant to our context,
the map $\targetEm[\dimBasis](\Par)$ can also be used as a surrogate for $\target(\Par)$.
With fixed coefficients $c_{\idxBasis}$, this map is deterministic and thus PCEs do not fall
within our definition of probabilistic surrogates. We nonetheless highlight them here
due to their popularity, the fact that they can be converted into random surrogates by 
considering Bayesian treatments of the coefficients 
\citep{BayesianPCE1,BayesianPCE2,BurknerSurrogate},
and their use in conjunction with probabilistic surrogates (e.g., as the mean function
of a GP; \citet{PCEGPWind,PCEGP2,SinsbeckNowak}). PCE surrogates have been
employed to accelerate Bayesian inversion in various applications 
\citep{dimRedPolyChaos,BurknerSurrogate,PCEBIP}.

\subsubsection{Neural Networks}
In regimes where the input dimension $\dimPar$ and computational 
budget $\Ndesign$ are large, neural networks are well-suited to 
serve as surrogate models. Bayesian treatment of neural 
network parameters provides probabilistic predictions, but in practice significant 
approximations are required for inference \citep{BayesOptNN}. One popular simplification
treats only the final neural network layer in a Bayesian fashion 
\citep{BayesLastLayer,BayesOptBayesLastLayer}. These difficulties have motivated
interest in surrogate models with predictive distributions 
not necessarily rooted in the Bayesian philosophy. This includes deep ensembles, 
which summarize uncertainty via an ensemble of neural network 
models \citep{deepEnsembles,Lueckmann2018LikelihoodfreeIW},
and epistemic neural networks \citep{epistemicNN,BayesOptEpistemicNN}.

\subsection{Finite vs. Infinite Dimensional Surrogates}
As will be explored throughout this paper, methods for surrogate-based posterior inference
may present varying degrees of computational challenges depending on the particular type
of emulator model. A key influencing factor is whether or not the surrogate admits a 
finite-dimensional representation. We define $\targetEm$ to be finite-dimensional if its randomness stems from a finite-dimensional
parameter $\theta_{\Ndesign}$; i.e., $\targetEm(\cdot) = g(\cdot; \theta_{\Ndesign})$ for some 
random vector $\theta_{\Ndesign}$ and non-random function $g$.
In this case, it is feasible to sample trajectories (sample paths) of $\targetEm$ via 
\begin{align}
&\targetTraj(\cdot) \Def g(\cdot; \theta),
&&\theta \sim \mathrm{law}(\theta_{\Ndesign}).
\end{align}
The sampled trajectory $\targetTraj(\cdot)$ can now be evaluated at any input value. A standard example is a 
model taking the form of a linear combination of basis functions 
$\targetEm(\cdot) = \sum_{\idxBasis=1}^{\dimBasis} \theta_{\Ndesign}^{(\idxBasis)} g^{(\idxBasis)}(\cdot)$.

An infinite-dimensional surrogate admits no such finite-dimensional representation. 
Typical examples include surrogates constructed from GPs. For these models, 
it is computationally infeasible to sample trajectories. Instead, the surrogate can typically be 
characterized by the set of distributions $\emDist(\ParBatch)$ over finite-dimensional
subsets $\ParBatch$.

% Surrogate targets
\section{Choosing the Target Map} \label{sec:target-map}
Parallel to the choice of model class is the determination of the surrogateâ€™s target: the map $\target$.
While this decision is inherently problem-dependent, the structure of a Bayesian inverse problem suggests 
two overarching strategies: \inlinedef{forward model emulation}, which targets the underlying forward map, 
and \inlinedef{log-density emulation}, which directly targets the posterior surface.
A similar dichotomy is explored in \citet{StuartTeck1,GP_PDE_priors,random_fwd_models}. 

\subsection{Forward Model Emulation}
The high computational cost in Bayesian inverse problems stems primarily from the underlying forward model. 
A natural strategy to alleviate this bottleneck is to fit an emulator directly targeting the forward map, $\target \Def \fwd$. 
The architecture of such a surrogate is largely dictated by the properties of $\fwd$.
A common challenge in this context is the high dimensionality of the observation space,
particularly for models with complex spatial or temporal structure; examples include 
epidemic modeling \citep{FadikarAgentBased},
engineering design \citep{PODemulation}, ecological forecasting 
\citep{emPostDens,DagonCLM}, and climate modeling \citep{ESM_modeling_2pt0,idealizedGCM}.
Emulators for such complex model outputs typically rely on some form of dimensionality reduction. Common approaches include:
\begin{enumerate}
\item \emph{Basis Expansion}: Emulating the coefficients of a linear basis 
(e.g., principal components analysis or proper orthogonal decomposition) \citep{HigdonBasis,FadikarAgentBased,PODemulation}.
\item \emph{Feature Extraction}: Targeting low-dimensional statistical summaries 
\citep{ESM_modeling_2pt0,idealizedGCM,CLMBayesianCalibration,CLMSurrogates}.
\item \emph{Specialized Architectures}: Leveraging the structure of particular
dynamical models 
\citep{GP_dynamic_emulation, Bayesian_emulation_dynamic,Liu_West_dynamic_emulation, dynamic_nonlinear_simulators_GP}.
\end{enumerate} 

\begin{examplebox}{Forward Model Surrogate, Gaussian Setting}{fwd-em}
Consider the setting of a Bayesian inverse problem with an additive Gaussian noise model
(\Cref{eq:inv_prob_Gaussian}). Assume an emulator $\targetEm$ has been 
fit to approximate the true forward model $\fwd$. This induces an approximation of the 
unnormalized posterior density 
\begin{align}
\postDens(\Par; \targetEm) &= \priorDens(\Par)\Gaussian(\obs \given \targetEm(\Par), \likPar),
\label{eq:fwd-em-Gaussian}
\end{align}
for each $\Par \in \parSpace$. In general, the distribution of $\postDens(\Par; \targetEm)$ depends on 
the predictive distribution of $\targetEm$. The additional assumption 
$\targetEm(\Par) \sim \Gaussian(\emMean(\Par), \emVar(\Par))$ facilitates closed-form computation
of the first two moments,
\begin{align*}
\emE\left[\postDens(\Par; \targetEm) \right] 
&= \priorDens(\Par) \Gaussian(\obs \given \emMean(\Par), \likPar + \emVar(\Par)) \\
\Var_{\emDist}\left[\postDens(\Par; \targetEm) \right]
&= \priorDens^2(\Par) \bigg[\frac{\Gaussian\left(\obs \given \emMean(\Par), \frac{1}{2}\likPar + 
\emVar(\Par)  \right)}{\det(2\pi \likPar)^{1/2}} - \\
&\qquad \qquad\qquad \frac{\Gaussian\left(\obs \given \emMean(\Par), \frac{1}{2}\left[\likPar + \emVar(\Par)\right]  \right)}{\det(2\pi [\likPar + \emVar(\Par)])^{1/2}}\bigg],
\end{align*}
a fact that has been leveraged frequently in the literature
\citep{StuartTeck1,GP_PDE_priors,hydrologicalModel,hydrologicalModel2,Surer2023sequential,
VillaniAdaptiveGP,weightedIVAR,idealizedGCM,CES}. The left column of \Cref{fig:em_dist_1d}
visualizes how the uncertainty in a GP forward model emulator propagates to downstream 
quantities within this setting.
\end{examplebox}

\subsection{Log-Density Emulation} \label{sec:log_density_emulation}
Given that most posterior inference algorithms require only an unnormalized density as input, 
an efficient alternative to forward model emulation is to directly target the log-likelihood or 
the unnormalized log-posterior, approaches we collectively refer to as \inlinedef{log-density emulation}.
While one could also consider modeling the likelihood or posterior surface directly,
emulating on the log scale is generally preferred to improve numerical stability, enforce
non-negativity of the resulting density approximation, and yield a smoother target surface. \todo{citation?}

The primary appeal of log-density emulation is \textit{scalarization} \citep{ranjan2016inverse, trainDynamics}: 
collapsing a potentially high-dimensional observation space into a single scalar output. 
However, this simplification introduces several challenges. Log-densities often exhibit a large dynamic 
range and non-stationary behavior, which can be difficult for standard surrogates to capture 
\citep{wang2018adaptive, Surer2023sequential}. Furthermore, because additive errors in the log-domain 
become multiplicative errors when exponentiated, the resulting posterior approximations are highly sensitive 
to emulator misspecification \citep{ourSurrPropPaper}. A further complication arises when likelihood 
parameters (e.g., the noise covariance $\likPar$ in \Cref{eq:inv_prob_Gaussian}) are unknown. 
While one can expand the emulator's input space to include these parameters \citep{llikRBF, emPostDens}, this increases 
the input dimensionality and can further complicate the target surface. Alternatively, some likelihoods 
admit a sufficient statistic that can be emulated independently of the likelihood parameters \citep{FerEmulation}.

Log-likelihood emulators have also seen use in calibrating stochastic simulators \citep{OakleyllikEm,llikEmABC,VehtariParallelGP,gpEmMCMC}, 
developing active learning algorithms \citep{JosephMinEnergy,ActiveLearningMCMC,quantileApprox,AlawiehIterativeGP}, 
and performing Bayesian quadrature \citep{BayesQuadrature,BayesQuadRatios}. Applications to 
ecological modeling are considered in \citet{FerEmulation,FATES_CES}, and \citep{GP_PDE_priors}
compare forward model and log-likelihood emulators for PDE-constrained inverse problems.

\begin{examplebox}{Log-Likelihood Surrogate, Gaussian Setting}{ldens-em}
In the case that the emulator is fit to the log-likelihood, the induced unnormalized posterior approximation
is of the form 
\begin{align}
\postDens(\Par; \targetEm) &= \priorDens(\Par) \Exp{\targetEm(\Par)}.
\end{align}
Under the assumption $\targetEm(\Par) \sim \Gaussian(\emMean(\Par), \emVar(\Par))$, this
quantity is log-normally distributed, with moments
\begin{align*}
\emE\left[\postDens(\Par; \targetEm) \right] 
&= \priorDens(\Par)\Exp{\emMean(\Par) + \frac{1}{2} \emVar(\Par)} \\
\Var_{\emDist}\left[\postDens(\Par; \targetEm) \right]
&= \priorDens^2(\Par) \left[\Exp{\emVar(\Par)} - 1 \right] \Exp{2\emMean(\Par) + \emVar(\Par)}.
\end{align*}
\end{examplebox}

\subsubsection{Log-Likelihood vs. Log-Posterior Emulation.} \label{sec:llik_vs_lpost}
Since the prior density is typically cheap to evaluate, it appears natural to approximate
only the log-likelihood. However, several works opt to emulate the unnormalized log-posterior 
directly \citep{emPostDens, Kandasamy_2017, gp_surrogates_random_exploration}. 
While the choice may seem numerically inconsequential (one can be converted to the other 
via a deterministic shift by the log-prior), there are tradeoffs to consider. 
Emulating the log-posterior allows one to incorporate within the surrogate the known constraint 
that the posterior must decay in the tails. In contrast, the log-likelihood's tail behavior may be 
difficult to characterize a priori, presenting an additional challenge for model specification.
Conversely, constraining tail behavior in certain surrogate models (e.g., GPs) can be difficult, 
and the failure to do so in log-posterior emulation can lead to pathological results. 
Another downside of log-posterior emulation is that the surrogate depends on the prior; 
any update to the prior model necessitates re-training. A final consideration is whether 
the log-posterior or log-likelihood surface is easier to emulate. In general, this will depend on 
the relative strength of the prior and the likelihood, as well as their particular functional forms.
In settings where the likelihood dominates the prior, the practical difference between these two 
target surfaces diminishes. 

% --- PAGE 1: THE FIGURE ---
\begin{figure}[p] 
    \centering
    \includegraphics[width=\textwidth, height=0.98\textheight, keepaspectratio]{surrogate_pushforward_grid.pdf}
    % Invisible caption to increment the counter and set the anchor
    \phantomcaption 
\end{figure}

\clearpage

% --- PAGE 2: THE CAPTION ---
\begin{figure}[t]
    \ContinuedFloat
    \caption{Pushforward distributions induced by GP forward model emulator (left column), 
    GP log-posterior emulator (middle column), and a clipped GP log-posterior emulator (right column). 
    The plots summarize the pointwise marginal distributions of each quantity; in particular, the means (magenta lines)
    and 95\% credible intervals (shaded regions). The black lines are ground truth (no emulation) and the gray dashed lines 
    indicate the locations of the design inputs used to train the surrogates. The respective rows represent the surrogate-induced 
    distributions over the \emph{(1)} forward model, \emph{(2)} unnormalized log-posterior density, \emph{(3)} unnormalized 
    posterior density, and \emph{(4)} normalized posterior density. The top middle and top right entries are blank because the 
    log-density surrogates do not produce an approximation of the forward model. The magenta lines in the third and fourth 
    rows represent \texorpdfstring{$\postApproxEUP$}{the unnormalized EUP} and \texorpdfstring{$\postApproxEP$}{the EP}, 
    respectively (see \Cref{sec:post-approx}).}
    \label{fig:em_dist_1d}
\end{figure}


% Surrogate-Based Posterior Approximation
\section{Surrogate-Based Posterior Approximation} \label{sec:post-approx}
The ultimate objective of Bayesian inference is to characterize the posterior distribution 
$\postDensNorm$, which is then used for downstream decision-making. Consequently, the 
central challenge in surrogate-based Bayesian inference is not merely fitting the emulator, but 
effectively utilizing it to approximate $\postDensNorm$ \citep{StuartTeck1,SinsbeckNowak}. 
Any discrepancy between the emulator and the target map introduces bias into the posterior estimate. 
While iterative refinement can asymptotically eliminate this bias (\Cref{sec:active-learning}), 
computational budgets often preclude this luxury. To mitigate bias and properly calibrate uncertainty, 
the surrogate's predictive uncertainty must be acknowledged within the posterior approximation
\citep{BilionisBayesSurrogates,ourSurrPropPaper}. However, as noted by \citet{BurknerSurrogate}, 
there is no single ``correct'' mechanism for propagating 
surrogate uncertainty. In this section, we survey the conceptual frameworks for deriving these 
approximations and detail specific estimators proposed in the literature.

\subsection{The Plug-In Mean}
We begin by establishing a baseline: ignoring surrogate uncertainty entirely. The \inlinedef{plug-in mean} 
approximation replaces the random surrogate with its deterministic predictive mean $\emMean$, yielding:
\begin{equation}
\postApproxNormMean(\Par) \Def \postDens(\Par; \emMean) / \normCst(\emMean).
\label{eq:mean-approx}
\end{equation}
While computationally straightforward and widely applied
\citep{VehtariParallelGP,trainDynamics,emPostDens,BurknerSurrogate,CLMBayesianCalibration,Lueckmann2018LikelihoodfreeIW,BilionisBayesSurrogates}, 
this approach is only justified if the emulator is highly accurate, an assumption rarely satisfied in complex problems. 
In general, disregarding the surrogate uncertainty leads to posterior 
approximations that are both biased and 
overconfident \citep{BurknerSurrogate,BilionisBayesSurrogates,StuartTeck1,ourSurrPropPaper}.

\subsection{Frameworks for Constructing Posterior Estimators}
To move beyond the plug-in baseline, we outline four conceptual frameworks that
provide a rigorous foundation for the propagation of surrogate uncertainty.

\subsubsection{Summarizing a Random Measure} \label{sec:random-measure}
Given that the emulator $\targetEm$ is a random function, the induced posterior $\postNormEm$ is a random density
\footnote{More generally, this is a random probability measure. We work with densities to avoid measure-theoretic technicalities.}
\footnote{Assuming $\targetEm$ is constructed such that $\postNormEm$ is well-defined.}. 
One principled approach is to construct a deterministic approximation that best summarizes this random measure. 
\citet{ourSurrPropPaper} formalize this via the variational objective
\begin{equation}
\qDensNormOpt \Def \argmin_{\qDensNorm \in \qSpaceNorm} \emE[\loss(\qDensNorm, \postNormEm)],
\label{eq:random-measure-variational}
\end{equation}
for a loss function $\loss$ and space of densities $\qSpaceNorm$.
Estimators derived from this perspective naturally account for the coupling between the unnormalized density and the 
normalizing constant. However, the global dependence on $\normCstEm$ (a function of the 
entire surrogate $\targetEm$) often renders inference challenging for approximations of this form.
The random measure perspective is introduced in \citet{StuartTeck1} and adopted in 
\citet{ourSurrPropPaper,StuartTeck2,random_fwd_models,TeckHyperpar}.

\subsubsection{Decision Theory for Unnormalized Densities} \label{sec:decision-theory}
To circumvent the difficulties stemming from the random normalizing constant, an alternative approach
is to estimate the \textit{unnormalized} density $\postEm$ directly. This approach is computationally 
attractive as $\postEm(\Par)$ depends only on the marginal distribution of $\targetEm(\Par)$. Adopting a 
decision-theoretic viewpoint \citep{SinsbeckNowak}, we seek the estimator $\qDensOpt$ that minimizes the 
expected loss
\begin{equation}
\qDensOpt \Def \argmin_{\qDens \in \qSpace} \emE[\loss(\qDens, \postEm)],
\label{eq:decision-theory}
\end{equation}
over a set of candidate functions $\qSpace$. The final approximate posterior is obtained by normalizing 
$\qDensOpt$ post-hoc. While computationally convenient, these \inlinedef{pointwise estimators} ignore the 
correlation structure of the surrogate \citep{ourSurrPropPaper}, as well as the probabilistic coupling between
$\normCstEm$ and $\postEm(\Par)$. This decision theoretic approach was originally proposed in 
\citet{SinsbeckNowak} and subsequently utilized in \citet{VehtariParallelGP,gpEmMCMC,StuartTeck2}.

\subsubsection{Generalized Bayesian Inference} \label{sec:generalized-bayes}
Pointwise estimators can alternatively be viewed through the lens of 
Generalized Bayesian Inference \citep{Bissiri2016,knoblauch2019}. The starting point of this approach 
entails the specification of a loss function $\gibbsloss(\Par; \targetEm)$.
Viewing this loss as a random function of $\targetEm$, let $\risk$ 
denote a risk functional mapping $\Par$ to a deterministic summary of the random variable $\gibbsloss(\Par; \targetEm)$;
for example, $\risk(\Par) \Def \emE[\gibbsloss(\Par; \targetEm)]$.
The posterior approximation is defined as the density minimizing the regularized risk
\begin{align}
\qDensNormOpt \Def \mathrm{arginf}_{\qDensNorm \in \qSpaceNorm} 
\left\{\int \risk(\Par) \qDensNorm(\d\Par) + \frac{1}{\gibbsrate} \KL{\qDensNorm}{\priorDens} \right\}
\label{eq:gen-bayes-opt}
\end{align}
over the space of densities $\qSpaceNorm$
\footnote{Let $\KL{p}{q} \Def \int \log(p/q) \d p$ denote the Kullback-Leibler (KL) divergence between two densities.}
\footnote{Under this construction, we assume that the prior density is external to the surrogate model,
thus excluding log-posterior emulators.}.
Under conditions detailed in \citet{Bissiri2016}, the optimum 
assumes the form
\begin{align}
\qDensNormOpt \propto \priorDens(\Par) \Exp{-\gibbsrate \risk(\Par)}.
\end{align}
The learning rate $\gibbsrate$ governs the weight of the loss relative to the prior. This framework is particularly useful 
for robustifying inference against surrogate misspecification; by tuning $\gibbsrate$, one can temper the posterior to 
account for errors in the emulator \citep{Bissiri2016}. 

\begin{remark}
With $\gibbsrate = 1$ and particular definitions 
of $\risk$, this framework is equivalent to the decision theoretic construction in the preceding section.
For example, using the squared $L^2$ loss $\loss(\qDens, \postEm) = \norm{\qDens - \postEm}^2_{L^2(\parSpace)}$
in \Cref{eq:decision-theory} yields the same posterior estimate as would be obtained by setting
$\gibbsrate = 1$ and $\risk(\Par) = -\log \E[\lik(\Par; \targetEm)]$ in \Cref{eq:gen-bayes-opt}.
\end{remark}

\subsubsection{Uncertainty Propagation via Computation} \label{sec:unc-prop-computation}
Finally, rather than defining an explicit target density, the posterior approximation can be defined 
\textit{implicitly} as the output of a randomized algorithm. \citet{gpEmMCMC} adopt this perspective,
seeking to characterize how emulator uncertainty propagates through an MCMC algorithm.
\citet{FerEmulation,ourSurrPropPaper} each consider algorithms
that involve sampling the surrogate model at each iteration of an MCMC scheme.
Such methods, closely related to noisy MCMC \citep{noisyMCSurvey,noisyMCMC}, 
treat inference as a direct forward propagation of surrogate uncertainty through the sampling machinery.


\subsection{Concrete Posterior Estimators}
We now examine specific estimators derived from these frameworks.

\subsubsection{The Expected Posterior (EP)}
Under the random measure framework (\Cref{sec:random-measure}), minimizing the expected KL-divergence 
yields the mean of the random density, or the \inlinedef{expected posterior (EP)}
\footnote{The label \textit{expected posterior} is borrowed from \citet{BurknerSurrogate}.}:
\begin{align}
\postApproxEP(\Par) \Def \emE[\postDensNorm(\Par; \targetEm)] = \int \postDensNorm(\Par; \targetTraj) \emDist(\d\targetTraj).
\label{eq:ep}
\end{align}
\citet{ourSurrPropPaper} derive the EP from this perspective and argue for its use as a principled default 
posterior approximation in many applications. Functionally, the EP is a mixture distribution averaging the 
posteriors induced by all possible surrogate trajectories. This interpretation suggests a nested sampling 
scheme (\Cref{alg:ep}) to marginalize over the trajectories $\targetTraj \sim \emDist$.

\begin{algorithm}[H]
    \caption{Direct sampling from $\postApproxEP$}
    \label{alg:ep}
    \begin{algorithmic}[1]
    \Function{sampleEP}{$\postNormEm, \NSample, M$}     
        \For{$\sampleIndex \gets 1, \dots, \NSample$} 
        		\State $\targetTraj^{(\sampleIndex)} \sim \emDist$ \Comment{Sample emulator trajectory}
		\State $\Par^{(\sampleIndex, 1)}, \dots, \Par^{(\sampleIndex, M)} \sim \postDensNorm(\cdot; \targetTraj^{(\sampleIndex)})$ \Comment{Sample posterior given trajectory}
	\EndFor
	\State \Return $\{\Par^{(\sampleIndex, m)}\}_{1 \leq \sampleIndex \leq \NSample, \ 1 \leq m \leq M}$
	\EndFunction
    \end{algorithmic}
\end{algorithm}

A practical implementation of this algorithm typically employs Metropolis-within-Monte-Carlo (MwMC), in which 
a separate MCMC scheme is run for each iteration of the loop (line 2) in order to produce approximate samples $\Par^{(\sampleIndex, m)}$
from each posterior trajectory $\postDensNorm(\cdot; \targetTraj^{(\sampleIndex)})$ \citep{garegnani2021NoisyMCMC, BurknerSurrogate}.
However, sampling full trajectories (line 3) is non-trivial for infinite-dimensional models like GPs, a limitation that 
likely hindered early adoption of the EP \citep{StuartTeck1,SinsbeckNowak,VehtariParallelGP}. Recent advances have proposed 
approximate schemes tailored for GP emulators to overcome this challenge \citep{ourSurrPropPaper,trainDynamics}.

\subsubsection{The Expected Unnormalized Posterior (EUP)}
To avoid integrating over the normalizing constant, as required by the EP, one can average the numerator 
and denominator independently. This yields the \inlinedef{expected unnormalized posterior (EUP)}
\footnote{
\citep{StuartTeck1,StuartTeck2,GP_PDE_priors} refer to this as the \textit{marginal} approximation,
while \citep{BurknerSurrogate} instead use the term \textit{expected likelihood}. We prefer 
\textit{expected unnormalized posterior}, as used in \citet{ourSurrPropPaper}, since it also encompasses
log-posterior emulators.
}:
\begin{align}
\postApproxEUPNorm(\Par) \Def \frac{\emE[\postEm(\Par)]}{\emE[\normCstEm]}.
\label{eq:eup}
\end{align}
The EUP corresponds to the $L^2$-optimal estimator under the unnormalized decision-theoretic framework 
\citep{SinsbeckNowak}. Because the expectation $\emE[\postEm(\Par)]$ can often 
be computed in closed form (see examples below) or unbiasedly estimated, the EUP enables the use 
of standard MCMC or pseudo-marginal \citep{pseudoMarginalMCMC} algorithms \citep{garegnani2021NoisyMCMC}.

\begin{table}
\centering
\begin{tabular}{>{\raggedright\arraybackslash}p{2.2cm} >{\centering\arraybackslash}p{3.8cm} >{\centering\arraybackslash}p{4.2cm} >{\centering\arraybackslash}p{4.2cm}}
\toprule
& \textbf{Plug-In Mean} & \textbf{EUP} & \textbf{EP} \\
\midrule
\textbf{Ratio Estimator} & 
$\displaystyle \frac{\postDens(\Par; \emE[\targetEm])}{\normCst(\emE[\targetEm])}$ &
$\displaystyle \frac{\emE[\postDens(\Par; \targetEm)]}{\emE[\normCst(\targetEm)]}$ &
$\displaystyle \emE\left[\frac{\postDens(\Par; \targetEm)}{\normCst(\targetEm)}\right]$ \\ [4ex]

\textbf{Mixture Dist.} & 
$\int \postDensNorm(\Par; \targetTraj) \delta_{\emMean}(\d\targetTraj)$ & 
$\int \postDensNorm(\Par; \targetTraj) \emDist(\d\targetTraj \given \obs)$ & 
$ \int \postDensNorm(\Par; \targetTraj) \emDist(d\targetTraj)$ \\
\bottomrule
\end{tabular}
\caption{Different perspectives on normalized density approximations defined by various forms of averaging.
	     The top row highlights interpretations as ratio estimators; only the EP considers the 
	     coupling between the numerator and denominator. The second row shows that each
	     approximation can be viewed as a weighted mixture over surrogate-induced posterior 
	     trajectories. We write $\emDist(\d\targetTraj \given \obs)$ to denote the distribution
	     proportional to $\normCst(\targetTraj) \emDist(\d\targetTraj)$, and $\delta_{\emMean}$
	     the Dirac measure centered at $\emMean$.}
\label{tab:post-approx-comparison}
\end{table}

The EUP is originally proposed in \citet{BilionisBayesSurrogates}, in which it is derived as 
the marginal posterior $p(\Par \given \obs)$ under the hierarchical model
\begin{equation}
\targetTraj  \sim \emDist, \qquad 
\Par \sim \priorDens, \qquad
\obs \given \targetTraj, \Par \sim \lik(\Par; \targetTraj, \d\obs),
\label{eq:eup-prob-model}
\end{equation}
a perspective also noted in \citet{SinsbeckNowak,StuartTeck1,StuartTeck2,ourSurrPropPaper}.
\citet{StuartTeck1,StuartTeck2,random_fwd_models} establish Hellinger bounds between the EUP
and ground truth posterior when using GP emulators.
 \citet{ourSurrPropPaper} study the EUP as an approximation
to the EP, demonstrating that the two distributions can deviate when 
the distribution of $\postEm(\Par)$ varies significantly with $\Par$, especially when these pointwise
distributions are heavy-tailed.
 \Cref{tab:post-approx-comparison} compares the plug-in mean, EUP,
and EP estimators as (i) ratio estimators, and (ii) mixture distributions aggregating surrogate-induced
posterior trajectories. 

\begin{examplebox}{EUP, Gaussian Forward Model Emulator}{eup-fwd-em}
Consider the setting from \Cref{ex:fwd-em}, where
$\postEm(\Par) = \priorDens(\Par) \Gaussian(\obs \given \targetEm(\Par), \likPar)$
and $\targetEm(\Par) \sim \Gaussian(\emMean(\Par), \emVar(\Par))$.
Under these assumptions, the EUP is given by
\begin{align}
\postApproxEUPNorm(\Par)
&\propto \emE\left[\priorDens(\Par)\Gaussian(\obs \given \targetEm(\Par), \likPar) \right] \nonumber \\
&= \priorDens(\Par) \Gaussian(\obs \given \emMean(\Par), \likPar + \emVar(\Par)). \label{eq:eup-gaussian}
\end{align}
Thus, in this setting the EUP admits a natural data space interpretation. 
The original inverse problem $\obs = \fwd(\Par) + \noise$ is replaced by
$\obs = \emMean(\Par) + \eta(\Par) + \noise$, with the parameter-dependent
noise term $\eta(\Par) \sim \Gaussian(0, \emVar(\Par))$ accounting for the 
uncertainty in the forward model \citep{CES,StuartTeck1}. Observe that
$\postApproxEUP(\Par) \to \priorDens(\Par)$ as $\emVar(\Par) \to \infty$,
implying that ignorance regarding the true forward model results in 
prior reversion \citep{ourSurrPropPaper}. The particular EUP estimator in \Cref{eq:eup-gaussian}
is utilized in \citet{Surer2023sequential,weightedIVAR,StuartTeck2,GP_PDE_priors,CES,
idealizedGCM,villani2024posteriorsamplingadaptivegaussian,hydrologicalModel,hydrologicalModel2}.
\end{examplebox}

\begin{examplebox}{EUP, Gaussian Log-Likelihood Emulator}{eup-ldens-em}
Recall the setup from \Cref{ex:ldens-em}, where $\postEm(\Par) = \priorDens(\Par)\Exp{\targetEm(\Par)}$
and $\targetEm(\Par) \sim \Gaussian(\emMean(\Par), \emVar(\Par))$.
Under these assumptions, the EUP is given by
\begin{align}
\postApproxEUPNorm(\Par)
&\propto \emE\left[\priorDens(\Par)\Exp{\targetEm(\Par)} \right] \nonumber \\
&= \priorDens(\Par) \Exp{\emMean(\Par) + \frac{1}{2} \emVar(\Par)} \label{eq:eup-ldens-gauss} \\
&= \postApproxMean(\Par) \Exp{\frac{1}{2} \emVar(\Par)}. \nonumber
\end{align}
The final expression demonstrates that, in this setting, the EUP inflates the plug-in mean estimator
where uncertainty is large \citep{StuartTeck1,StuartTeck2,VehtariParallelGP}. 
The estimator scales very quickly as surrogate uncertainty increases, with 
$\postApproxEUP(\Par) \to \infty$ as $\emVar(\Par) \to \infty$.
Thus, unlike the forward model analog in \Cref{ex:eup-fwd-em}, the EUP does not exhibit prior
reversion under surrogate ignorance \citep{ourSurrPropPaper}.
Due to the exponential dependence in \Cref{eq:eup-ldens-gauss}, this distribution can be highly 
sensitive to small changes in $\emMean(\Par)$ and $\emVar(\Par)$, making it particularly susceptible to 
extreme concentration in small regions with large uncertainty \citep{ourSurrPropPaper,VehtariParallelGP}.
This is illustrated in \Cref{fig:post_norm_approx_ldensem}, in which the EUP is effectively a point mass
centered at the most uncertain location.
\end{examplebox}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth, height=0.98\textheight, keepaspectratio]{post_approx_grid.pdf}

    \caption{A continuation of the example in \Cref{fig:em_dist_1d}. From left to right, the columns correspond
    	to the GP forward model emulator, GP log-posterior emulator, and clipped GP log-posterior emulator.
	The top row summarizes the pointwise marginal distributions of 
	\texorpdfstring{$\log \postEm(\Par)$}{the log unnormalized posterior approximation}, showing the 
	mean (magenta line) and 90\% intervals against the true log-posterior (black). The bottom
	row presents different normalized posterior approximations relative to the true posterior (blue line). The
	vertical dashed lines indicate the locations of the design points.}
        \label{fig:post_norm_approx_1d}
\end{figure}

 
\subsubsection{Other Pointwise Estimators}
The instability of the EUP in log-density emulation (\Cref{ex:eup-ldens-em}) has motivated alternative pointwise estimators.
\begin{itemize}
    \item \textbf{Marginal Quantiles:} To improve robustness, \citet{VehtariParallelGP} propose using pointwise quantiles of 
    $\postEm(\Par)$ rather than the mean. As detailed in \Cref{ex:quantile-pw-ldens-em}, setting the quantile probability 
    $\quantileProb > 0.5$ inflates the posterior in regions with higher uncertainty, but scales more moderately relative to the EUP.
    \item \textbf{Marginal Modes:} \citet{gpEmMCMC} utilize the pointwise mode of $\postEm(\Par)$. This effectively penalizes 
    regions with high surrogate variance, encouraging the posterior to decay in these regions. While this can have the desirable
    effect of promoting tail decay in the posterior estimate, it neglects uncertain regions that may in reality contain posterior mass.
    \item \textbf{Expected Log-Likelihood:} In the forward model emulation setting, \citet{BurknerSurrogate} consider a
    posterior estimate proportional to \\ $\priorDens(\Par) \Exp{\emE[\log \lik(\Par; \targetEm)]}$ and draw 
    a connection with power-scaled likelihoods. However, the authors ultimately recommend the EP and EUP as preferred 
    alternatives to this method.
\end{itemize}

\begin{examplebox}
{Quantile Estimator, Gaussian Log-Likelihood Emulator}
{quantile-pw-ldens-em}
We return to the setting from \Cref{ex:ldens-em} with a Gaussian log-likelihood emulator. 
Let $\emQ(\cdot)$ denote the $\quantileProb \in (0, 1)$ quantile of its argument with respect to $\emDist$. 
A quantile-based estimate in this setting takes the form
\begin{align*}
\postApproxQuantileNorm(\Par) \propto
\priorDens(\Par) \emQ(\Exp{\targetEm(\Par)})
&= \priorDens(\Par) \Exp{\emMean(\Par) + \GaussianCDF^{-1}(\quantileProb) \emSD(\Par)} \\
&= \postApproxMean(\Par) \Exp{\GaussianCDF^{-1}(\quantileProb) \emSD(\Par)},
\end{align*}
where $\GaussianCDF$ is the standard Gaussian distribution function. This expression is of the same form 
as the EUP in \Cref{ex:eup-ldens-em}, but the uncertainty inflation term scales more slowly as a function
of $\emSD(\Par)$. The special case $\quantileProb = 1/2$ (i.e., the median) 
reduces to the plug-mean approximation, while values $\quantileProb > 1/2$ imply 
the density will be inflated in regions of higher surrogate uncertainty. The quantile approximation
arises from the decision theoretic viewpoint by considering losses of the $L_1$ variety
\citep{VehtariParallelGP,gpEmMCMC}. Quantile-based estimators are also utilized in
\citet{quantileApprox,FATES_CES}.
\end{examplebox}

\section{Active Learning for Bayesian Inversion} \label{sec:active-learning}
Up until this point, we have considered a fixed surrogate model fit to training data 
obtained from simulator runs at a set of design points $\design \Def \{\Par_1, \dots, \Par_{\Ndesign}\}$.
The simplest approach to select these points is to sample from some distribution over $\parSpace$
(e.g., the prior $\priorDens$). Such a ``one-shot'' design is appealing in that it allows for maximal 
parallelism in simulator runs. However, the posterior distribution commonly concentrates on a small 
subset of the prior support, implying that a prior-based 
design will likely allocate the majority of points in regions with negligible posterior mass.
In many such cases, one cannot hope to achieve an acceptable posterior approximation with 
a static design based solely on prior information. 

To address this issue, the design can instead be constructed 
sequentially, with information from the current simulations used to inform the selection of new design points.
We refer to this broad class of algorithms as \inlinedef{active learning} for Bayesian inverse problems.
At the extreme end of this spectrum is a \inlinedef{pure sequential} strategy, where simulations are performed serially, 
one at a time. This allows for the most informed design point selection, but fails to exploit parallel computing 
resources and is thus impractical in many large-scale applications.
To balance these extremes, practical approaches typically adopt a batch-sequential workflow: simulator runs are 
spread across multiple rounds, with a batch of model runs executed in parallel each round
\footnote{This is the ``synchronous parallel'' setting. 
For simplicity, we do not discuss asynchronous parallel approaches here \citep{parallelBOThompson}.}.
The central challenge faced by such algorithms is navigating the ``exploration vs. exploitation'' 
trade-off \citep{reviewBayesOpt,BadiaRL}. Active learning schemes must exploit current information 
to refine the surrogate in known high-probability regions, while simultaneously exploring high-uncertainty 
areas to avoid missing other important regions.

Active learning algorithms have been explored extensively in the context of Bayesian inference. Our focus
here is on the sub-class of methods where design points are selected sequentially to refine a surrogate
model with the goal of improving a posterior approximation. We identify three (non-mutually exclusive)
strategies that are commonly used for this purpose:
\begin{enumerate}
    \item \inlinedef{Design Optimization}: Explicitly optimizing an objective function to select the next batch of points.
    \item \inlinedef{Tempering}: Constructing a sequence of intermediate target densities to guide the surrogate toward the posterior.
    \item \inlinedef{MCMC-based Exploration}: Embedding the design construction directly within a posterior sampling algorithm.
\end{enumerate}

\subsection{Design Optimization}
Many active learning algorithms explicitly define a design criterion, or \inlinedef{acquisition function}, that quantifies the utility 
of running the simulator at a set of candidate locations. This objective function is then optimized at each round
of the active learning procedure to select the next batch of design points. Similar approaches are also widely applied in other
applications involving surrogate models. For example, the field of Bayesian optimization focuses on defining 
acquisition functions tailored to the optimization of  black-box functions \citep{reviewBayesOpt}. Acquisition functions for 
Bayesian inversion are analogous, but should instead encode the explicit goal of estimating the posterior distribution.

To better appreciate the considerations involved in defining an acquisition function, it is useful to consider how the 
criterion should behave in the absence of uncertainty. In Bayesian optimization, clearly the ideal behavior is to 
return the optimum of the function being optimized. In the present context, it is less clear which arrangement of points 
is optimal in representing a posterior distribution. Results suggest that the points should be sampled from an 
over-dispersed variant of the posterior, thereby ensuring adequate coverage of the tails \citep{StuartTeck2,briol2017sampling}. 
These results are consistent with the intuitive notion that design points should be placed in high-probability regions, while also 
ensuring adequate coverage to constrain the global surrogate behavior. With imperfect information, acquisition functions must 
balance this ideal with the need to reduce uncertainty in poorly explored regions.

The following sections explore design criteria that seek to navigate this particular flavor of an exploration-exploitation tradeoff.
We begin by formalizing the problem, discuss theoretical frameworks used for deriving design criteria, and then 
offer a survey of concrete acquisitions used in the literature. We close the section with a brief discussion of practical methods for 
carrying out the optimization of acquisition functions. 

\subsubsection{Formalizing the Design Optimization}
Throughout this section, we consider an emulator $\targetEm$ that has been conditioned on an existing design 
$(\design, \target(\design))$, with the goal being to select a new batch $\ParBatch \subset \parSpace$ of $\Nbatch$ design points. 
For an acquisition function $\acq: \parSpace^\Nbatch \to \R$, the design selection problem is formalized as 
\begin{equation}
\ParBatchOpt \Def \argmin_{\ParBatch \in \parSpace^\Nbatch} \acq(\ParBatch).
\end{equation}
Let $\ParBatchAug \Def \design \cup \ParBatch$ denote the extended set of design points, $\targetEm[\Naugment]$
the updated surrogate, and $\postEm[\Naugment]$ the resulting unnormalized posterior approximation. We will find 
it useful to make explicit the dependence of $\targetEm[\Naugment]$ and $\postEm[\Naugment]$ on 
$(\ParBatch, \target(\ParBatch))$. For this purpose, we let $\batchResponse \Def \target(\ParBatch)$ and write 
$\targetEm[\Naugment]^{\ParBatch,\batchResponse}$ and $\postEm[\Naugment]^{\ParBatch,\batchResponse}$.
We utilize similar notation for other quantities depending on $\ParBatch$ and $\batchResponse$.

\begin{remark}
The particular process of updating the surrogate from $\targetEm$ to $\targetEm[\Naugment]$ will depend on the
particular model in use. For GP surrogates, this entails conditioning 
$\targetEm[\Naugment] \Def \targetEm \given [\targetEm(\ParBatch) = \target(\ParBatch)]$, typically requiring 
$\BigO(\Ndesign^2 \Nbatch + \Nbatch^3)$ operations. The GP hyperparameters may also be updated, at the 
cost of $\BigO([\Ndesign + \Nbatch]^3)$ scaling. For parametric models, the surrogate update will entail 
re-estimation of the model parameters using the augmented dataset.
\end{remark}


\subsubsection{Frameworks for Design Criteria}
Similar to the posterior estimators in \Cref{sec:target-map}, design criteria are commonly derived from rigorous, first-principles frameworks.

\paragraph{Decision Theoretic Framework.}
Recall the unnormalized density decision theoretic framework formalized in \Cref{eq:decision-theory}, whereby
an unnormalized posterior estimate is chosen as the optimizer of an expected loss:
\begin{equation}
\qDens_\Ndesign \Def \argmin_{\qDens \in \qSpace} \emE[\loss(\qDens, \postEm)].
\end{equation}
The minimal value of the objective function is known as the \textit{Bayes' risk}:
\begin{equation}
\bayesrisk \Def \emE[\loss(\qDens_\Ndesign, \postEm[\Ndesign])].
\end{equation}
If the surrogate is updated using $(\ParBatch, \batchResponse)$, it will yield a corresponding Bayes' risk
$\bayesrisk[\Naugment]^{\ParBatch,\batchResponse}$. A natural design strategy is to choose $\ParBatch$
so that this risk is as small as possible. The problem, of course, 
is that we generally cannot compute this quantity without evaluating $\batchResponse = \target(\ParBatch)$.
Thus, we marginalize these values under the assumption $\batchResponse \sim \emDist(\ParBatch)$, which
models the unobserved responses according to the current surrogate. This yields an acquisition function of the form 
\begin{equation}
\acq(\ParBatch) \Def \E_{\batchResponse \sim \emDist(\ParBatch)}\left[\bayesrisk[\Naugment]^{\ParBatch,\batchResponse}\right].
\end{equation} 
Below we will explore some special cases where the Bayes' risk is not a function of $\batchResponse$, thus conveniently 
eliminating the expectation over $\targetEm(\ParBatch)$.

\paragraph{Stepwise Uncertainty Reduction (SUR).}
\textit{Stepwise Uncertainty Reduction (SUR)} is another theoretical framework that has been used to develop 
and analyze sequential design algorithms for applications such as optimization and 
reliability analysis \citep{supermartingaleSUR,BectSUR}. The
framework has also recently been used in solving Bayesian inverse problems \citep{lartaudSUR}.
Let $\surmetric(\targetEm)$ denote a metric that maps to some scalar-valued notion of uncertainty we would
like to minimize. SUR acquisition functions are defined as the expected one-step-ahead uncertainty
\begin{equation}
\acq(\ParBatch) \Def \E_{\batchResponse \sim \emDist(\ParBatch)}\left[\surmetric(\targetEm[\Naugment]^{\ParBatch,\batchResponse})\right].
\end{equation}
This framework is quite general, and particular choices of $\surmetric$ coincide with criteria derived using the 
Bayesian decision theoretic approach. The primary benefit of SUR is theoretical, as it provides general conditions 
to ensure that the uncertainty will converge to zero if the algorithm is repeated indefinitely. 

\subsubsection{Local Single-Point Criteria}
Before describing acquisition functions derived from the above frameworks, we introduce some 
common heuristic strategies. When optimizing for a single design point ($\Nbatch = 1$), an intuitive 
strategy is to simply select the input where the uncertainty in $\postNormEm(\Par)$ is largest.
Owing to the challenge of dealing with the random normalizing constant $\normCstEm$,
previous work has opted to instead target the uncertainty in the unnormalized density 
$\postEm(\Par)$. If predictive variance
is used as the measure of uncertainty, this yields the \textit{maximum variance} criterion
\begin{equation}
\acq(\Par) \Def -\Var_{\Ndesign}[\postEm(\Par)], \label{eq:acq-maxvar}
\end{equation}
which is negated to align with our convention of minimizing acquisition functions.
Alternative ``maximum uncertainty'' criteria can be defined by changing the measure
of uncertainty (e.g., variance, entropy, interquartile range) and the target quantity
(e.g., $\postEm$, $\targetEm$). For example, targeting the 
maximum variance of $\targetEm(\Par)$ yields a classical criterion 
used for exploration of response surfaces \citep[Section 6.2.1]{gramacy2020surrogates}.
However, this criterion tends not to perform well in the Bayesian inference setting
since it does not take into account the magnitude of the posterior density. 
It may be that $\targetEm(\Par)$ is highly uncertain, but 
$\postDens(\Par; \targetEm)$ concentrates on a very small value.
The maximum variance criterion is utilized 
in \citet{Lueckmann2018LikelihoodfreeIW,Kandasamy_2017,AlawiehIterativeGP}.
In the GP log-density emulator setting (\Cref{eq:llik-em-Gaussian})
$\postEm[\Ndesign](\Par)$ is log-normal. Given the heavy tails and asymmetry of a log-normal 
random variable, \citep{VehtariParallelGP,wang2018adaptive} argue that the variance provides a 
misleading measure of uncertainty in this setting, instead favoring the entropy or interquartile range. 

As an alternative to these maximum uncertainty criteria, \citet{gp_surrogates_random_exploration}
suggest explicitly decoupling exploration and exploitation by selecting one point 
that maximizes $\emE[\log \postEm(\Par)]$ and randomly sampling a second point from 
$\priorDens$. \citet{Takhtaganov2018AdaptiveBayesianGP} employs the expected improvement
criterion from Bayesian optimization to target the placement of new design points in high-posterior regions.

While nominally designed for the pure sequential $\Nbatch = 1$ settings, these single-point criteria can be 
adapted for batch acquisition using heuristic strategies. The \textit{Kriging Believer} and \textit{Constant Liar} heuristics
\citep{Ginsbourger2010}.
\todo[inline]{clean this up / move some to example box / describe these better}

\subsubsection{Global Multipoint Criteria}
While computationally convenient, single-point criteria suffer from two primary drawbacks: (1) they are not 
naturally defined in the batch sequential setting; and (2) they are purely local, neglecting the global impact a 
new design point has across $\parSpace$. The latter property commonly results in maximum uncertainty 
criteria targeting points in the edges or tails of the parameter space. We now introduce a class of acquisition
functions, referred to as \inlinedef{Expected Conditional Uncertainty (ECU)} criteria, that address 
both of these limitations.

Intuitively, ECU acquisitions arise from the following logic: we would like to select an input batch 
$\ParBatch$ that results in an updated (unnormalized) posterior estimate $\postEm[\Naugment]$ with the lowest
possible uncertainty on average over $\parSpace$. Given that we cannot typically compute this uncertainty without
observing $\target(\ParBatch)$, we utilize the same approach described for the Bayes' risk 
and marginalize over this quantity with respect to the current predictive distribution $\emDist$. As a concrete example, 
if we again choose variance as our measure of uncertainty, we have
\begin{equation}
\acq(\ParBatch) \Def 
\int_{\parSpace} \E_{\gamma} \left\{\Var_{\Naugment}[\postDens(\Par; \targetEm[\Naugment]^{\ParBatch,\gamma}) \given \gamma]\right\} \ \weightdens(\Par) \d\Par,
 \label{eq:acq-intvar}
\end{equation}
Variations of 
ECU criteria can be created by changing the measure of uncertainty (e.g., variance, entropy, interquartile range),
the target quantity (e.g., $\postEm$, $\funcEm$), and the weighting measure $\weightdens$.
For example, targeting the variance of $\funcEm$ with uniform weighting measure yields the
classical integrated mean squared prediction error \citep{Mercer_kernels_IVAR}.

Outside of special cases \citep{Binois_2018,MakTargetedVar,Koermer2024} the outer integral (over $\parSpace$) 
in ECU criteria is not tractable. This is especially the case in our present setting,
and thus we focus on the sample average approximation \citep{Mercer_kernels_IVAR,botorch},
\begin{align}
&\acq(\ParBatch) \Def \frac{1}{J}
\sum_{j=1}^{J} \E_{\gamma} \left\{\Var_{\Naugment}[\postDens(\Par_j; \targetEm[\Naugment]^{\ParBatch,\gamma}) \given \gamma]\right\},
&&\Par_j \overset{\mathrm{iid}}{\sim} \weightdens.
 \label{eq:acq-intvar-saa}
\end{align}
The $\Par_j$ are sampled at the beginning of the sequential design round and then fixed, so that
\Cref{eq:acq-intvar-saa} is viewed as a deterministic objective function. 
The expected variance terms in the summands admit closed forms in the Gaussian 
settings of \Cref{eq:fwd-em-Gaussian,eq:llik-em-Gaussian}, as shown below. As an alternative to 
\Cref{eq:acq-intvar-saa}, we can consider an ECU criterion that targets uncertainty in the underlying
emulator $\targetEm[\Ndesign]$, but acknowledges the goal of posterior approximation through the choice
of $\weightdens$; i.e., 
\begin{align}
&\acq(\ParBatch) \Def \frac{1}{J}
\sum_{j=1}^{J} \Var_{\Naugment}[\targetEm[\Naugment](\Par_j)],
&&\Par_j \overset{\mathrm{iid}}{\sim} \hat{\postNormEm},
 \label{eq:acq-intvar-lartaud-saa}
\end{align}
where $\hat{\postNormEm}$ is any of the approximate posteriors from \Cref{sec:post-approx}.
An acquisition function of this form is proposed in \citet{weightedIVAR}, and compares 
favorably against \Cref{eq:acq-intvar-saa}.


\begin{comment}

\subsubsection{Solving the Optimization Problem}

\subsection{Tempered Approximations}
In problems where the likelihood is highly informative, the posterior effectively becomes a "needle in a haystack" relative to the prior. Active learning schemes targeting the true posterior directly may fail to identify the high-mass region, exhausting the budget on exploring negligible areas.

A powerful remedy is \inlinedef{tempering}: introducing a sequence of intermediate distributions $\pi_0, \pi_1, \dots, \pi_T$, where $\pi_0 = \priorDens$ and $\pi_T = \postDens$. Common choices involve geometric bridges of the form $\pi_t(\Par) \propto \priorDens(\Par) \lik(\Par)^{\beta_t}$ with $0 = \beta_0 < \dots < \beta_T = 1$.
The surrogate is constructed sequentially to approximate each $\pi_t$ in turn. By the time the algorithm targets $\pi_T$, the surrogate has already resolved the broader basins of attraction, preventing mode collapse. This strategy is closely related to Sequential Monte Carlo (SMC) and has been adapted for surrogate modeling in methods such as \textit{adaptive Gaussian process approximation} \citep{wang2018adaptive, adaptiveMultimodal} and Ensemble Kalman Inversion \citep{EKI_review}.

\todo[inline]{\citep{wang2018adaptive,adaptiveMultimodal} present a related method in which surrogates are constructed 
to approximate a sequence of functions designed to be more regular than the log-likelihood.}

\subsection{MCMC-based Exploration}
A third class of strategies weaves the design construction directly into the execution of an MCMC chain. Rather than distinct "training" and "sampling" phases, the MCMC sampler acts as the exploration engine.

These methods generally fall into two sub-categories:
\begin{enumerate}
    \item \textbf{Exact-Approximate MCMC:} These algorithms asymptotically sample from the exact posterior. A typical heuristic is to use the surrogate to propose a move, and then decide whether to run the true simulator based on a specific trigger (e.g., if the surrogate error at that point is likely to affect the acceptance decision) \citep{conrad2016accelerating, noisyMCMC}.
    \item \textbf{Budget-Constrained Exploration:} Here, the MCMC chain is used primarily to discover high-probability candidates. If the chain encounters a region of high surrogate variance, the simulator is queried, and the surrogate is updated. Once the computational budget is exhausted, the final surrogate is frozen for inference. This approach is conceptually similar to "active learning" but uses the Markov chain dynamics to solve the maximization of the acquisition function implicitly \citep{gpEmMCMC, li2019adaptive}.
\end{enumerate}



% old section
\section{Sequential Strategies for Surrogate Construction} \label{sec:active-learning}

\subsection{Design Optimization}
In this section I want to emphasize acquisition functions that are tailored to the goal of improving the posterior approximation,
drawing a distinction to standard design criteria that are geared towards other goals (global response surface approximation
or optimization). I also want to highlight two flavors of criteria (see subsections below). I want to adopt the general viewpoint
of a sequential design loop that acquires a batch of points at each iteration. There is also a subtlety to get across regarding
the optimal selection of new design points. Even in the absence of surrogate uncertainty, there exists the question of where 
to optimally place design points to provide the best surrogate-based approximation of a probability distribution. Past work 
suggests that the tails of the distribution should be over-sampled (i.e., sample design points from an over-dispersed version
of the target distribution). In sequential design, this question is complicated by the fact that we also want to balance this with
the placement of points in regions that are currently uncertain. Design criteria need to weigh both of these things.
I would like to also discuss how criteria can be designed from the unnormalized density decision theoretic viewpoint, or 
other viewpoints discussed when constructing posterior estimators. Perhaps this section should mimic that previous section,
and first begin with a sub-section that lays out frameworks for deriving design criteria. Frameworks I know about are the 
unnormalized decision theoretic framework and stepwise uncertainty reduction. I'm sure there could be some interested
generalized Bayes viewpoints or a normalized posterior decision theoretic framework as well, which would be nice to
tie this closely to that previous section.

\subsubsection{Pointwise Criteria}
This encompasses criteria like maxvar/maxent that seek the single point where the quantity of interest (e.g., the unnormalized
posterior density) is most uncertain. These strategies are thus nominally for the pure sequential setting, but I want to highlight
that they can utilized for multi-point acquisition using heuristic techniques like kriging believer/constant liar, or other methods.

\subsubsection{Global Criteria}
This encompasses criteria that consider the uncertainty over the entire design space such as integrated variance/entropy
criteria. I want to highlight that pointwise criteria can often be converted to global criteria (maxvar to integrated variance).
The general pattern here is: maximum uncertainty criteria converted to integrated conditional uncertainty criteria. These
integrated criteria are naturally defined in the batch sequential setting, since the batch of points appears in the conditioning.
I also want to highlight that there are many goal-oriented ways to construct these criteria in the Bayesian inference setting:
the ``goal'' can be encoded in the both the integrand or the weighting measure in the integrated criteria. For example, 
we can consider the conditional variance of the unnormalized posterior and integrate this over the design space, weighted
uniformly or by the prior. Alternatively, we could consider the conditional variance of the underlying target map (e.g., the forward model)
and then weight the integral by the current posterior approximation. These both take into account the goal of posterior approximation
in some sense (i.e., place design points where the posterior is large as well as where there is surrogate uncertainty).  

\subsection{Tempered Approximations}
This section should highlight approaches that use some sort of likelihood tempering in addition to surrogate, which is common in 
techniques like sequential importance sampling and ensemble Kalman inversion. The motivation here is that the posterior 
may be very concentrated relative to the prior, so active learning schemes that target the fixed posterior over multiple iterations
may be quite inefficient and take a while to find the region of high posterior mass. This might be improved by instead targeting
intermediate distributions that act as stepping stones to the true posterior. This can be combined with acquisition criteria targeting
the intermediate distributions as well.

\subsection{MCMC-based Exploration}
This section is a catch-all for techniques that do sequential design within a single MCMC algorithm. This includes so-called 
``exact-approximate'' schemes which are designed to eventually sample from the true posterior, as well as approximate
schemes that only acquire new points until some sort of budget is exhausted. 


\section{Connection to Other Literatures}
\subsection{Amortized and Simulation-Based Inference} \label{sec:sbi}
\subsection{Computer Model Calibration}
\subsection{Modular Bayesian Inference}


For GP surrogates, a variety of design criteria (i.e., acquisition functions) have been 
proposed that seek to strike this balance in the context of solving Bayesian inverse problems \citep{SinsbeckNowak,Surer2023sequential,KandasamyActiveLearning2015,weightedIVAR,
VehtariParallelGP,VillaniAdaptiveGP,AlawiehIterativeGP}.

The exploration--exploitation question is one of decision making under uncertainty.   
Even if one had perfect knowledge about the true posterior, there remains the question concerning the optimal
placement of design points for surrogate-based posterior approximation. Insights into this question can guide
the development of improved design algorithms.
Various papers informally remark that accurate approximation requires design points only in the region where the 
posterior is large \citep{AlawiehIterativeGP} [\todo add other citations].
This statement is somewhat misleading, and should be amended as follows:
achieving an accurate posterior approximation
requires an accurate emulator in the subset of $\parSpace$ where the posterior is large, while also
containing enough global information to know where the posterior is small. This informal statement is 
put on rigorous footing in \citet{StuartTeck2}, with theoretical results suggesting designs based on 
an over-dispersed version of $\postDensNorm$. 
The notion of oversampling the tails has also been proposed to construct designs
for numerical integration \citep{briol2017sampling}. These results are consistent with the notion of 
constraining the global surrogate behavior, while also fine-tuning the local fit in high-probability regions.
Therefore, in addition to balancing exploration and 
exploitation when selecting design points, one must also consider this local-global tradeoff
\citep{StuartTeck2, gp_surrogates_random_exploration,emPostDens,SinsbeckNowak,Surer2023sequential,adaptiveMultimodal}.
The choice of design algorithm to navigate this tradeoff is problem-specific. For example, 
\citet{adaptiveMultimodal} propose an active learning strategy that specifically targets multimodal posteriors.
The choice will also be determined by the particular surrogate model being used. [\todo: didn't finish edits here]

The manner in which this tradeoff is navigated depends on the particular problem setup and 
the surrogate model itself. For example, \citet{adaptiveMultimodal} propose an active learning strategy 
targeting multimodal posteriors. Another promising line of research consists of adapting local approximations, 
avoiding the challenging task of fitting a single global surrogate \citep{Li_2014,ConradLocalExactMCMC}. 

In the following, we outline the general structure of an active learning algorithm and review design strategies 
that have been proposed for surrogate-based Bayesian inference. We place particular emphasis on 
the batch sequential design setting, where multiple design points are acquired simultaneously [\todo: use problem-solution here].
We conclude this section by briefly noting connections to so-called ``exact-approximate'' MCMC algorithms.
\end{comment}



%%%
\begin{comment}
%%%

\section{Modular Surrogate-Based Bayesian Workflow}
% maybe discuss the KOH joint model in the intro here?
\subsection{Initial Design}
\subsection{Surrogate Target}
\subsection{Posterior Approximation}
\subsection{Surrogate Refinement}

\section{Posterior Approximation}


% stuff to include in MCMC section
The pseudo-marginal approach to EUP-based inference is noted in \citep{StuartTeck1} and studied 
in depth in \citep{garegnani2021NoisyMCMC}. \citet{BurknerSurrogate} propose targeting the 
distribution proportional to $\hat{\postDens}^M(\Par; \targetTraj_{1:M})$, where $\targetTraj_{1:M}$
is fixed across all MCMC iterations. This does not target the EUP exactly, and can be viewed
as an analog of the sample average approximation from the optimization literature \citep{SAA}.
To improve MCMC efficiency, \citet{garegnani2021NoisyMCMC} also considers ``noisy'' approximations
of the EUP. In contrast to pseudo-marginal algorithms, these methods re-sample both 
$\targetTraj_{1:M}$ and $\tilde{\targetTraj}_{1:M}$ each iteration. 
\citet{FerEmulation} utilize a similar noisy algorithm with $M = 1$, adopting an
approximate computation viewpoint rather than explicitly trying to target $\postApproxEUPNorm$.

\paragraph{Infinite-Dimensional Model.} For an infinite-dimensional model, no such 
finite-dimensional parameter $\theta_{\Ndesign}$ exists. Typical examples include 
GPs and deep GPs. In this setting, a generic view of a 
surrogate model is as a map from finite sets of inputs $\parMat$ to a predictive distribution 
over the associated responses $\func(\parMat)$. This viewpoint has formed the basis 
for the implementation of surrogate models in software packages such as 
\verb+BoTorch+ \citep{botorch}. It is therefore feasible to sample the finite-dimensional distributions
$\funcEm[\Ndesign](\parMat)$ for finite input sets $\parMat$, but sampling trajectories
$\func_{\mathrm{samp}}(\cdot) \sim \mathrm{law}(\funcEm[\Ndesign])$ would require 
infinite computing resources. Practical techniques to sample approximate trajectories have been
extensively studied when $\funcEm[\Ndesign]$ is a GP, including work in 
Bayesian inverse problems \citep{dimRedPolyChaos,functionSpaceMCMC} 
and Bayesian optimization \citep{pathwiseConditioning,samplingGPPosts}.
Common approaches construct finite-rank approximations of the form  
in \Cref{eq:finite-basis}.


\footnote{This is in contrast to other surrogate modeling strategies (e.g., reduced-order modeling)
that exploit the specific structure of the forward model; see \citet{multifidelityReview} for a detailed review.}

 \subsection{Gaussian Processes} \label{gp_review}
 Since Gaussian processes will serve as our primary example of a probabilistic surrogate,
 we provide a brief overview here; for in-depth treatments, we refer to 
 \cite{gramacy2020surrogates, StuartTeck2, gpML}.
 

% Initial Design and Surrogate Models
\section{Initial Design and Surrogate Models} \label{sec:surrogate-models}
We begin our review by summarizing the surrogate modeling workflow in the context of solving
Bayesian inverse problems. We focus exclusively on a modular workflow \citep{modularization}, 
such that the surrogate is trained only on data produced by the simulator, as opposed to jointly 
learning the surrogate with the parameters in a unified Bayesian model 
(e.g., as in the seminal work \citet{KOH}). Fitting the surrogate requires 
generating training data by evaluating the simulator at a chosen set of input parameters
$\designIn \Def \{\Par_1, \dots, \Par_{\Ndesign}\}$, referred to as the \textit{initial design}.
The design points are then used for training a model to predict some output quantity of interest 
as a function of $\Par$. We refer to this output quantity as the \textit{emulator target}, 
and discuss several targets commonly used in surrogate-based Bayesian inference. 
Many different regression and interpolation models have been used as emulators. 
Our aim is not to investigate any specific model in depth; rather, we generally focus 
on models that provide a probabilistic representation of emulator uncertainty. 
This uncertainty can then be propagated when constructing a posterior approximation 
(\Cref{sec:post-approx}) and leveraged to guide the selection of new design points (\Cref{sec:seq-design}).

\subsection{Initial Design}
Initially, one typically has limited information regarding the structure of the emulator target and thus
chooses the initial design $\designIn$ to satisfy some sort of ``space-filling'' criterion; canonical examples 
include latin hypercube designs and Sobol sequences \citep{initDesignReview}.
In the Bayesian inference setting, a natural approach is to sample $\designIn$ from the prior $\priorDens$, 
either via simple Monte Carlo or deterministic alternatives \citep{supportPoints, SteinPoints}.
One of the central challenges of surrogate-based Bayesian inference is the well-documented fact that
the posterior is often highly concentrated relative to the prior \citep{StuartTeck2,Li_2014,PCEBIP}.
This implies that initial designs sampled from the prior may contain few or no points in the region of 
high posterior mass. Therefore, initial emulator fits may simultaneously produce reasonable approximations
in a prior-averaged sense but poor approximations to the posterior. This challenge motivates
the use of active learning algorithms to iteratively construct the design in order to target high-posterior
regions (see \Cref{sec:seq-design}).

Another approach to this problem is to first run an alternative algorithm (e.g., an approximate 
sampler or optimizer) to produce design points in regions of high posterior mass, which can then 
be used as part of an initial design to fit an emulator. This general strategy is exemplified by the 
\textit{calibrate, emulate, sample} workflow \citep{CES,idealizedGCM,CESSoftware,FATES_CES,adaptiveMultimodal}, 
which uses Ensemble Kalman methods to produce the initial design. In similar spirit, the earlier work 
\citet{emPostDens} utilizes a sequence of importance sampling steps to construct a Gaussian 
approximation of the posterior, which is then sampled from to produce an initial surrogate design.
\citet{JosephMEDSampling} instead proposes the use of deterministic sampling methods to generate 
the initial design. While we do not focus on these methods further in this review, continued 
methodological development investigating such workflows is a promising avenue for future research. 

 
\section{Posterior Approximation} \label{sec:post-approx}

\subsection{Expected Likelihood}

The \textit{unnormalized} expected likelihood approximation $\postApproxMarg[\Ndesign]$ 
 may be justified from a Bayesian decision-theoretic viewpoint as the minimizer of an $L^2$ risk. However, this does not 
 confer the same optimality on the normalized approximation $\postApproxNormMarg[\Ndesign]$;
 see \citep{SinsbeckNowak,StuartTeck2,VehtariParallelGP} for details. 
 Alternatively, under a forward model emulator, $\postApproxNormMarg[\Ndesign]$ can be viewed as
 the $\Par$-marginal of the joint posterior $p(\Par, \fwdEm[\Ndesign](\Par) \given \obs)$; by contrast, recall
 the interpretation of $\postApproxEP[\Ndesign]$ as the marginal of $p(\Par, \fwdEm[\Ndesign] \given \obs)$.
 This extended parameter space viewpoint is adopted in \citet{BilionisBayesSurrogates}, who 
 to our knowledge are the first to propose the expected likelihood approximation to propagate 
 surrogate uncertainty.
 \footnote{\citet{BilionisBayesSurrogates} only consider the forward model emulation setting, 
 and call $\postApproxNormMarg[\Ndesign]$ the 
 $\mathcal{D}$-restricted posterior, in reference to the finite computational budget
 $\mathcal{D} = \{\designIn, \fwd(\designIn)\}$.} 
They explore several variants of the approximation, which differ based on the treatment of surrogate 
hyperparameters. The works by \citet{SinsbeckNowak,StuartTeck1} follow shortly thereafter, 
providing a Bayesian decision theoretic perspective and lending theoretical support to the expected
likelihood approximation.

 If the pointwise expectation 
 $\E_{\Ndesign}[\postEm[\Ndesign](\Par)]$ is computable in closed-form, then 
the expected likelihood approximation can be sampled using standard MCMC software.
In cases where this expectation is intractable, pseudo-marginal MCMC 
\citep{pseudoMarginalMCMC} may be employed, so long as 
samples can be drawn from the surrogate predictive distribution $\postEm[\Ndesign](\Par)$
at any input $\Par$. The pseudo-marginal approach is discussed in \Cref{sec:MH-approx}.
\citet{BurknerSurrogate} alternatively propose to replace  $\E_{\Ndesign}[\postEm[\Ndesign](\Par)]$
with a fixed Monte Carlo estimate derived from surrogate samples (i.e., a sample average approximation). 
Their method differs from the 
pseudo-marginal algorithm in that the Monte Carlo samples are simulated once 
and then fixed throughout the MCMC run; this is similar to the particle approximation 
previously proposed in \citet{BilionisBayesSurrogates}.
This approach allows for the application of standard 
MCMC methods, but targets an approximation to $\postApproxNormMarg[\Ndesign]$
and is only directly implementable in the finite-dimensional setting.
In the infinite-dimensional case, most previous literature 
has focused on the Gaussian settings from \Cref{eq:fwd-em-Gaussian-post,eq:fwd-em-Gaussian} 
and \Cref{eq:llik-em-Gaussian} due to their analytic tractability. We summarize these special cases below.

\begin{examplebox}[Gaussian Forward Model Emulation Setting]
In the Gaussian forward model emulation setting from \Cref{eq:fwd-em-Gaussian-post,eq:fwd-em-Gaussian}, the
expected likelihood approximation is given by 
\begin{align}
\postApproxMarg[\Ndesign](\Par) 
&= \priorDens(\Par) \Gaussian\left(\obs \given \emMean[\Ndesign]{\fwd}(\Par), \likPar + \emKer[\Ndesign]{\fwd}(\Par) \right). 
\label{eq:post-approx-fwd-EL-Gaussian}
\end{align}
Moreover, \Cref{eq:post-approx-fwd-EL-Gaussian} is the unnormalized posterior corresponding to the modified
Bayesian inverse problem
\begin{align}
&\obs = \emMean[\Ndesign]{\fwd}(\Par) + \eta_{\Ndesign}(\Par) + \noise
&&\noise \sim \Gaussian(0, \likPar)  \label{inv_prob_Gaussian_modified} \\
&\eta_{\Ndesign}(\Par) \sim \Gaussian(0, \emKer[\Ndesign]{\fwd}(\Par))
&&\Par \sim \priorDens  \nonumber
\end{align}
where $\noise$, $\Par$, and $\eta_{\Ndesign}(\Par)$ are pairwise a priori independent for all $\Par$.
The approximate likelihood retains a Gaussian form, where the surrogate predictive mean
$\emMean[\Ndesign]{\fwd}$ has replaced the true forward model $\fwdEm[\Ndesign]$. The surrogate uncertainty
is incorporated via the addition of $\emKer[\Ndesign]{\fwd}(\Par)$ to the noise covariance $\likPar$.
We emphasize that even if the prior $\priorDens$ is Gaussian, the posterior approximation will typically be non-Gaussian
due to the nonlinearity of $\emMean[\Ndesign]{\fwd}(\Par)$ and the fact that the likelihood covariance depends on 
$\Par$ through $\emKer[\Ndesign]{\fwd}(\Par)$. The modified inverse problem viewpoint 
in \Cref{inv_prob_Gaussian_modified} is noted in \citet{SinsbeckNowak} and \citet{StuartTeck1},
representing a special case of the extended parameter space perspective taken in \citet{BilionisBayesSurrogates}.
The closed-form expression in \Cref{eq:post-approx-fwd-EL-Gaussian} is also noted in both
\citet{SinsbeckNowak, StuartTeck1} and has been used in many subsequent studies 
\citep{weightedIVAR,StuartTeck2,GP_PDE_priors,CES,idealizedGCM,
villani2024posteriorsamplingadaptivegaussian,hydrologicalModel,hydrologicalModel2}. 
\citet{Surer2023sequential} derive the special case of \Cref{eq:post-approx-fwd-EL-Gaussian}
under the multi-output basis vector model in \Cref{basis_func_GPs,basis_func_noise}, while 
\citet{Takhtaganov2018AdaptiveBayesianGP} give the analogous formula when the 
predictive distribution is a finite Gaussian mixture.
\end{examplebox}

\begin{examplebox}[Gaussian Log-Density Emulation Setting]
Consider the Gaussian log-density emulation setting from \Cref{eq:llik-em-Gaussian}
with a log-likelihood emulator. With this setup, the expected likelihood approximation is given by 
\begin{align}
\postApproxMarg[\Ndesign](\Par) 
&= \priorDens(\Par) \Exp{\emMean[\Ndesign]{\llik}(\Par) + \frac{1}{2}\emKer[\Ndesign]{\llik}(\Par)}
= \postApproxMean(\Par) \Exp{\frac{1}{2}\emKer[\Ndesign]{\llik}(\Par)}. 
\label{eq:post-approx-llik-EL-Gaussian}
\end{align}
The log-posterior emulation case is very similar. From \Cref{eq:post-approx-llik-EL-Gaussian},
we see that $\postApproxMarg[\Ndesign]$ inflates the mean approximation at points
where the emulator is uncertain. It is notable that the uncertainty inflation factor 
$\Exp{\frac{1}{2}\emKer[\Ndesign]{\lpost}(\Par)}$ scales very quickly as the surrogate variance 
increases. \citet{VehtariParallelGP} note this fact, emphasizing that using the expectation can
be a misleading summary of the log-normal random variable $\postEm[\Ndesign](\Par)$.
In practice, we also find this to be the case; the heavy-tailed nature of log-normal distributions
can lead $\postApproxNormMarg[\Ndesign]$ to be heavily concentrated in small regions with high 
predictive variance. In \Cref{rec:bound-constraints} and \Cref{sec:case-study-lpost-em} we 
describe how enforcing bound constraints can avoid these pathologies.
The EL approximation in the Gaussian log-density emulation setting is analyzed theoretically
in \citet{StuartTeck1,StuartTeck2,GP_PDE_priors,random_fwd_models,TeckHyperpar}.
\end{examplebox}

\subsection{Other Unnormalized Density Approximations}
Various alternative approximations have been proposed for the unnormalized posterior density. 
Instead of computing pointwise expectations, one can consider summarizing $\postEm[\Ndesign](\Par)$
by computing pointwise quantiles \citep{VehtariParallelGP,quantileApprox}. In the log-likelihood 
emulation setting with a GP emulator, \cite{VehtariParallelGP} considers the $\quantileProb$-quantile of 
the likelihood surrogate
\begin{equation}
\mathrm{Quantile}_{\quantileProb}(\Exp{\llikEm[\Ndesign](\Par)})
= \Exp{\emMean[\Ndesign]{\llik}(\Par) + \GaussianCDF^{-1}(\quantileProb) \sqrt{\emKer[\Ndesign]{\llik}(\Par)}},
\label{eq:post-approx-quantile}
\end{equation}
where $\GaussianCDF$ denotes the standard Gaussian distribution function. This expression is of the same form 
as the expected likelihood in \Cref{eq:post-approx-llik-EL-Gaussian}, but the uncertainty inflation term 
$\Exp{\GaussianCDF^{-1}(\quantileProb) \sqrt{\emKer[\Ndesign]{\llik}(\Par)}}$ scales more slowly than 
$\Exp{\frac{1}{2} \emKer[\Ndesign]{\llik}(\Par)}$. The special case $\quantileProb = 1/2$ (i.e., the median) 
reduces to the mean approximation in \Cref{eq:mean-approx-llik}, while values $\quantileProb > 1/2$ imply 
the density will be inflated in regions of higher surrogate uncertainty. \citet{FATES_CES} also utilize the 
approximation in \Cref{eq:post-approx-quantile}, though they do not explicitly draw the connection to 
the quantile estimator.

In the forward model emulation setting, \citet{BurknerSurrogate} also consider an \textit{expected log-likelihood}
approximation of the form $\priorDens(\Par) \Exp{\E_{\Ndesign}[\llik(\Par; \fwdEm[\Ndesign])]}$ and draw 
a connection with power-scaled likelihoods. However, the authors ultimately recommend the expected 
posterior and expected likelihood as preferred alternatives to this method.

\subsection{Noisy MCMC Approximations} \label{sec:MH-approx}
Outside of special cases, many of the above approximate posteriors can pose computational
challenges for inference (e.g., requiring closed-form density
approximations or sampling trajectories). It is thus desirable to consider general-purpose 
algorithms that can be easily
implemented for any surrogate. We thus consider a class of MCMC algorithms 
that only require the ability to draw samples from the emulator predictive distribution at finite 
sets of inputs. Such algorithms are therefore agnostic to the predictive distribution
or the particular likelihood, and are also applicable to infinite-dimensional emulators.
These approaches focus on constructing approximations to MCMC algorithms, as opposed to 
approximations of the unnormalized posterior density.
Some of these methods provide algorithms for sampling from approximate posteriors already 
defined above, while others represent new approaches to inference.

To start, we recall the standard Metropolis-Hastings (MH) algorithm, which is defined by a proposal 
kernel with density $\propDens(\Par, \cdot)$. If the Markov chain is in the current state 
$\Par \in \parSpace$ then the next state is defined by sampling the proposal
 $\propPar \sim \propDens(\Par, \cdot)$, which is accepted with probability
\begin{align}
&\accProbMH(\Par, \propPar) \Def 
\min\left\{1, \frac{\postDens(\propPar)\propDens(\propPar, \Par)}{\postDens(\Par) \propDens(\Par, \propPar)} \right\}.
\label{MH_acc_prob_exact}
\end{align}
If accepted, the next state is defined to be $\propPar$, else it is set to the current state $\Par$. 
This procedure is summarized in \Cref{alg:MH}. 

\begin{figure}[ht]
\centering
\begin{minipage}[t]{0.495\textwidth}
    \floatname{algorithm}{Alg.}
    \captionsetup{type=algorithm}
    \caption{Metropolis-Hastings}
    \label{alg:MH}
    \begin{algorithmic}[1]
    \Function{MH}{$\Par_0, \NMCMC$}     
        \For{$k \gets 0, \dots, \NMCMC$} 
            \State $\tilde{\Par} \sim q(\Par_{k}, \cdot)$
            \State $\alpha \gets \min\left\{1, \frac{\pi(\tilde{\Par}) q(\tilde{\Par}, \Par_k)}{\pi(\Par_k) q(\Par_k, \tilde{\Par})} \right\}$
            \State $b \sim \text{Bernoulli}(\alpha)$
            \If{$b = 1$}
                \State $\Par_{k+1} \gets \tilde{\Par}$ 
            \Else
                \State $\Par_{k+1} \gets \Par_k$
            \EndIf
        \EndFor
    \EndFunction
    \end{algorithmic}
\end{minipage}
\hfill
\begin{minipage}[t]{0.495\textwidth}
    \floatname{algorithm}{Alg.}
    \captionsetup{type=algorithm}
    \caption{Noisy Metropolis-Hastings}
    \label{alg:MH-noisy}
    \begin{algorithmic}[1]
    \Function{MH-Noisy}{$\Par_0, \NMCMC, \postSampleKernel$}
        \State $\hat{\pi}_{\text{curr}} \sim \mathrm{law}(\postEm[\Ndesign](\indexMCMC[0]{\Par}))$
        \For{$k \gets 0, \dots, \NMCMC$} 
            \State $\tilde{\Par} \sim q(\Par_k, \cdot)$
            \State $[\hat{\pi}_{\Par}, \hat{\pi}_{\tilde{\Par}}] \sim \postSampleKernel([\Par_k, \tilde{\Par}, \hat{\pi}_{\text{curr}}], \cdot)$
            \State $\hat{\alpha} \gets \min\left\{1, \frac{\hat{\pi}_{\tilde{\Par}} \cdot q(\tilde{\Par}, \Par_k)}{\hat{\pi}_{\Par} \cdot q(\Par_k, \tilde{\Par})} \right\}$
            \State $b \sim \text{Bernoulli}(\hat{\alpha})$
            \If{$b = 1$}
                \State $\Par_{k+1} \gets \tilde{\Par}$
                \State $\hat{\pi}_{\text{curr}} \gets \hat{\pi}_{\tilde{\Par}}$
            \Else
                \State $\Par_{k+1} \gets \Par_k$
            \EndIf
        \EndFor
    \EndFunction
    \end{algorithmic}
\end{minipage}
\caption{\textbf{(Left)} A standard Metropolis-Hastings MCMC algorithm with proposal density $\propDens(\Par, \cdot)$.
\textbf{(Right)} A generic noisy Metropolis-Hastings algorithm. The choice of Markov kernel $\postSampleKernel$ 
defines particular algorithms.}
\end{figure}

We consider a family of algorithms that change $\accProbMH(\Par, \propPar)$ by
substituting the exact densities $\postDens(\Par)$  and $\postDens(\propPar)$ 
with approximations sampled from a specified distribution. The particular choice of 
this distribution yields different algorithms, all of which are ``noisy'' in the sense that 
an additional Monte Carlo step has been injected within the standard MH scheme
\citep{noisyMCSurvey,noisyMCMC,stabilityNoisyMH}. In particular, we assume 
that the approximation of $[\postDens(\Par), \postDens(\propPar)]$ is sampled as
\begin{equation}
[\hat{\postDens}_{\Par}, \hat{\postDens}_{\propPar}] \sim \postSampleKernel([\Par, \propPar, \postDens^\prime], \cdot),
\end{equation}
where $\postSampleKernel$ is a Markov kernel mapping from source $\parSpace^2 \times \R_+$
to target $\R^2_{+}$. The generic noisy MH algorithm is stated in \Cref{alg:MH-noisy}. 
We consider three special cases below.

\paragraph{Pseudo-Marginal.}
We first consider the choice 
\begin{equation}
\postSampleKernel([\Par, \propPar, \postDens^\prime], \cdot)
\Def \delta_{\postDens^\prime} \otimes \mathrm{law}(\postEm[\Ndesign](\propPar)),
\end{equation}
which implies that at each iteration only the density value at the proposed point 
$\postEm[\Ndesign](\propPar)$  is sampled, while the value at the current point 
is recycled from the previous iteration. This is a pseudo-marginal algorithm 
targeting the stationary distribution $\postApproxNormMarg[\Ndesign]$ \citep{pseudoMarginalMCMC}.
In principle, it provides an exact MCMC scheme to sample from the expected likelihood 
approximation even when the expectation $\E_{\Ndesign}[\postEm[\Ndesign](\Par)]$ is intractable, 
a fact noted in \citet{StuartTeck1}. The key property ensuring invariance with respect to 
$\postApproxNormMarg[\Ndesign]$ is that the value $\hat{\postDens}_{\propPar}$ sampled from 
$\postSampleKernel$ is an unbiased estimate of $\E_{\Ndesign}[\postEm[\Ndesign](\propPar)]$.
Therefore, the method remains valid for estimators of the form 
\begin{align}
&\hat{\postDens}_{\tilde{\Par}}^{J} \Def \frac{1}{J} \sum_{j=1}^{J} \hat{\postDens}_{\tilde{\Par}}^{(j)},
&&\hat{\postDens}_{\tilde{\Par}}^{(j)} \overset{\mathrm{iid}}{\sim} \mathrm{law}(\postEm[\Ndesign](\propPar)). \label{eq:pm-unbiased-est}
\end{align}
It is well-known that pseudo-marginal methods
can suffer from slow mixing, but that efficiency can be improved by reducing the variance 
in the estimate of $\E_{\Ndesign}[\postEm[\Ndesign](\propPar)]$; e.g., by increasing $J$ in
\Cref{eq:pm-unbiased-est} \citep{pseudoMarginalMCMC,pseudoMarginalEfficiency}.
The pseudo-marginal approach to sampling $\postApproxNormMarg[\Ndesign]$ is studied 
in \citet{garegnani2021NoisyMCMC}.

\paragraph{Monte Carlo within Metropolis Hastings.}
We next consider the Markov kernel 
\begin{equation}
\postSampleKernel([\Par, \propPar, \postDens^\prime], \cdot)
\Def \mathrm{law}(\postEm[\Ndesign](\Par)) \otimes \mathrm{law}(\postEm[\Ndesign](\propPar)),
\end{equation}
which independently re-samples the density values at both the current and proposed locations
at each iteration (the kernel does not depend on $\postDens^\prime$). Algorithms of this form are 
typically referred to as Monte Carlo within Metropolis Hastings (MCwMH), and have been studied as an
efficient alternative to the pseudo-marginal algorithm \citep{noisyMCMC,stabilityNoisyMH}.
The sampled density values can also be replaced with sample means as in \Cref{eq:pm-unbiased-est},
though the efficiency of MCwMH is generally less sensitive to the variance in the estimate
\citep{garegnani2021NoisyMCMC,stabilityNoisyMH}.
The MCwMH is typically referred to as inexact, in the sense that it does not admit 
$\postApproxNormMarg[\Ndesign]$ as an invariant distribution. However, in the present setting
$\postApproxNormMarg[\Ndesign]$ is itself an approximation of $\postDensNorm$ so we might
view MCwMH as an alternative method for propagating surrogate uncertainty
on equal footing with $\postApproxNormMarg[\Ndesign]$. This perspective is taken in 
\citet{surrogateNoisyMCMC}, while \citet{garegnani2021NoisyMCMC} studies MCwMH
as an approximation to $\postApproxNormMarg[\Ndesign]$. A variant of MCwMH
is employed in \citet{FerEmulation}.

\paragraph{Expected Acceptance Probability.}
Finally, we consider
\begin{equation}
\postSampleKernel([\Par, \propPar, \postDens^\prime], \cdot)
\Def \mathrm{law}(\postEm[\Ndesign](\Par), \postEm[\Ndesign](\propPar)),
\end{equation}
implying that both density values are re-sampled each iteration, but now from
the joint distribution implied by the surrogate $\postEm[\Ndesign]$. 
We refer to this as the \textit{expected acceptance probability (E-Acc)} approximation,
as it can be viewed as marginalizing the MH acceptance probability with respect
to the surrogate. Indeed, by inserting $\postEm[\Ndesign]$
in place of $\postDens$ in $\accProbMH(\Par, \propPar)$, the surrogate induces a random 
approximation
\begin{equation}
\accProbMHEm[\Ndesign](\Par, \propPar) 
\Def \min\left\{1, \frac{\postEm[\Ndesign](\propPar)\propDens(\propPar, \Par)}{\postEm[\Ndesign](\Par) \propDens(\Par, \propPar)} \right\}
\label{eq:MH-prob-surrogate}
\end{equation}
of the MH acceptance probability. The E-Acc algorithm can thus be viewed as a modification of the
MH scheme in \Cref{alg:MH} with $\E_{\Ndesign}[\accProbMHEm[\Ndesign](\Par, \propPar)]$
replacing $\accProbMH(\Par, \propPar)$. Many of the other posteriors introduced above can also
be viewed as invoking particular approximations of $\accProbMH(\Par, \propPar)$, as summarized
in \Cref{tab:acc-prob-comparison}. \citet{surrogateNoisyMCMC} propose the E-Acc algorithm, 
and explore connections to the expected posterior approximation.

\begin{table}[h]
\centering
\small % (optional) shrink slightly if needed
\renewcommand{\arraystretch}{1.6} % row height
\setlength{\tabcolsep}{10pt} % column separation
\newcolumntype{C}[1]{>{\centering\arraybackslash}m{#1}} % centered column of width #1

\begin{tabular}{lC{10cm}}
\toprule
\textbf{Posterior Approximation} & \textbf{MH Approximation} \\
\midrule
Plug-In Mean & 
\(\displaystyle \min\left\{1, \frac{\Exp{\E[\lpostEm[\Ndesign](\propPar)]}}{\Exp{\E[\lpostEm[\Ndesign](\Par)]}} \right\}\) \\ 
Expected Likelihood & 
\(\displaystyle \min\left\{1, \frac{\E \left[\Exp{\lpostEm[\Ndesign](\propPar)}\right]}{\E\left[\Exp{\lpostEm[\Ndesign](\Par)}\right]} \right\}\) \\
Expected Acc. Prob. & 
\(\displaystyle \E\left[\min\left\{1, \frac{\Exp{\lpostEm[\Ndesign](\propPar)}}{\Exp{\lpostEm[\Ndesign](\Par)}} \right\}\right]\) \\
\bottomrule
\end{tabular}
\caption{The approximations to the Metropolis-Hastings (MH) acceptance probability implied by different posterior approximations using a log-posterior surrogate $\lpostEm[\Ndesign]$. All expectations are with respect to 
the underlying surrogate predictive distribution. For brevity, the acceptance probabilities 
are presented for the case of a symmetric proposal distribution.}
\label{tab:acc-prob-comparison}
\end{table}

\subsection{Existence and Integrability} \label{sec:existence}
We have so far implicitly assumed that the surrogate-induced posterior approximations 
introduced above are well-defined. Consideration of this question points to important 
practical issues in constructing emulators for use in posterior approximation (see
\Cref{sec:recs}). The primary concern
is that the tail behavior of the surrogate may lead to approximations of $\postDens$ that 
are not integrable. Such pathologies can easily arise if utilizing a stationary surrogate, where 
the predictive mean and variance stabilize at constant values as distance from the design points 
increases. This issue is especially a concern if emulating the log-posterior density, as the prior 
density is being modeled and hence cannot be relied upon to ensure integrability \citep{emPostDens}.
Figure \todo illustrates simple examples where such pathologies can occur.
In order to avoid issues related to
tail behavior, previous work tends to restrict to the setting where $\parSpace$
is a compact subset of $\R^{\dimPar}$ \citep{StuartTeck1, VehtariParallelGP}.
Other applications have not directly addressed this issue, but in numerical experiments focus on 
prior distributions with compact support \citep{trainDynamics,FATES_CES} or truncate an unbounded
prior to achieve compact support \citep{gp_surrogates_random_exploration,FerEmulation}. 
\citet{emPostDens} address this issue in depth, describing how the use of stationary log-posterior
surrogates can lead to divergent MCMC chains when performing approximate posterior inference.
Theoretical treatments have also explored conditions to ensure existence over generic unbounded
domains \citep{random_fwd_models,garegnani2021NoisyMCMC}. We refer to 
\citep{StuartTeck1,StuartTeck2} for a comprehensive theoretical treatment in the GP setting.
Ideally, the surrogate ought to be constructed such that every realization of $\postEm[\Ndesign]$
is integrable (i.e., $\normCstEm$ exists almost surely). This assumption is implicit in \Cref{alg:ep}, 
which assumes that each sampled trajectory of $\postEm[\Ndesign]$ induces a valid probability 
distribution from which samples can be drawn. This condition can be weakened for other 
approximations; for example, in \Cref{eq:llik-em-Gaussian} we observe the requirement is that
$\log\left[\priorDens(\Par)\right] + \emMean[\Ndesign]{\llik}(\Par) + \frac{1}{2}\emKer[\Ndesign]{\llik}(\Par)$
decays sufficiently quickly as $\norm{\Par} \to \infty$. 

\section{Sequential Design} \label{sec:seq-design}


The manner in which this tradeoff is navigated depends on the particular problem setup and 
the surrogate model itself. For example, \citet{adaptiveMultimodal} propose an active learning strategy 
targeting multimodal posteriors. Another promising line of research consists of adapting local approximations, 
avoiding the challenging task of fitting a single global surrogate \citep{Li_2014,ConradLocalExactMCMC}. 

\subsection{Sequential Design Loop}
Given a current surrogate fit to design inputs $\designIn[\Ndesign] \in \parSpace^{\Ndesign}$,
our goal is to select a new batch of inputs $\designBatchIn \in \parSpace^{\Nbatch}$
to form the augmented design $\designIn[\Naugment] \Def \designIn[\Ndesign] \cup \designBatchIn$.
After running the simulator at the new points $\designBatchIn$ and updating the emulator, we obtain
an updated posterior surrogate $\postEm[\Naugment]$. We therefore seek to select $\designBatchIn$
to yield the best possible improvement in the approximate posterior, which is naturally cast as 
an optimization problem with respect to some objective function $\acq[]: \parSpace^{\Nbatch} \to \R$, typically
called the \textit{acquisition function} or \textit{design criterion}:
\begin{equation}
\designBatchIn \in \argmin_{\parMat \in \parSpace^{\Nbatch}} \acq[](\parMat).
\label{eq:acq-opt}
\end{equation}
Depending on computational resources, this optimization can be repeated over a sequence of 
$\Nrounds$ rounds, yielding the sequential design loop summarized in \Cref{alg:seq-des-loop}.

We state the algorithm for a generic probabilistic model $\funcPrior$. 
This model is first fit to an initial design $\{\designIn[\Ndesign], \func(\designIn[\Ndesign])\}$ and then 
updated at each iteration $\designIndex$ by augmenting the existing design with newly 
acquired points $\{\designBatchIn^{(\designIndex)}, \func(\designBatchIn^{(\designIndex)})\}$.
\footnote{One could of course consider varying the batch size $\Nbatch$ across the $\Ndesign$ iterations but to simplify notation
we keep $\Nbatch$ constant.}
For GPs, these updates involve conditioning and potentially also re-fitting hyperparameters. 
The special case $\Nbatch = 1$ corresponds to the 
pure sequential design setting in which the function $\func$ is evaluated at each acquired point before
considering the subsequent acquisition. The more challenging batch sequential design setting
$\Nbatch > 1$ requires selection of inputs without observing the responses for the other points
in the batch. In practice, batch selection may be a necessity when simulations are costly but can 
be run in parallel. Though it accommodates batch acquisitions, \Cref{alg:seq-des-loop} is
still ``myopic'' in the sense that it disregards the potential for acquisitions in future rounds. 
Non-myopic strategies have been considered
through a dynamic programming lens, though they typically come at the cost of significant 
computational expense \citep{SURThesis, supermartingaleSUR}.

\subsection{Goal-Oriented Acquisition Functions}
We now make \Cref{alg:seq-des-loop} concrete by introducing several acquisition functions
that explicitly target the goal of posterior approximation. We draw a distinction between 
acquisition criteria restricted to the pure sequential ($\Nbatch = 1$) setting
and those naturally defined in the batch setting. It is still possible to perform 
batch acquisition with criteria of the former type, as discussed in \Cref{sec:greedy-opt}.

\subsubsection{Single Point Criteria} \label{sec:acq-single-point}
When optimizing for a single design point, a natural strategy is to simply select the input
where the uncertainty in $\postEm[\Ndesign](\Par)$ is largest. If predictive variance
is used as the measure of uncertainty, this yields the \textit{maximum variance} criterion
\begin{equation}
\acq[](\Par) \Def -\Var_{\Ndesign}[\postEm[\Ndesign](\Par)], \label{eq:acq-maxvar}
\end{equation}
which is negated to align with our convention of minimizing acquisition functions.
Alternative ``maximum uncertainty'' criteria can be defined by changing the measure
of uncertainty (e.g., variance, entropy, interquartile range) and the target quantity
(e.g., $\postEm[\Ndesign]$, $\funcEm[\Ndesign]$). For example, targeting the 
maximum variance of $\funcEm[\Ndesign](\Par)$ yields a classical criterion 
for exploring the parameter space \citep[Section 6.2.1]{gramacy2020surrogates}.
However, this criterion tends not to perform well in the Bayesian inference setting
since it does not take into account the magnitude of the posterior density. 
It may be that $\funcEm[\Ndesign](\Par)$ is highly uncertain, but 
$\postDens(\Par; \funcEm[\Ndesign])$ concentrates on a very small value.  

The predictive variance of $\postEm[\Ndesign](\Par)$
is given in closed-form in \Cref{eq:fwd-em-Gaussian,eq:llik-em-Gaussian} for 
forward model and log-density emulators in the Gaussian settings. For example, 
when $\lpostEm[\Ndesign](\Par) \sim \Gaussian(\emMean[\Ndesign]{\lpost}(\Par), \emKer[\Ndesign]{\lpost}(\Par))$
we have
\begin{equation}
\Var\left[\postEm[\Ndesign](\Par; \lpostEm[\Ndesign])\right] &= 
\left[\Exp{\emKer[\Ndesign]{\lpost}(\Par)} - 1\right] \Exp{2\emMean[\Ndesign]{\lpost}(\Par) + \emKer[\Ndesign]{\lpost}(\Par)},
\end{equation}
which demonstrates that the criterion favors inputs where both the expected log-posterior
$\emMean[\Ndesign]{\lpost}(\Par)$ and epistemic uncertainty $\emKer[\Ndesign]{\lpost}(\Par)$ are large, encoding an exploration-exploitation
tradeoff. The maximum variance criterion is utilized in \citet{Lueckmann2018LikelihoodfreeIW,Kandasamy_2017,AlawiehIterativeGP}. 
In the GP log-density emulator setting (\Cref{eq:llik-em-Gaussian})
$\postEm[\Ndesign](\Par)$ is log-normal. Given the heavy tails and asymmetry of a log-normal random variable, 
\citep{VehtariParallelGP,wang2018adaptive} argue that the variance provides a misleading measure
of uncertainty in this setting, instead favoring the entropy or interquartile range. 
As an alternative to these maximum uncertainty criteria, \citet{gp_surrogates_random_exploration}
suggest explicitly decoupling exploration and exploitation by selecting one point 
that maximizes $\emMean[\Ndesign]{\lpost}(\Par)$ and randomly sampling a second point from 
$\priorDens$. \citet{Takhtaganov2018AdaptiveBayesianGP} employs the expected improvement
criterion from Bayesian optimization to target the placement of new design points in high-posterior regions.

\subsubsection{Multipoint Criteria} \label{sec:acq-multipoint}
We next consider acquisition functions that can be evaluated at batches of multiple inputs. In particular,
we focus on a class of acquisition functions that we call \textit{expected conditional uncertainty (ECU)} 
criteria. Criteria falling within this general class have been explored in various contexts 
\citep{ALC,Roy2001,Mercer_kernels_IVAR,Binois_2018,deepGPAL,
ALExpErrReduction,parallelSURExcursionSet,SurerStochasticIVAR}
\footnote{Many names have been used for such criteria, including \textit{expected error reduction}, 
\textit{active learning Cohn}, \textit{integrated mean squared prediction error}, \textit{integrated variance}, 
and generically \textit{integral criteria}.},
but we focus on examples geared specifically towards surrogate-induced posterior approximation.

ECU acquisitions arise from the following logic: we would like to select an input batch 
$\parMat \in \parSpace^{\Nbatch}$ that induces an updated surrogate $\postEm[\Naugment]$ with the largest 
possible reduction in uncertainty on average over $\parSpace$. This uncertainty reduction is not, in general,
computable without observing the response $\func(\parMat)$. However, it can be approximated by modeling
$\func(\parMat)$ as a random vector $\gamma \sim \mathrm{law}(\funcEm[\Ndesign](\parMat))$. Let
$\funcEm[\Naugment]^{\parMat,\gamma} \Def \funcEm[\Ndesign] \given [\funcEm[\Ndesign](\parMat) = \gamma]$
denote $\funcEm[\Ndesign]$ conditioned on new data $\{\parMat, \gamma\}$. In computing ECU, we marginalize
over $\gamma$ in addition to averaging over $\parSpace$. If we again choose variance as our measure of 
uncertainty, we have
\begin{equation}
\acq[](\parMat) \Def 
\int_{\parSpace} \E_{\gamma} \left\{\Var_{\Naugment}[\postDens(\Par; \funcEm[\Naugment]^{\parMat,\gamma}) \given \gamma]\right\} \ \weightDens(\Par) d\Par,
 \label{eq:acq-intvar}
\end{equation}
where $\weightDens$ is a measure on $\parSpace$ that we are free to choose.
Notice that in contrast to the pointwise 
criteria, ECU acquisition functions are ``global'' in that they account for the effect of the 
new batch $\parMat$ on the surrogate uncertainty over the entire space $\parSpace$. Variations of 
ECU criteria can be created by changing the measure of uncertainty (e.g., variance, entropy, interquartile range),
the target quantity (e.g., $\postEm$, $\lpostEm$, $\funcEm$), and the weighting measure $\weightDens$.
For example, targeting the variance of $\funcEm$ with uniform weighting measure yields the
classical integrated mean squared prediction error \citep{Mercer_kernels_IVAR}.

Outside of special cases \citep{Binois_2018,MakTargetedVar,Koermer2024} the outer integral (over $\parSpace$) 
in ECU criteria is not tractable. This is especially the case in our present setting,
and thus we focus on the sample average approximation \citep{Mercer_kernels_IVAR,botorch},
\begin{align}
&\acq[](\parMat) \Def \frac{1}{J}
\sum_{j=1}^{J} \E_{\gamma} \left\{\Var_{\Naugment}[\postDens(\Par_j; \funcEm[\Naugment]^{\parMat,\gamma}) \given \gamma]\right\},
&&\Par_j \overset{\mathrm{iid}}{\sim} \weightDens[\Ndesign].
 \label{eq:acq-intvar-saa}
\end{align}
The $\Par_j$ are sampled at the beginning of the sequential design round and then fixed, so that
\Cref{eq:acq-intvar-saa} is viewed as a deterministic objective function. 
The expected variance terms in the summands admit closed forms in the Gaussian 
settings of \Cref{eq:fwd-em-Gaussian,eq:llik-em-Gaussian}, as shown below. As an alternative to 
\Cref{eq:acq-intvar-saa}, we can consider an ECU criterion that targets uncertainty in the underlying
emulator $\funcEm[\Ndesign]$, but acknowledges the goal of posterior approximation through the choice
of $\weightDens[\Ndesign]$; i.e., 
\begin{align}
&\acq[](\parMat) \Def \frac{1}{J}
\sum_{j=1}^{J} \Var_{\Naugment}[\funcEm[\Naugment](\Par_j)],
&&\Par_j \overset{\mathrm{iid}}{\sim} \postNormEm[\Ndesign]^{\mathrm{approx}},
 \label{eq:acq-intvar-lartaud-saa}
\end{align}
where $\postNormEm^{\mathrm{approx}}$ is any of the approximate posteriors from \Cref{sec:post-approx}.
An acquisition function of this form is proposed in \citet{weightedIVAR}, and compares 
favorably against \Cref{eq:acq-intvar-saa}.

\begin{examplebox}[Gaussian Forward Model Emulation Setting]
In the Gaussian forward model emulation setting from \Cref{eq:fwd-em-Gaussian-post,eq:fwd-em-Gaussian}, 
the ECU-variance criterion in \Cref{eq:acq-intvar-saa} reduces to
\begin{align}
\acq[](\parMat) &= \frac{1}{J}
\sum_{j=1}^{J} \priorDens^2(\Par_j) \bigg[\frac{\Gaussian\left(\obs \given \emMean{\fwd}(\Par_j), \CovComb(\Par_j) - \frac{1}{2}\likPar \right)}{2^{\dimObs/2} \det(2\pi \likPar)^{1/2}} - \label{eq:acq-intvar-saa-fwd} \\
&\qquad\qquad \frac{\Gaussian\left(\obs \given \emMean{\fwd}(\Par_j), \CovComb(\Par_j) - \frac{1}{2}\CovComb[\Naugment](\Par_j) \right)}{2^{\dimObs/2} \det(2\pi \CovComb[\Naugment](\Par_j))^{1/2}} \bigg], \nonumber
\end{align}
where $\CovComb(\Par) \Def \likPar + \emKer{\fwd}(\Par)$ and $\CovComb[\Naugment](\Par) \Def \likPar + \emKer[\Naugment]{\fwd}(\Par)$.  
\citet{SinsbeckNowak} are the first to propose an ECU-variance criterion in the forward model emulation setting,
and briefly note the above closed-form expression in the Gaussian special case.
\citet{Surer2023sequential} also derive this expression, but in the particular case of the multi-output basis vector model
in \Cref{basis_func_model}.

\citet{weightedIVAR} consider an alternative ECU-variance criterion in the Gaussian forward model emulator setting:
\begin{align}
&\acq[](\parMat) \Def \frac{1}{J}
\sum_{j=1}^{J} \emKer[\Naugment]{\fwd}(\Par_j),
&&\Par_j \sim \postApproxNormMarg.
 \label{eq:acq-intvar-lartaud}
\end{align}
The summands target uncertainty in $\fwdEm[\Ndesign]$ rather than $\postEm[\Ndesign]$, while the weighting measure
$\weightDens = \postApproxNormMarg$ is chosen to target the goal of posterior approximation. This has the 
benefit of being much easier to compute, since the GP variance $\emKer[\Naugment]{\fwd}(\Par)$ is independent of the 
unseen response $\fwd(\parMat)$. \citet{weightedIVAR} establish asymptotic convergence results for this criterion
using the stepwise uncertainty reduction framework \citep{BectSUR}. 
\end{examplebox}

\begin{examplebox}[Gaussian Log-Density Emulation Setting]
Consider the Gaussian log-density emulation setting from \Cref{eq:llik-em-Gaussian}
with a log-likelihood emulator. With this setup, the ECU-variance criterion in 
\Cref{eq:acq-intvar-saa} reduces to
\begin{equation}
\acq[](\parMat) = \frac{1}{J}
\sum_{j=1}^{J} \Var\left[\postEm(\Par_j) \given \llikEm(\parMat) = \emMean[\Ndesign]{\llik}(\parMat) \right] \varInflation_{\Ndesign}(\Par_j; \parMat)   
\label{eq:acq-intvar-saa-ldens}
\end{equation}
where
\begin{align*}
\Var\left[\postEm(\Par) \given \llikEm(\parMat) = \emMean[\Ndesign]{\llik}(\parMat) \right]
&= \priorDens(\Par)^2 \Exp{2\emMean[\Ndesign]{\llik}\left(\Par\right) + \emKer[\Naugment]{\llik}(\Par)} \cdot \\
&\qquad\qquad\qquad \left[\Exp{\emKer[\Naugment]{\llik}(\Par)} - 1 \right] \\
\varInflation_{\Ndesign}(\Par; \parMat)
&= \Exp{2\left(\emKer[\Ndesign]{\llik}(\Par) - \emKer[\Naugment]{\llik}(\Par)\right)}.
\end{align*}

Notice that the first term in \Cref{eq:acq-intvar-saa-ldens} is the variance of $\postEm[\Ndesign](\Par_j)$ conditioned on
$\{\parMat, \emMean[\Ndesign]{\llik}(\parMat)\}$; i.e., the current GP prediction is treated as if it were the true response.
The second term accounts for the uncertainty in the true response; in particular, the penalty
$\emKer[\Ndesign]{\llik}(\Par) - \emKer[\Naugment]{\llik}(\Par)$ is large when the input batch $\parMat$ is highly 
``influential.''

\Cref{eq:acq-intvar-saa-ldens} is derived in \citet{VehtariParallelGP}, but the authors ultimately recommend
an alternative criterion that uses the interquartile range in place of the variance. The interquartile range
is more robust to the heavy tails of the log-normal predictive distribution, a benefit that translates to 
improved empirical performance in their experiments.
\end{examplebox}

\subsection{Batch Design Strategies}
When simulation cost is high but runs can be parallelized, batch acquisition is often essential. For example, in large-scale
geoscience applications the batch size may be in the hundreds ($\Nbatch \approx 100$), with only a few rounds 
of acquisition possible ($\Nrounds < 10$) \citep{FerEmulation}. This is in stark contrast to much of the sequential 
design literature, which focuses on the behavior of single-point acquisition algorithms as $\Nrounds$ grows large.
The challenge of batch acquisition has gained interest in the active learning and Bayesian 
optimization literature \citep{Ginsbourger2010,LOEPPKY20101452,Chevalier2013,batchBOThesis}. We begin 
by highlighting ideas from this broader literature, and then discuss some promising approaches
well-suited to the particular goal of posterior approximation.

\subsubsection{Joint Optimization}
The task of minimizing $\acq[](\parMat)$ requires an optimization over $\dimPar\Nbatch$ variables, and is thus
difficult to scale as the parameter dimension or batch size increases. \citet{Mercer_kernels_IVAR} investigate
the performance of gradient-based continuous optimization over $\parSpace^\Nbatch$ for integrated variance
criteria, demonstrating favorable performance for small values of $\dimPar$ and $\Nbatch$. 
\citep{botorch} describes the gradient-based optimization framework using sample average approximations
implemented in the \verb+BoTorch+ package. A large portion of the literature eschews continuous optimization in 
favor of discrete methods. These algorithms take the form of a subset selection problem; the optimal batch
is sought from within a finite set of candidate points $\parMatCand \subset \parSpace$. This presents a 
challenging combinatorial optimization problem, commonly solved by employing stochastic exchange 
algorithms (i.e., Federov exchange) to find a local minimum \citep{FederovExchange,WynnDiscreteExchange,LOEPPKY20101452}
\footnote{Exchange algorithms can also be employed to optimize over continuous space and leverage gradient information.}.

\subsubsection{Greedy Optimization} \label{sec:greedy-opt}
Motivated by the difficulty of joint optimization, greedy approximations are common in practice \citep{Ginsbourger2010}.
These methods seek to approximate the joint optimum using a sequence of $\Nbatch$ simpler optimization 
problems over $\parSpace$. Under this approach, at the beginning of round $\designIndex$ the first 
point in the batch $\Par^{(\designIndex,1)}$ is selected by optimizing $\acq[]^{(\designIndex)}(\Par)$ as 
in the pure sequential design setting. The remaining $\Nbatch - 1$ points are added sequentially via
\begin{align}
&\Par^{(\designIndex, b)} \Def \argmin_{\Par \in \parSpace} \acq[]^{(\designIndex,b)}(\parMat^{(\designIndex,1:b-1)} \cup \{\Par\}),
&&b = 2, \dots, \Nbatch. 
\label{eq:greedy-acq-opt}
\end{align}
In pure sequential design, the acquisition function changes every iteration owing to the addition of a new
observation $(\Par, \func(\Par))$. Greedy batch design differs in that the criterion is updated to reflect
the new input $\Par$ only, as we do not observe $\func(\Par)$ until the entire batch is acquired.
The superscript in $\acq[]^{(\designIndex,b)}$ indicates that the objective is approximated to account for
these unobserved responses. \citep{Ginsbourger2010} introduce several heuristics for this approximation.
At each iteration, the \textit{Kriging believer} strategy updates the surrogate with a pseudo-observation;
the current emulator predictive mean is used in place of the truth $\func(\Par^{(\designIndex, b)})$.
Believing the surrogate prediction over a sequence of iterations can be problematic, so the popular 
\textit{constant liar} alternative consists of fixing the pseudo-observation to a constant value throughout the 
entire round. \citep{Ginsbourger2010} refer to this constant value as a ``lie'' and investigate the empirical 
performance of different choices for the lie. A related alternative consists of using the predictive mean of 
$\funcEm[\Ndesign]$ to generate the pseudo-observation over the course of the round, rather than using the 
updated predictive mean function after each iteration as in the Kriging believer approach \citep{VehtariParallelGP}.
Both \citep{VehtariParallelGP,Surer2023sequential} consider such greedy heuristics in the context of
solving a Bayesian inverse problem.

An unappealing aspect of the greedy approach is that the potential for batch acquisitions to assess within-batch
interactions is not fully leveraged. In order to make better use of a batch acquisition, one idea consists of generating
multiple candidate batches of points and then using the batch criterion to select among the competitors. This is
exemplified by the \textit{constant liar mix} strategy, where the candidate batches are generated using the constant
liar heuristic with different choices of the lie \citep{Chevalier2013}.
Finally, note that since the optimization in \Cref{eq:greedy-acq-opt} proceeds one point at a time then the single point criteria
in \Cref{sec:acq-single-point} can be combined with greedy heuristics to enable batch optimization (e.g., \citet{VehtariParallelGP}).

\subsubsection{Sampling-Based Approaches}
The batch design methods discussed above are generic active learning techniques, not unique to our particular
context. However, the specific goal of posterior approximation suggests a natural alternative: select the batch by sampling from the 
current approximate posterior. \citep{hydrologicalModel,quantileApprox} both adopt this strategy.
\citet{FerEmulation} instead sample from a mixture of the current approximate posterior and the prior, with the mixture weights 
representing a user-defined tuning parameter. \citet{turbulenceModelAdaptiveLHS} considers a 
similar prior-posterior mixture, with a latin hypercube adjustment to encourage the new design 
points to be spread out. 
\citet{adaptiveMultimodal} samples from the current approximate posterior, and
then updates these samples with an iteration of an ensemble Kalman algorithm; this method is 
closely related to the \textit{calibrate, emulate, sample} workflow \citep{CES}.
\citet{hydrologicalModel2} consider a similar strategy, using parameters sampled from an MCMC
proposal as additional design points.

These sampling-based approaches enjoy the practical benefits of being inherently parallel and not requiring the solution
of a difficult optimization problem. In this sense, they are similar in spirit to Thompson sampling for
batch Bayesian optimization \citep{parallelBOThompson}. We conjecture that such approaches may be superior to 
alternatives in the large $\Nbatch$, small $\Nrounds$ setting. We expect the performance of this approach to be closely 
tied to the choice of approximate posterior; e.g., samples from the plug-in mean posterior will likely under-explore the 
parameter space. The \citet{FerEmulation} approach of sampling from a mixture of the prior and approximate posterior might
be viewed as a more scalable analog of the method in \citet{gp_surrogates_random_exploration}, in the sense of 
explicitly decoupling exploration and exploitation. We believe further work is warranted to better understand the 
behavior of these methods, and their applicability to large-scale batch design.

\subsection{Adaptive Local Surrogates}
Local in the sense of only using design points in region of high posterior: \citep{hydrologicalModel2}
Tempering approaches: \citep{JosephMEDSampling,Li_2014}


\subsection{Exact-Approximate MCMC}
Throughout this section, we have framed the question of surrogate refinement through a standard active 
learning lens, in which the selection of design points proceeds over a sequence of rounds. We briefly
highlight related methods that stray from this framework; in particular, algorithms that 
perform sequential design within a single MCMC run, often with the goal of converging 
to the true target $\postDensNorm$. Such methods are sometimes referred to as \textit{exact-approximate}
MCMC. The papers \citet{Li_2014,ConradLocalExactMCMC} 
adaptively construct local polynomial surrogates within an MCMC algorithm, and are able to establish asymptotic 
exactness by showing the polynomial approximation error diminishes over time.
\citep{ActiveLearningMCMC}
also conduct sequential design within a MCMC run, using emulator predictions at points where the 
surrogate is confident, and running exact simulations at points that exceed a user-defined uncertainty tolerance.
We note that it is possible to ensure convergence to $\postDensNorm$ even with a fixed surrogate
by using the surrogate predictions to filter out poor proposals, avoiding the cost of unnecessary 
expensive model runs. This idea dates back to the delayed acceptance mechanism of \citep{DelayedAcceptance}
for Metropolis-Hastings algorithms.
In \citet{MCMC_GP_proposal}, a similar approach is used to accelerate Hamiltonian Monte Carlo.
These algorithms all leverage a surrogate in various ways with the goal of reducing the simulation load, while
maintaining asymptotic exactness. The cost of exactness is the requirement of more simulator runs, often 
performed serially. We therefore view such approaches as well-suited to inverse problems with moderately 
expensive forward models. Convergence to $\postDensNorm$ will typically be impractical as the computational
costs increase, especially in the large $\Nbatch$, small $\Nrounds$ setting.

\todo: add references;
Design within MCMC but not asymptotically exact: \citep{hydrologicalModel2}


\section{Practical Recommendations} \label{sec:recs}
We now provide a set of practical recommendations for building surrogate models, constructing
posterior approximations, and sequentially refining the surrogate. \Cref{sec:case-study}
highlights these recommendations through a numerical case study.

\begin{rec} \label{rec:prop-uncertainty}
The choice of surrogate model and uncertainty propagation method should be conducted jointly.
\end{rec}

In general, we emphasize the importance of propagating surrogate uncertainty in 
the posterior approximation, but are not convinced of a single ``correct'' uncertainty 
propagation method. Instead we find a few different approaches to be reasonable, but
emphasize that the empirical success of any particular method will be closely tied to the
surrogate model itself. The expected posterior approximation is conceptually appealing
as a direct summary of the random posterior $\postNormEm[\Ndesign]$, but is often 
challenging to implement and computationally expensive. 
Therefore, we tend to prefer the noisy MCMC methods defined in \Cref{sec:MH-approx},
which show empirical promise, require only a single MCMC run, and are applicable to 
generic probabilistic surrogates.
However, in choosing these methods one needs to appreciate how the behavior of the posterior
approximation will vary based on the properties of the surrogate predictive distribution.
For example, in log-density emulation the expected likelihood approximation can concentrate in very 
small regions of parameter space where the surrogate is uncertain, in which case a pseudo-marginal 
MCMC run will almost certainly fail. However, in this case we have found that the simple adjustment 
of incorporating a bound constraint in the emulator can solve this problem and produce reasonable 
results. Alternatively, the E-acc method tends to be more robust with respect to 
heavy-tailed surrogate predictions, but requires stronger requirements to ensure 
existence (\Cref{sec:existence}). 

\begin{rec} \label{rec:multiscale}
Treat density emulation as a multiscale problem.
\end{rec}

In many applications, it is common for log-likelihoods and log-posteriors to exhibit various
properties that render log-density emulation a challenging task. They tend to have very 
large dynamic ranges over the support of the prior distribution, even when their range 
may be relatively small over the posterior support. In addition, their values may drop sharply 
in certain directions while asymptoting in others. In general, we find that traditional stationary 
surrogates perform quite poorly in approximating such response surfaces.
\todo: finish this recommendation

\begin{rec} \label{rec:oversample-tails}
The design should oversample the tails.
\end{rec}
As discussed in \Cref{sec:seq-design}, it is natural to aim to place design points in regions
where $\postDensNorm(\Par)$ is large. However, it is often critical to also include sufficient
points in regions where $\postDensNorm(\Par)$ is small, and at least initially, where 
$\priorDens(\Par)$ is small as well. Intuitively, such points are required to 
learn the global trend of the response surface (see \Cref{rec:multiscale}) and to ``pin down''
regions of negligible posterior mass. In constructing the initial design, we often find it helpful
to sample design points from an over-dispersed version of $\priorDens$. In the 
case study in \Cref{sec:case-study} we sample the initial design from the prior, but also
explicitly include additional points in the tails of the prior. We also suggest that sequential
acquisition schemes are designed to ensure sufficient exploration. This can be encoded
in an acquisition function (e.g., via the choice of $\weightDens[\Ndesign]$ in \Cref{eq:acq-intvar})
or via the explicit selection of exploratory points \citep{gp_surrogates_random_exploration}.  
For example, at each active learning iteration \citet{gp_surrogates_random_exploration,FerEmulation}. 
We note that these recommendations are in line with the theoretical results of \citet{StuartTeck2}, who 
suggest designs based on an over-dispersed version of $\postDensNorm(\Par)$.
The notion of oversampling the tails has also been proposed to construct designs
for numerical integration \citep{briol2017sampling}.

\begin{rec} \label{rec:pred-check-tails}
Conduct goal-oriented predictive checks of the induced posterior density surrogate.
\end{rec}
As discussed in \Cref{sec:existence}, one must take care in designing emulators that
induce well-defined posterior approximations. In MCMC-based inference, this is crucial for
avoiding divergent MCMC chains. \Cref{rec:multiscale,rec:oversample-tails}
offer modeling suggestions to help avoid such issues, but they do not provide certified 
guarantees. We suggest an explicit prior predictive check to diagnose problematic 
tail behavior in the induced posterior surrogate $\postEm[\Ndesign]$. A simple graphical
check consists of plotting an upper quantile of $\mathrm{law}(\lpostEm[\Nesign](\Par))$ 
as $\Par$ varies over the parameter space. One should ensure that $\Par$ is allowed to 
vary well past the extent of the design points in order to assess the extrapolation behavior 
of the surrogate. A high quantile (say, 95\% or 99\%) is chosen to assess whether 
the distribution of $\lpostEm[\Ndesign](\Par)$ appears to be converging almost surely 
to $-\infty$ in the limit. For multidimensional input spaces we suggest varying one 
parameter at a time, projecting onto different fixed values of the other parameters.
Performing this simple check does not require any additional 
evaluations of the expensive simulator, and can prevent wasting resources by having
to wait to uncover issues with the surrogate during inference (for example, 
\citet{emPostDens} use divergent MCMC chains as a sort of surrogate diagnostic check).
 See \Cref{fig:vsem-prior-check-lpostem} in the below case study for an example
 of this predictive check.

\begin{rec} \label{rec:bound-constraints}
Enforce bound constraints.
\end{rec}

\todo: Recommend rectified adjustment.

\begin{rec} \label{rec:multimodal-post-approx}
Embrace multi-modal posterior approximations.
\end{rec}

In utilizing a flexible statistical model to approximate a complex response surface, one expects
the approximation to feature local modes. Given that the surface corresponds to a
log-posterior density in this setting, it is natural to anticipate that even a deterministic emulator
may induce multimodal posterior approximations, even when the true posterior is unimodal. 
Multimodality is even more common when propagating surrogate uncertainty, as the uncertainty 
level will vary over the input space (e.g., consider the ``sausage-shaped'' confidence 
bands in \Cref{fig:em_dist_1d}). For example, modes in the approximate posterior may reflect
that the surrogate expects high posterior mass in a certain region, or that the surrogate is simply 
uncertain in the region. This uncertainty quantification is essential for acknowledging surrogate 
inadequacies and for guiding future improvements (\Cref{sec:seq-design}). However, it does
present computational challenges in performing inference. While specialized algorithms 
can be employed \citep{adaptiveMultimodal}, we typically prefer practical heuristic approaches
in the spirit of \citep{multimodalYao}. In particular, we run multiple MCMC chains in parallel with 
the aim of characterizing the dominant modes of the distribution. We perform within-chain 
convergence diagnostics to validate that the chains are well-mixed locally, and then 
utilize heuristics to assign weights to each chain.

\vspace

\todo: Add active learning recommendation

\section{Numerical Case Study} \label{sec:case-study}
We present a numerical illustration of a surrogate-assisted Bayesian inference workflow, highlighting
the practical recommendations given in the previous section.
Our illustrative example is motivated by the problem of producing near-term forecasts of the 
terrestrial carbon cycle \citep{nearTermForecasts,FerEmulation}. In this setting, both model parameters 
and initial conditions are typically unknown and must be learned from observational data. Performing 
such parameter estimation runs into computational challenges for large-scale land surface models, 
underscoring the potential for surrogates in this domain \citep{paramLSM}. 

\subsection{Model Setup}
We start by introducing the mechanistic simulator model, and then define a Bayesian inverse 
problem with respect to this model.

\subsubsection{Mechanistic Model}
As a simple concrete example, we utilize the \textit{Very Simple Ecosystem Model} (VSEM), a toy model capturing the basic 
structure of more complex land surface models, thus ideally suited for algorithm evaluation \citep{vsem}. The model 
describes the evolution of the state vector
\begin{align*}
\state(\Time) \Def [\stateV(\Time), \stateR(\Time), \stateS(\Time)]^\top \in \R_{\geq 0}^{3}, 
\end{align*}
with the state variables representing the quantity of carbon (\textrm{kg C/$m^2$}) in above-ground vegetation, below-ground 
vegetation (roots), and soil reservoirs, respectively. The VSEM model is given by the system of coupled 
ordinary differential equations
\begin{align}
\dstateV(\Time) &= \alphaV \NPP(\stateV(\Time), \forcing(\Time)) - \frac{\stateV(\Time)}{\tauV} \\
\dstateR(\Time) &= (1.0 - \alphaV) \NPP(\stateV(\Time), \forcing(\Time)) - \frac{\stateR(\Time)}{\tauR} \nonumber \\ 
\dstateS(\Time) &= \frac{\stateR(\Time)}{\tauR} + \frac{\stateV(\Time)}{\tauV} - \frac{\stateS(\Time)}{\tauS}, \nonumber
\end{align}
where the model forcing $\forcing(\Time)$ is provided by photosynthetically active radiation 
(\textrm{MJ/$m^2$/day}), and the dynamics rely on the following parameterized model of 
Net Primary Productivity (NPP; \textrm{kg C/$m^2$/day}),
\begin{align}
\NPP(\stateV, \forcing) &= (1 - \fracRespiration) \GPP(\stateV, \forcing) \\
\GPP(\stateV, \forcing) &= \forcing \cdot \LUE \cdot \left[1 - \exp\left\{-\KEXT \cdot \LAI(\stateV) \right\} \right] \nonumber \\
\LAI(\stateV) &= \LAR \cdot \stateV, \nonumber
\end{align} 
where $\GPP(\stateV, \forcing)$ and $\LAI(\stateV)$ model Gross Primary Productivity (GPP; \textrm{kg C/$m^2$/day})
and Leaf Area Index (LAI; \textrm{$m^2/m^2$}), respectively.
Note that the ODE is of the form \ref{ode_ivp}, with the caveat that the dynamics $\odeRHS$ additionally depend on a 
time-dependent forcing $\forcing(\Time)$. Given a value of $\Par$, we numerically solve the ODE at a daily time step
via the basic Euler scheme implemented in the R \verb+BayesianTools+ package \citep{vsem}. We recall the discretized 
parameter-to-state map 
$\solutionOp: \Par \mapsto \left[\indexTime[0]{\state}(\Par), \dots, \indexTime[\NTimeStep]{\state}(\Par) \right]^\top$, 
as defined in \Cref{eq:ode-solution-op}.

Potential calibration parameters in this model include 
$\{\alphaV, \tauV, \tauR, \tauS, \LUE, \KEXT, \fracRespiration, \LAR\}$, as well as the initial conditions for the three state
variables $\{\stateV(0), \stateR(0), \stateS(0)\}$.
Noting that the model is over-parameterized, we will focus on estimating 
$\Par \Def \{\KEXT, \fracRespiration, \tauV, \stateV(0)\}$ with the remaining parameters held fixed.

\subsubsection{Statistical Model}
We consider estimating the parameters $\Par$ given noisy monthly averages of LAI over a two year period.
We assume an additive Gaussian noise model
\begin{align}
\obs &= \fwd(\Par) + \noise \label{eq:vsem-inv-prob} \\
\noise &\sim \Gaussian(0, \sigma^2 I) \nonumber 
\end{align}
where $\fwd: \parSpace \to \R^{24}$ maps to the twenty-four LAI averages; i.e., the first entry of $\fwd(\Par)$
is given by 
\begin{equation}
\fwd_{1}(\Par) \Def \frac{\LAR}{30} \sum_{\timeIndex=1}^{30} \state_{\textrm{v},\timeIndex}(\Par),
\end{equation}
and the remaining entries simply change the indices of the summation. For simplicity, we fix $\sigma^2$
and assume a priori independence over the entries of $\Par$. Synthetic data $\obs$ is simulated
using \Cref{eq:vsem-inv-prob} with fixed ground truth values $\{\Par_{\star}, \sigma^2_{\star}\}$. The same 
model is used when solving the inverse problem, but the values of the fixed parameters (those not
being estimated) and the noise variance are changed, implying the presence of parametric misspecification.
Table \todo compares these misspecified values relative to the ground truth, while
table \todo summarizes the prior distribution $\Par \sim \priorDens$. As a baseline for comparison, we 
draw samples from the posterior using exact MCMC. \Cref{fig:vsem_prior_post} compares the prior 
and posterior marginal distributions, while \Cref{fig:vsem_pred_dists} compares the prior and 
posterior predictive distributions over LAI trajectories.

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.24\textwidth} % Cv 
         \centering
         \includegraphics[width=\textwidth]{{vsem/prior_post_par_Cv.png}}
         \caption{$\stateV(0)$}
         \label{fig:vsem_prior_post_Cv}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.24\textwidth} % GAMMA
         \centering
         \includegraphics[width=\textwidth]{{vsem/prior_post_par_GAMMA.png}}
         \caption{$\gamma$}
         \label{fig:vsem_prior_post_GAMMA}
     \end{subfigure}
      \begin{subfigure}[b]{0.24\textwidth} % tauV
         \centering
         \includegraphics[width=\textwidth]{{vsem/prior_post_par_tauV.png}}
         \caption{$\tauV$}
         \label{fig:vsem_prior_post_tauV}
     \end{subfigure}
          \begin{subfigure}[b]{0.24\textwidth} % KEXT
         \centering
         \includegraphics[width=\textwidth]{{vsem/prior_post_par_KEXT.png}}
         \caption{$\KEXT$}
         \label{fig:vsem_prior_post_KEXT}
     \end{subfigure}
        \caption{Marginal prior (black dashed) and exact posterior (red) distributions for the four
        calibration parameters.}
        \label{fig:vsem_prior_post}
\end{figure}


\begin{figure}
     \centering
     \begin{subfigure}[b]{0.48\textwidth} % Prior predictive distribution
         \centering
         \includegraphics[width=\textwidth]{{vsem/prior_pred_dist.png}}
         \caption{Prior Predictive}
         \label{fig:vsem_prior_pred}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.48\textwidth} % Posterior predictive distribution
         \centering
         \includegraphics[width=\textwidth]{{vsem/post_pred_dist.png}}
         \caption{Posterior Predictive}
         \label{fig:vsem_post_pred}
     \end{subfigure}
        \caption{(Left) The distribution over LAI trajectories induced by $\Par \sim \priorDens$. 
        The red points are the observed noisy observations of monthly LAI averages, with the 
        vertical bars indicating $\pm \sigma$ observation noise. The blue shaded region captures 
        90\% prior predictive probability. The gray lines are prior predictive samples, and the black 
        line is the ground truth LAI trajectory used to generate the data. (Right) The analogous plot
        for the posterior predictive distribution; i.e., the distribution over LAI trajectories induced 
        by $\Par \sim \postDens$.}
        \label{fig:vsem_pred_dists}
\end{figure}

\subsection{Initial Surrogate Fits}
For this problem, we compare GP emulators for both the forward model and log-posterior.
Let $\funcEm[\Ndesign]$ denote the underlying GP prediction of $\func$.
To evaluate these emulators we consider both prior and posterior averaged continuous
ranked probability score (CRPS; \citep{scoringRules})
\begin{align}
\mathrm{crps}(\funcEm[\Ndesign]) &\Def \int_{\parSpace} \mathrm{crps}(\funcEm[\Ndesign](\Par), \func(\Par)) \weightDens[](\Par) d\Par
\end{align}
and multivariate log-score (i.e., predictive deviance; \citep{scoringRules})
\begin{align}
\mathrm{logS}(\funcEm[\Ndesign]) 
&\Def \log \Gaussian(\func(\parMat) \given \emMean[\Ndesign]{}(\parMat), \emKer[\Ndesign]{}(\parMat)),
&&\parMat \overset{\mathrm{iid}}{\sim} \weightDens[].
\end{align}

The choice $\weightDens[] \in \{\priorDens, \postDensNorm\}$ determines whether error is assessed with
respect to the prior or true posterior; both scores are approximated by sampling $1000$ points 
from the relevant distribution. We similarly estimate 
\begin{align}
\mathrm{mae}(\postEm[\Ndesign]) &\Def 
\int_{\parSpace} \abs{\postApproxMean[\Ndesign](\Par) - \postDens(\Par)} \weightDens[](\Par) d\Par,
\end{align}
to evaluate the quality of the plug-in mean posterior approximation.

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.49\textwidth} % lpost em, prior evaluation
         \centering
         \includegraphics[width=\textwidth]{{vsem/pred_scatter_prior_lpostem.png}}
         \caption{$\lpostEm[\Ndesign], \weightDens[] = \priorDens$}
         \label{fig:vsem_pred_scatter_prior_lpostem}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth} % lpost em, posterior evaluation
         \centering
         \includegraphics[width=\textwidth]{{vsem/pred_scatter_post_lpostem.png}}
         \caption{$\lpostEm[\Ndesign], \weightDens[] = \postDensNorm$}
         \label{fig:vsem_pred_scatter_post_lpostem}
     \end{subfigure}
          \begin{subfigure}[b]{0.49\textwidth} % fwd em, prior evaluation
         \centering
         \includegraphics[width=\textwidth]{{vsem/pred_scatter_prior_lpostem.png}}
         \caption{$\fwdEm[\Ndesign], \weightDens[] = \priorDens$}
         \label{fig:vsem_pred_scatter_prior_fwdem}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth} % fwd em, posterior evaluation
         \centering
         \includegraphics[width=\textwidth]{{vsem/pred_scatter_post_lpostem.png}}
         \caption{$\fwdEm[\Ndesign], \weightDens[] = \postDensNorm$}
         \label{fig:vsem_pred_scatter_post_fwdem}
     \end{subfigure}
        \caption{Emulator predictions based on the initial design. The top and bottom rows correspond
        to the forward model and log-posterior emulator, respectively. The left and right columns correspond
        to evaluation inputs sampled from the prior and exact posterior, respectively. The points summarize
        emulator mean predictions, while vertical bars are 90\% emulator predictive intervals. The orange 
        bars indicate that the 90\% interval does not contain the truth.}
        \label{fig:vsem_pred_scatter}
\end{figure}

\subsubsection{Forward Model Emulator}
\subsubsection{Log-Posterior Emulator} \label{sec:case-study-lpost-em}
This inverse problem presents several challenges for log-density emulators: the dynamic 
range of the log-likelihood over the prior support is quite large, the parameter space is 
unbounded, and the likelihood remains relatively flat along certain directions in parameter
space. One must therefore take care to control the tails of the emulator in order to produce well-defined
posterior approximations. This situation is not uncommon in applications, as it may simply reflect the 
fact that the simulator predictions asymptote in certain directions of parameter space. 
In general, we find a stationary GP performs quite poorly in such contexts. One could argue that 
the placement of design points in the tails of the prior distribution could alleviate this issue, 
as it would force the GP predictions downward. Although the GP would revert to its prior
as the distance from the design points increases, the hope is  
that an MCMC algorithm would never reach such regions, as the design points in the tail
would effectively create a ``moat'' of low probability.
Moreover, if emulating the log-likelihood then one could also rely on the prior to drive the posterior 
density emulator to zero.

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.49\textwidth} % tauV
         \centering
         \includegraphics[width=\textwidth]{{vsem/extrap_q95_lpostem_tauV.png}}
         \caption{$\tauV$}
         \label{fig:vsem-prior-check-lpostem-tauv}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth} % Cv
         \centering
         \includegraphics[width=\textwidth]{{vsem/extrap_q95_lpostem_Cv.png}}
         \caption{$\stateV(0)$}
         \label{fig:vsem-prior-check-lpostem-cv}
     \end{subfigure}
        \caption{The prior predictive check recommended in \Cref{rec:pred-check-tails} 
        for the log-posterior emulator, focusing on the two parameters with unbounded support. 
        The lines correspond to the $95^{\mathrm{th}}$ percentile of the log-posterior surrogate 
        $\mathrm{Quantile}_{0.95}(\lpostEm[\Ndesign](\Par))$ as only one parameter in $\Par$ 
        is varied. Different lines correspond to different fixed values of the remaining parameters,
        which have been sampled from $\priorDens$. Dashed vertical lines indicate the extent of 
        the design points in that dimension, with inputs outside of these bounds representing
        pure extrapolation.}
        \label{fig:vsem-prior-check-lpostem}
\end{figure}

\subsection{Active Learning}
\todo: note that different active learning algorithms can be combined with different acquisition 
functions to define many algorithms. Mention this is too many combs to test, so we instead
first run active learning algorithms, then focus on the best performing algorithm to compare
the posterior approximation.



\section{Related Work and Extensions} \label{sec:related-work}

\subsection{Computer Model Calibration} \label{sec:computer-model-calibration}
The challenge of emulating a black-box computer model has received widespread attention 
well beyond the scope of Bayesian inference. The design of surrogate models for Bayesian 
inverse problems may be informed by the vast literature from the computer experiments, 
engineering, applied math, machine learning, and statistics communities. As a starting point, 
we refer readers to \citet{gramacy2020surrogates,design_analysis_computer_experiments,SanterCompExp,UQpredCompSci} 
and the references therein. It is worth taking a moment to clarify the scope of our review 
with respect to related work in the computer experiments literature in particular.
Indeed, early work in this field addressed the challenge of learning 
model parameters  $\Par$ from observational data via the use of a surrogate for $\fwd$, a problem 
commonly referred to as \textit{computer model calibration} (see \citet{computerModelCalibrationReview}
for a review). When cast as a problem of Bayesian inference, the calibration problem falls within the 
framework considered in this article. However, much of this early calibration work focused on 
the added challenge of learning a discrepancy term between the computer model $\fwd$ and the 
true underlying system \citep{ModelDiscrepancy,emPostDens,OakleyllikEm}. 
For example, the pioneering work \citet{KOH} considers jointly learning 
a forward model emulator, calibration parameters, and a discrepancy function within a single 
Bayesian model. By contrast, we do not consider discrepancy modeling in this review, and moreover
focus on the alternative modular workflow, where the surrogate is fit offline 
without seeing the calibration data $\obs$ \citep{modularization}. 
\footnote{This point is specific to the forward model emulation setting. Log-density emulators 
do depend on $\obs$, since the log-likelihood is a function of the data.}
This modular two-stage approach naturally leads to 
the question of how to propagate the surrogate uncertainty in the calibration stage, which is one 
of the central questions motivating this review.

\subsection{Probabilistic Numerics} \label{sec:prob-numerics}
See Sullivan, Hennig papers; and Teckentrup random forward models paper section 5

\subsection{Stochastic Simulators and Simulation-Based Inference} \label{sec:sbi}
\citet{Lueckmann2018LikelihoodfreeIW,VehtariParallelGP,ABCApproxLik,
BurknerAmortized,llikEmABC,ABCGP}

\subsection{Other}
Multifidelity methods? Active subspaces? Data subsampling/randomized misfits?

\section{Conclusion} \label{sec:conclusion}


% Appendix 
\section{Appendix}

\subsection{Surrogate-Induced Posterior Distributions}
This section proves \Cref{eq:fwd-em-Gaussian,eq:llik-em-Gaussian}, which characterize the distribution 
of $\postEm[\Ndesign]$ in the Gaussian forward model and log-density emulation settings, respectively.
The latter result is immediate, but the former requires proving some preliminary Gaussian identities.

\subsubsection{Forward Model Emulator}
We start by deriving the convolution of two Gaussians.

\begin{prop} \label{Gaussian_convolution}
Let $\Gaussian(A \mu, \likPar)$ and $\Gaussian(m, C)$ be Gaussian distributions on $\R^{\dimObs}$ and $\R^{\dimPar}$, 
respectively, with $A \in \R^{\dimObs \times \dimPar}$ and $\likPar, C$ symmetric, positive definite matrices. Then 
\begin{align*}
\int_{\R^{\dimPar}} \Gaussian(\obs \given A \mu, \likPar) \Gaussian(\mu \given m, C) d\mu
&= \Gaussian(\obs \given Am, \likPar + ACA^\top). 
\end{align*}
\end{prop}

\begin{proof} 
\todo
\end{proof}

We next prove a lemma that will be used in calculating $\Var[\postDens(\Par; \fwdEm[\Ndesign])]$.
\begin{lemma} \label{lemma:squared_Gaussian_density}
Let $\Gaussian(m, C)$ be a Gaussian distribution on $\R^{\dimObs}$ with $C$ a symmetric, positive-definite 
matrix. Then, for $\obs \in \R^{\dimObs}$, 
\begin{align*}
\Gaussian(\obs \given m, C)^2 
&= 2^{-\dimObs/2} \det(2\pi C)^{-1/2} \Gaussian\left(\obs \given m, \frac{1}{2}C\right). 
\end{align*}
\end{lemma}

\begin{proof}
\begin{align*}
\Gaussian(\obs \given m, C)^2 
&= \det(2\pi C)^{-1} \Exp{-\frac{1}{2} (\obs - m)^\top \left[\frac{1}{2}C \right]^{-1}(\obs - m)} \\
&= \det(2\pi C)^{-1} \det(2\pi (1/2)C)^{1/2} \Gaussian\left(\obs \given m, \frac{1}{2}C\right) \\
&= 2^{-\dimObs/2} \det(2\pi C)^{-1/2} \Gaussian\left(\obs \given m, \frac{1}{2}C\right). 
\end{align*}
\end{proof}

\Cref{eq:fwd-em-Gaussian} follows directly from the following result.

\begin{prop} \label{prop:Gaussian_marginal_moments}
Assume $\obs \given \mu \sim \Gaussian(A \mu, \likPar)$ and $\mu \sim \Gaussian(m, C)$, where $\mu \in \R^{\dimPar}$, 
$A \in \R^{\dimObs \times \dimPar}$, and $\likPar$, $C$ are both symmetric, positive definite. Then 
\begin{align*}
\E\left[\Gaussian(\obs \given A \mu, \likPar) \right] &= \Gaussian(\obs \given Am, \likPar + ACA^\top) \\
\Var\left[\Gaussian(\obs \given A \mu, \likPar) \right] 
&= \frac{\Gaussian\left(\obs \given Am, \frac{1}{2} \likPar + ACA^\top \right)}{2^{\dimObs/2} \det(2\pi \likPar)^{1/2}} - 
\frac{\Gaussian\left(\obs \given Am, \frac{1}{2}[\likPar + ACA^\top] \right)}{2^{\dimObs/2} \det(2\pi[\likPar + ACA^\top])^{1/2}}
\end{align*}
\end{prop}

\begin{proof} 
The first result follows immediately from \Cref{Gaussian_convolution}. For the variance, we have 
\begin{align}
\Var\left[\Gaussian(\obs \given A \mu, \likPar) \right] 
&= \E\left[\Gaussian(\obs \given A \mu, \likPar)^2 \right] - \E\left[\Gaussian(\obs \given A \mu, \likPar) \right]^2 \nonumber \\
&= \E\left[\Gaussian(\obs \given A \mu, \likPar)^2 \right] - \Gaussian(\obs \given Am, \likPar + ACA^\top)^2. \label{two_terms_variance}
\end{align}
Starting with the first term, we apply \Cref{lemma:squared_Gaussian_density} and 
\Cref{Gaussian_convolution}, respectively, to obtain 
\begin{align*}
\E\left[\Gaussian(\obs \given A \mu, \likPar)^2 \right]
&= 2^{-\dimObs/2} \det(2\pi \likPar)^{-1/2} \E\left[\Gaussian\left(\obs \given A\mu, \frac{1}{2}\likPar \right)\right] \\
&= 2^{-\dimObs/2} \det(2\pi \likPar)^{-1/2} \Gaussian\left(\obs \given Am, \frac{1}{2}\likPar + ACA^\top \right).
\end{align*}
For the second term in \ref{two_terms_variance}, another application of \Cref{lemma:squared_Gaussian_density} gives
\begin{align*}
\Gaussian(\obs \given Am, \likPar + ACA^\top)^2
&= 2^{-\dimObs/2} \det(2\pi[\likPar + ACA^\top])^{-1/2} \Gaussian\left(\obs \given Am, \frac{1}{2}[\likPar + ACA^\top]\right).
\end{align*}
Plugging these expressions back into \ref{two_terms_variance} completes the proof. 
\end{proof}

\subsubsection{Log-Density Emulator}




\subsection{Marginal Approximation with Gaussian Likelihood: Forward Model Emulation}
The closed-form computations related to the marginal approximation with a Gaussian 
likelihood follow from standard results regarding the convolution of Gaussian densities.  








\subsection{Marginal Acceptance Probability}
In this section we derive an expression for 
\begin{align}
\llikEmJointMarg[\Ndesign]{\accProbMH}(\Par, \propPar) 
&= \E_{\llikEm[\Ndesign]} \left[\min\left\{1, \Em[\Ndesign]{\accProbRatio}(\Par, \propPar)\right\} \right], 
\end{align}
as considered in \ref{acc_prob_joint_marg}. We start by noting 
\begin{align}
\Em[\Ndesign]{\accProbRatio}(\Par, \propPar)
&\sim \LN\left(\log C + \emMean[\Ndesign]{\llik}(\propPar) - \emMean[\Ndesign]{\llik}(\Par), \Var\left[\llikEm[\Ndesign](\propPar) - \llikEm[\Ndesign](\Par) \right] \right),
\label{acc_ratio_LN}
\end{align}
where 
\begin{align*}
C \Def \frac{\priorDens(\propPar) \propDens(\propPar, \Par)}{\priorDens(\Par) \propDens(\Par, \propPar)}.
\end{align*}
Thus, the required computation reduces to computing the expectation of $\min\left\{1, Y \right\}$, where $Y$ is a log-normally distributed 
random variable. 

\begin{lemma} \label{lemma:exp_max_one_LN}
Let $Y \sim \LN(m, s^2)$. Then, 
\begin{align}
\E\left[\min\left\{1, Y \right\} \right] &= \GaussianCDF\left(\frac{m}{s} \right) + \GaussianCDF\left(-\frac{m + s^2}{s} \right) e^{m + \frac{1}{2}s^2}
\end{align}
\end{lemma}

\begin{proof}
We have 
\begin{align}
\E\left[\min\left\{1, Y \right\} \right]
&= \int_{0}^{\infty} \min\{1, y\} \LN(y | m, s^2) dy \nonumber \\
&= \int_{-\infty}^{\infty} \min\{1, e^x\} \Gaussian(x | m, s^2) dx \nonumber \\
&= \int_{0}^{\infty} \Gaussian(x | m, s^2) dx +  \int_{-\infty}^{0} e^x \Gaussian(x | m, s^2) dx \nonumber \\
&= \GaussianCDF(m/s) + \int_{-\infty}^{0} e^x \Gaussian(x | m, s^2) dx. \nonumber \\
&= \GaussianCDF(m/s) + \int_{-\infty}^{0} \frac{1}{\sqrt{2\pi s^2}} e^x \Exp{-\frac{1}{2s^2} (x - m)^2} dx.  
\label{second_integral} 
\end{align}
For the integral in \ref{second_integral} we combine the exponential terms and complete the square. 
This yields 
\begin{align*}
&\int_{-\infty}^{0} \frac{1}{\sqrt{2\pi s^2}} e^x \Exp{-\frac{1}{2s^2} (x - m)^2} dx \\
&= \Exp{-\frac{m^2}{2s^2}} \int_{-\infty}^{0} \frac{1}{\sqrt{2\pi s^2}} \Exp{-\frac{1}{2} \left[\frac{x^2}{2} - 2\left(\frac{m}{s^2} + 1\right)x  \right]} dx \\
&= \Exp{-\frac{m^2}{2s^2} + \frac{[m + s^2]^2}{2s^2}} \int_{-\infty}^{0} \frac{1}{\sqrt{2\pi s^2}} \Exp{-\frac{1}{2s^2}(x - [m+s^2])^2} dx \\
&= \Exp{m + \frac{1}{2}s^2} \GaussianCDF\left(-\frac{m+s^2}{s}\right).
\end{align*}
Plugging this back into \ref{second_integral} completes the proof. 
\end{proof}

We now apply \Cref{lemma:exp_max_one_LN} to obtain the expression for the marginal acceptance probability. 
\begin{prop} \label{prop:joint-marg-accept-prob}
\begin{align*}
\llikEmJointMarg[\Ndesign]{\accProbMH}(\Par, \propPar) 
&= \E_{\llikEm[\Ndesign]} \left[\min\left\{1, \Em[\Ndesign]{\accProbRatio}(\Par, \propPar)\right\} \right] 
= w_1 + w_2 \llikEmJointMarg[\Ndesign]{\accProbRatio}(\Par, \propPar), 
\end{align*}
where 
\begin{align*}
w_1 &= \Prob(\Em[\Ndesign]{\accProbRatio}(\Par, \propPar) \geq 1) \\
w_2 &= \Prob\left(\Em[\Ndesign]{\accProbRatio}(\Par, \propPar) \leq \Exp{-\Var\left[\llikEm[\Ndesign](\propPar) - \llikEm[\Ndesign](\Par) \right]}\right).
\end{align*}
\end{prop}

\begin{proof}
We recall from \ref{acc_ratio_LN} that $\Em[\Ndesign]{\accProbRatio}(\Par, \propPar) \sim \LN(m, s^2)$, with 
\begin{align*}
m &= \log C + \emMean[\Ndesign]{\llik}(\propPar) - \emMean[\Ndesign]{\llik}(\Par) \\
s^2 &= \Var\left[\llikEm[\Ndesign](\propPar) - \llikEm[\Ndesign](\Par) \right]. 
\end{align*}
We thus have 
\begin{align*}
e^{m + \frac{1}{2}s^2} = \E_{\llikEm}\left[\Em[\Ndesign]{\accProbRatio}(\Par, \propPar) \right] 
=  \llikEmJointMarg[\Ndesign]{\accProbRatio}(\Par, \propPar). 
\end{align*}
It remains to verify the expressions for the weights $w_1$ and $w_2$. Letting $Z \sim \Gaussian(0,1)$, 
we apply \Cref{lemma:exp_max_one_LN} to obtain
\begin{align*}
w_1 &= \GaussianCDF(m/s) = \Prob(Z \leq m/s) = \Prob(\Exp{m+sZ} \geq 1) = \Prob(\Em[\Ndesign]{\accProbRatio}(\Par, \propPar) \geq 1) \\
w_2 &= \GaussianCDF(-(m+s^2)/s) = \Prob(\Exp{m + sZ} \leq e^{-s}) = \Prob(\Em[\Ndesign]{\accProbRatio}(\Par, \propPar) \leq e^{-s}).
\end{align*}
\end{proof}

\subsection{Transition Kernels of Approximate MCMC Algorithms} \label{transition_kernel_derivations}
We derive the expression for the \textit{MCWMH-joint} transition 
kernel $\llikEmJointMCWMH[\Ndesign]{\MarkovKernel}$ given in \ref{MCWMH-joint-kernel}. 
Let $\Par \in \parSpace$ and $A \subset \parSpace$ a Borel set. 
We recall that the kernel for a standard MH algorithm is given by 
\begin{align}
\MarkovKernel(\Par, A)
&= \int_{A} \propDens(\Par, \propPar) \accProbMH(\Par, \propPar) d\propPar
+ [1 - \avgAccProbMH(\Par)] \delta_{\Par}(A) \label{MH-kernel}, 
\end{align}
where $\avgAccProbMH(\Par)$ is the overall acceptance probability, averaged over all proposals,
\begin{align}
\avgAccProbMH(\Par)
&= \int_{\parSpace} \propDens(\Par, \propPar) \accProbMH(\Par, \propPar) d\propPar. 
\end{align}
Denote $\parMat \Def \{\Par, \propPar\}$. 
The \textit{MCWMH-joint} algorithm replaces the exact log-likelihood evaluations 
$\llik(\parMat) \Def [\llik(\Par), \llik(\propPar)]^\top$ used to define $\propDens(\Par, \propPar)$ by 
sampled approximate values 
\begin{align}
\llikSamp_{\parMat} \Def [\llikSamp, \llikSampProp]^\top \sim \Gaussian(\emMean[\Ndesign]{\llik}(\parMat), \emKer[\Ndesign]{\llik}(\parMat)). 
\end{align}
We let $\Em[\Ndesign]{\accProbMH}(\Par, \propPar | \llikSamp_{\parMat})$ denote the approximate acceptance probability defined using 
the sampled values $\llikSamp_{\parMat}$. The probability of accepting a state in the set $A$, conditional on the sample $\llikSamp_{\parMat}$, 
is thus 
\begin{align}
\Prob(\indexMCMC[\mcmcIndex+1]{\Par} \in A | \Par, \llikSamp_{\parMat})
&=  \int_{A} \propDens(\Par, \propPar) \Em[\Ndesign]{\accProbMH}(\Par, \propPar | \llikSamp_{\parMat}) d\propPar. 
\end{align}
The unconditional probability follows from the law of total probability:
\begin{align}
\Prob(\indexMCMC[\mcmcIndex+1]{\Par} \in A | \Par)
&= \int_{\R^2} \Prob(\indexMCMC[\mcmcIndex+1]{\Par} \in A | \Par, \llikSamp_{\parMat}) \Gaussian(\llikSamp_{\parMat} | \emMean[\Ndesign]{\llik}(\parMat), \emKer[\Ndesign]{\llik}(\parMat)) d\llikSamp_{\parMat} \\
&= \int_{\R^2} \int_{A} \propDens(\Par, \propPar) \Em[\Ndesign]{\accProbMH}(\Par, \propPar | \llikSamp_{\parMat})  
\Gaussian(\llikSamp_{\parMat} | \emMean[\Ndesign]{\llik}(\parMat), \emKer[\Ndesign]{\llik}(\parMat)) d\propPar \ d\llikSamp_{\parMat} \\
&= \int_{A} \propDens(\Par, \propPar) \int_{\R^2}  \Em[\Ndesign]{\accProbMH}(\Par, \propPar | \llikSamp_{\parMat})  
\Gaussian(\llikSamp_{\parMat} | \emMean[\Ndesign]{\llik}(\parMat), \emKer[\Ndesign]{\llik}(\parMat)) d\llikSamp_{\parMat} \ d\propPar \label{flip_integral_order} \\
&= \int_{A} \propDens(\Par, \propPar) \llikEmJointMarg[\Ndesign]{\accProbMH}(\Par, \propPar)  d\propPar
\end{align}
where \ref{flip_integral_order} follows from Tonelli's theorem, and using the definition of $\llikEmJointMarg[\Ndesign]{\accProbMH}(\Par, \propPar)$
in \ref{acc_prob_joint_marg}. Setting $A \Def \parSpace$ in the above integral yields the overall acceptance probability 
\begin{align}
\llikEmJointMarg[\Ndesign]{\avgAccProbMH}(\Par) \Def \int_{\parSpace} \propDens(\Par, \propPar) \llikEmJointMarg[\Ndesign]{\accProbMH}(\Par, \propPar)  d\propPar. 
\end{align}
These quantities thus give 
\begin{align}
\llikEmJointMCWMH[\Ndesign]{\MarkovKernel}(\Par, A)
&= \int_{A} \propDens(\Par, \propPar) \llikEmJointMarg[\Ndesign]{\accProbMH}(\Par, \propPar) d\propPar
+ [1 - \llikEmJointMarg[\Ndesign]{\avgAccProbMH}(\Par)] \delta_{\Par}(A) \label{MH-kernel}, 
\end{align}
which follows from same derivations for the standard MH kernel \ref{MH-kernel} with the marginal acceptance probabilities substituted for
the original ones. The transition kernel for the \textit{MCWMH-ind} algorithm follows immediately by marginalizing with respect 
to $\Gaussian(\emMean[\Ndesign]{\llik}\left(\parMat), \diag\left\{\emKer[\Ndesign]{\llik}(\Par), \emKer[\Ndesign]{\llik}(\propPar) \right\}\right)$
in place of the full joint distribution. 

\subsection{Sequential Design Calculations}
We start by stating an identity for the inversion of partitioned matrices, which is very useful in updating GPs by 
conditioning on new design points. The generic result can be found in the lecture notes \cite{MinkaMatrixLectures}, 
but we specialize the statement to the GP setting.  

\subsubsection{Useful Lemmas}

\begin{prop} \label{partitioned-matrix-inverse}
Let $\funcPrior \sim \GP(\gpMeanPrior, \gpKerPrior)$ be a GP prior, with 
$\funcEm[\Ndesign] \Def \funcPrior | [\funcPrior(\designIn) = \func(\designIn)] \sim \GP(\gpMean[\Ndesign], \gpKer[\Ndesign])$  
the GP predictive distribution after conditioning on the design $(\designIn, \func(\designIn))$. Let 
$\designBatchIn$ be a set of $\Nbatch$ new design points. Define 
$\kerMat[\Ndesign] \Def \gpKerPrior(\designIn)$, $\kerMat[\Nbatch] \Def \gpKerPrior(\designBatchIn)$,
and $\kerMat[\Ndesign,\Nbatch] \Def \gpKerPrior(\designIn[\Ndesign], \designBatchIn)$.  
Then, letting 
$\designIn[\Naugment] \Def \designIn \cup \designBatchIn$, the inverse of the kernel matrix 
evaluated on the augmented design satisfies 
\begin{align}
\gpKerPrior(\designIn[\Naugment])^{-1}
&= \begin{pmatrix} \kerMat[\Ndesign] & \kerMat[\Ndesign,\Nbatch] \\
\kerMat[\Ndesign,\Nbatch]^\top & \kerMat[\Nbatch] \end{pmatrix}^{-1}
=  \begin{pmatrix} \tilde{K} & -\kerMat[\Ndesign]^{-1} \kerMat[\Ndesign,\Nbatch] \gpKer[\Ndesign](\designBatchIn)^{-1} \\
-\gpKer[\Ndesign](\designBatchIn)^{-1} \kerMat[\Ndesign,\Nbatch]^\top  \kerMat[\Ndesign]^{-1} & \gpKer[\Ndesign](\designBatchIn)^{-1} \end{pmatrix},
\end{align}
where 
\begin{align}
\tilde{K} = \kerMat[\Ndesign]^{-1} + \kerMat[\Ndesign]^{-1} \kerMat[\Ndesign,\Nbatch] \gpKer[\Ndesign](\designBatchIn)^{-1} \kerMat[\Nbatch,\Ndesign] \kerMat[\Ndesign]^{-1}.
\end{align}
Thus, assuming $\kerMat[\Ndesign]^{-1}$ has already been computed, $\gpKerPrior(\designIn[\Naugment])^{-1}$ can be constructed in an additional 
$\BigO(\Nbatch^3 + \Nbatch \Ndesign^2 + \Nbatch^2 \Ndesign)$ operations. 
\end{prop}

We repeatedly use the fact that $\funcPrior|[\funcPrior(\designIn[\Naugment]) = \func(\designIn[\Naugment])]$ and 
$\funcEm[\Ndesign] | [\funcEm[\Ndesign](\designBatchIn) = \func(\designBatchIn)]$ are equal in distribution ; 
i.e., conditioning the GP prior on the entire design 
is equivalent to sequentially conditioning on subsets of the design. For the sake of completeness, we provide the rigorous justification for this below.

\begin{lemma} \label{lemma:gp-condition-order}
Let $\funcPrior \sim \GP(\gpMeanPrior, \gpKerPrior)$ be a GP prior. Consider a set of $\Naugment$ design points $\{\designIn[\Naugment], \funcVal[\Naugment]\}$
partitioned as $\designIn[\Naugment] = \designIn[\Ndesign] \cup \designBatchIn$ and $\funcVal[\Naugment] = \funcVal[\Ndesign] \cup \funcVal[\Nbatch]$.
Let $\funcEm[\Ndesign] \Def \func | [\func(\designIn[\Ndesign]) = \funcVal[\Ndesign]] \sim \GP(\gpMean[\Ndesign], \gpKer[\Ndesign])$. 
Then the random process $\funcPrior | [\funcPrior(\designIn[\Naugment]) = \funcVal[\Naugment]]$ is equal in distribution to the random process
$\funcEm[\Ndesign] | [\funcEm[\Ndesign](\designIn[\Nbatch]) = \funcVal[\Nbatch]]$. 
\end{lemma} 

\begin{proof} 
Since both processes in question are Gaussian it suffices to check that 
\begin{align*}
\E[\funcPrior(\parMat) | \funcPrior(\designIn[\Naugment]) = \funcVal[\Naugment]] 
&= \E[\funcEm[\Ndesign](\parMat) | \funcEm[\Ndesign](\designIn[\Nbatch]) = \funcVal[\Nbatch]] \\
\Cov[\funcPrior(\parMat) | \funcPrior(\designIn[\Naugment]) = \funcVal[\Naugment]] 
&= \Cov[\funcEm[\Ndesign](\parMat) | \funcEm[\Ndesign](\designIn[\Nbatch]) = \funcVal[\Nbatch]],
\end{align*}
for an arbitrary finite set of inputs $\parMat \subset \parSpace$. The quantities on the lefthand side are 
$\gpMean[\Naugment](\parMat)$ and $\gpKer[\Naugment](\parMat)$, by definition. We begin by expanding 
the expression $\gpKerPrior(\parMat, \designIn[\Naugment]) \kerMat[\Naugment]^{-1}$, noting that we 
are borrowing the notation from \Cref{partitioned-matrix-inverse}. Applying the partitioned matrix 
inversion identity from \Cref{partitioned-matrix-inverse} yields 
\begin{align*}
\gpKerPrior(\parMat, \designIn[\Naugment]) \kerMat[\Naugment]^{-1}
&= \begin{pmatrix} \gpKerPrior(\parMat, \designIn[\Ndesign]) &  \gpKerPrior(\parMat, \designIn[\Nbatch]) \end{pmatrix}
\begin{pmatrix} \tilde{K} & -\kerMat[\Ndesign]^{-1} \kerMat[\Ndesign,\Nbatch] \gpKer[\Ndesign](\designBatchIn)^{-1} \\
-\gpKer[\Ndesign](\designBatchIn)^{-1} \kerMat[\Ndesign,\Nbatch]^\top  \kerMat[\Ndesign]^{-1} & \gpKer[\Ndesign](\designBatchIn)^{-1} \end{pmatrix}.
\end{align*}
Denoting $\funcVal[\Ndesign]^\prime \Def \funcVal[\Ndesign] - \gpMeanPrior(\designIn[\Ndesign])$ and 
$\funcVal[\Nbatch]^\prime \Def \funcVal[\Nbatch] - \gpMeanPrior(\designIn[\Nbatch])$, the predictive mean $\gpMean[\Naugment](\parMat)$ is thus given by 
\begin{align*}
\gpMean[\Naugment](\parMat)
&= \gpMeanPrior(\parMat) + \gpKerPrior(\parMat, \designIn[\Naugment]) \kerMat[\Naugment]^{-1}[\funcVal[\Naugment] - \gpMeanPrior(\designIn[\Naugment])] \\
&= \gpMeanPrior(\parMat) + \begin{pmatrix} \gpKerPrior(\designIn[\Ndesign], \parMat) \\  \gpKerPrior(\designIn[\Nbatch], \parMat) \end{pmatrix}^\top
\begin{pmatrix} \tilde{K} & -\kerMat[\Ndesign]^{-1} \kerMat[\Ndesign,\Nbatch] \gpKer[\Ndesign](\designBatchIn)^{-1} \\
-\gpKer[\Ndesign](\designBatchIn)^{-1} \kerMat[\Ndesign,\Nbatch]^\top  \kerMat[\Ndesign]^{-1} & \gpKer[\Ndesign](\designBatchIn)^{-1} \end{pmatrix} 
\begin{pmatrix}  \funcVal[\Ndesign]^\prime \\  \funcVal[\Nbatch]^\prime \end{pmatrix} \\
&= \gpMeanPrior(\parMat) + \gpKerPrior(\parMat, \designIn[\Ndesign])\kerMat[\Ndesign]^{-1}\funcVal[\Ndesign]^\prime + 
\gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1} \funcVal[\Nbatch]^\prime - 
\gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1} \kerMat[\Ndesign,\Nbatch]^\top \kerMat[\Ndesign]^{-1} \funcVal[\Ndesign]^\prime \\
&= \gpMean[\Ndesign](\parMat) + \gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1}[\funcVal[\Nbatch]^\prime - \kerMat[\Ndesign,\Nbatch]^\top \kerMat[\Ndesign]^{-1} \funcVal[\Ndesign]^\prime] \\
&= \gpMean[\Ndesign](\parMat) + \gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1}[\funcVal[\Nbatch]^\prime - \gpMean[\Ndesign](\designIn[\Nbatch]) + \gpMeanPrior(\designIn[\Nbatch])] \\
&= \gpMean[\Ndesign](\parMat) + \gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1}[\funcVal[\Nbatch] - \gpMean[\Ndesign](\designIn[\Nbatch])] \\
&= \E[\funcEm[\Ndesign](\parMat) | \funcEm[\Ndesign](\designIn[\Nbatch]) = \funcVal[\Nbatch]] 
\end{align*}
where we have used the fact that the predictive covariance of the GP $\funcEm[\Ndesign]$ gives 
\[
\gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) = \gpKerPrior(\parMat, \designIn[\Nbatch]) - 
\gpKerPrior(\parMat, \designIn[\Ndesign])\kerMat[\Ndesign]^{-1} \gpKerPrior(\designIn[\Ndesign], \parMat).
\]
The covariance calculation proceeds similarly by replacing $\funcVal[\Ndesign]^\prime$ and $\funcVal[\Nbatch]^\prime$ with 
$\gpKerPrior(\designIn[\Ndesign], \parMat)$ and $\gpKerPrior(\designIn[\Nbatch], \parMat)$, respectively. We obtain 
\begin{align*}
\gpKer[\Naugment](\parMat)
&= \gpKerPrior(\parMat) - \gpKerPrior(\parMat, \designIn[\Naugment]) \kerMat[\Naugment]^{-1}[\funcVal[\Naugment] - \gpMeanPrior(\designIn[\Naugment])] \\
&= \gpKerPrior(\parMat) - \begin{pmatrix} \gpKerPrior(\designIn[\Ndesign], \parMat) \\  \gpKerPrior(\designIn[\Nbatch], \parMat) \end{pmatrix}^\top
\begin{pmatrix} \tilde{K} & -\kerMat[\Ndesign]^{-1} \kerMat[\Ndesign,\Nbatch] \gpKer[\Ndesign](\designBatchIn)^{-1} \\
-\gpKer[\Ndesign](\designBatchIn)^{-1} \kerMat[\Ndesign,\Nbatch]^\top  \kerMat[\Ndesign]^{-1} & \gpKer[\Ndesign](\designBatchIn)^{-1} \end{pmatrix} 
\begin{pmatrix}  \gpKerPrior(\designIn[\Ndesign], \parMat) \\  \gpKerPrior(\designIn[\Nbatch], \parMat) \end{pmatrix} \\
&= \gpKer[\Ndesign](\parMat) - 
\gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1} [\gpKerPrior(\designIn[\Nbatch], \parMat) - \kerMat[\Ndesign,\Nbatch]^\top \kerMat[\Ndesign]^{-1}\gpKerPrior(\designIn[\Ndesign], \parMat)] \\
&= \gpKer[\Ndesign](\parMat) -  \gpKer[\Ndesign](\parMat, \designIn[\Nbatch]) \gpKer[\Ndesign](\designIn[\Nbatch])^{-1} \gpKer[\Ndesign](\designIn[\Nbatch], \parMat) \\
&= \Cov[\funcEm[\Ndesign](\parMat) | \funcEm[\Ndesign](\designIn[\Nbatch]) = \funcVal[\Nbatch]].
\end{align*}

\end{proof}

\subsubsection{Uncertainty in GP Predictive Mean Due to Unobserved Response}

\begin{proof} [Proof of \Cref{lemma:pred-mean-dist}]
Though the result is only required for a single input $\Par$, it is no more difficult to establish for a set of inputs $\parMat$. 
We recall that 
\begin{align*}
\gpMean[\Ndesign](\parMat | \designBatchFunc) 
&= \E[\funcEm[\Ndesign](\parMat) | \funcEm(\designBatchIn) = \designBatchFunc] \\
&= \gpMean[\Ndesign](\parMat) + \gpKer[\Ndesign](\parMat, \designBatchIn) \gpKer[\Ndesign](\designBatchIn)^{-1} [\designBatchFunc - \gpMean[\Ndesign](\designBatchIn)],
\end{align*}
following from the GP predictive equations \ref{kriging_eqns}. Since, $\designBatchFunc|\parMat \sim \Gaussian(\gpMean[\Ndesign](\designBatchIn), \gpKer[\Ndesign](\designBatchIn))$, 
we see that $\gpMean[\Ndesign](\parMat | \designBatchFunc)$ is a linear function of a Gaussian random variable. It is thus Gaussian distributed, with mean and covariance
\begin{align*}
\E_{\designBatchFunc}[\gpMean[\Ndesign](\parMat | \designBatchFunc)]
&= \gpMean[\Ndesign](\parMat) + \gpKer[\Ndesign](\parMat, \designBatchIn) \gpKer[\Ndesign](\designBatchIn)^{-1} [\gpMean[\Ndesign](\designBatchIn) - \gpMean[\Ndesign](\designBatchIn)] = \gpMean[\Ndesign](\parMat) \\
\Cov_{\designBatchFunc}[\gpMean[\Ndesign](\parMat | \designBatchFunc)]
&= \gpKer[\Ndesign](\parMat, \designBatchIn) \gpKer[\Ndesign](\designBatchIn)^{-1}  \gpKer[\Ndesign](\designBatchIn) \gpKer[\Ndesign](\designBatchIn)^{-1} \gpKer[\Ndesign](\designBatchIn, \parMat) \\
&=  \gpKer[\Ndesign](\parMat, \designBatchIn) \gpKer[\Ndesign](\designBatchIn)^{-1} \gpKer[\Ndesign](\designBatchIn, \parMat) \\
&= \gpKer[\Ndesign](\parMat) - \gpKer[\Naugment](\parMat).
\end{align*}
\end{proof}

\subsubsection{Integrated Conditional Variance Calculations: Log-Likelihood Emulation}

\begin{proof} [Proof of \Cref{lemma:evar}]
We start by noting that 
\begin{align*}
\Var[\llikEmRdmDens[\Ndesign](\Par) | \llikEm[\Ndesign](\designBatchIn) = \designBatchLlik]
&= \Var[\priorDens(\Par) \Exp{\llikEm(\Par)} | \llikEm[\Ndesign](\designBatchIn) = \designBatchLlik] \\
&= \priorDens(\Par)^2 \Var[\Exp{\llikEm(\Par)} | \llikEm[\Ndesign](\designBatchIn) = \designBatchLlik],
\end{align*}
so we will focus on the likelihood emulator, ignoring the prior for now. Since 
\begin{align*}
\Exp{\llikEm(\Par)} | [\llikEm[\Ndesign](\designBatchIn) = \designBatchLlik] \sim 
\LN(\emMean[\Ndesign]{\llik}(\Par| \designBatchLlik), \emKer[\Naugment]{\llik}(\Par)),
\end{align*}
we apply the formula for a log-normal variance to obtain 
\begin{align}
\Var[\Exp{\llikEm(\Par)} | \llikEm[\Ndesign](\designBatchIn) = \designBatchLlik]
&= \cst \Exp{2\emMean[\Ndesign]{\llik}(\Par | \designBatchLlik)}, \label{formula_plug_in}
\end{align}
where 
\begin{align*}
\cst \Def \left[\Exp{\emKer[\Naugment]{\llik}(\Par)} -1 \right] \Exp{\emKer[\Naugment]{\llik}(\Par)}
\end{align*}
is not a function of the random variable $\designBatchLlik$. \Cref{lemma:pred-mean-dist} gives 
\begin{align*}
\emMean[\Ndesign]{\llik}(\Par | \designBatchLlik)
&\sim \LN(\emMean[\Ndesign]{\llik}(\Par), \emKer[\Ndesign]{\llik}(\Par) - \emKer[\Naugment]{\llik}(\Par)), 
\end{align*}
which implies 
\begin{align*}
\Exp{2\emMean[\Ndesign]{\llik}(\Par | \designBatchLlik)}
&\sim \Gaussian(2\emMean[\Ndesign]{\llik}(\Par), 4[\emKer[\Ndesign]{\llik}(\Par) - \emKer[\Naugment]{\llik}(\Par)]).
\end{align*}
Applying the formula for a log-normal mean thus yields 
\begin{align*}
\E_{\designBatchLlik} \left[\Exp{2\emMean[\Ndesign]{\llik}(\Par | \designBatchLlik)} \right]
&= \Exp{2\emMean[\Ndesign]{\llik}(\Par)} \Exp{2[\emKer[\Ndesign]{\llik}(\Par) - \emKer[\Naugment]{\llik}(\Par)]} \\
&=  \Exp{2\emMean[\Ndesign]{\llik}(\Par)} \varInflation(\Par; \designBatchIn), 
\end{align*}
where $\varInflation(\Par; \designBatchIn)$ is defined in \ref{var_inflation_factor}. Plugging this expression back 
into \ref{formula_plug_in} gives 
\begin{align*}
\E_{\designBatchLlik} \Var[\Exp{\llikEm(\Par)} | \llikEm[\Ndesign](\designBatchIn) = \designBatchLlik]
&= \cst \Exp{2\emMean[\Ndesign]{\llik}(\Par)} \varInflation(\Par; \designBatchIn) \\
&= \Var[\Exp{\llikEm(\Par)} | \llikEm[\Ndesign](\designBatchIn) = \emMean[\Ndesign]{\llik}(\Par)] \varInflation(\Par; \designBatchIn).
\end{align*}
Multiplying both sides by $\priorDens(\Par)$ completes the proof, with the closed-form expression for the first term following 
immediately from the formula for a log-normal variance. 
\end{proof}

\subsubsection{Integrated Conditional Variance Calculations: Forward Model Emulation}

\begin{proof} [Proof of \Cref{prop:evar-fwd-emulation}]
We begin by noting that the squared prior density can be pulled out of the expectation as
\begin{align*}
\E_{\designBatchFwd} \Var[\postDens(\Par; \fwdEmCond{\designBatchFwd}) | \designBatchFwd]
&= \priorDens^2(\Par) \ \E_{\designBatchFwd}  \Var[\Gaussian\left(\obs |  \fwdEmCond{\designBatchFwd}(\Par), \likPar \right) | \designBatchFwd]. 
\end{align*}
The variance on the righthand side can be expanded as 
\begin{align}
\Var[\Gaussian\left(\obs |  \fwdEmCond{\designBatchFwd}(\Par), \likPar \right) | \designBatchFwd]
&= \frac{\Gaussian\left(\obs | \emMean[\Ndesign]{\fwd}(\Par|\designBatchFwd), \frac{1}{2}\likPar + \emKer[\Naugment]{\fwd}(\Par) \right)}{\det(2\pi \likPar)^{1/2}}
- \frac{\Gaussian\left(\obs | \emMean[\Ndesign]{\fwd}(\Par|\designBatchFwd), \frac{1}{2}\left[\likPar + \emKer[\Naugment]{\fwd}(\Par)\right]  \right)}{\det(2\pi [\likPar + \emKer[\Naugment]{\fwd}(\Par)])^{1/2}}
\end{align}
following from an application of \Cref{eq:fwd-em-Gaussian}. The denominators in the above expression can be 
pulled out of the outer expectation and are seen to equal the denominators in the desired expression. We thus complete the proof by 
computing the expectation of the numerators with respect to 
$\designBatchFwd | \designBatchIn \sim \Gaussian(\emMean[\Ndesign]{\fwd}(\designBatchIn), \emKer[\Ndesign]{\fwd}(\designBatchIn))$. 
These expectations can be computed by noting \Cref{lemma:pred-mean-dist} and then applying \Cref{prop:Gaussian_marginal_moments}.
This yields,
\begin{align*}
\E_{\designBatchFwd}\left[\Gaussian\left(\obs \bigg| \emMean[\Ndesign]{\fwd}(\Par|\designBatchFwd), \frac{1}{2}\likPar + \emKer[\Naugment]{\fwd}(\Par) \right)\right]
&= \Gaussian\left(\obs \big| \emMean[\Ndesign]{\fwd}(\Par), 
\left[\frac{1}{2}\likPar + \emKer[\Naugment]{\fwd}(\Par)\right] + \left[\emKer[\Ndesign]{\fwd}(\Par) - \emKer[\Naugment]{\fwd}(\Par)\right] \right) \\
&= \Gaussian\left(\obs \big| \emMean[\Ndesign]{\fwd}(\Par), \frac{1}{2}\likPar + \emKer[\Ndesign]{\fwd}(\Par) \right)
\end{align*}
and
\begin{align*}
\E_{\designBatchFwd}\left[\Gaussian\left(\obs \big| \emMean[\Ndesign]{\fwd}(\Par|\designBatchFwd), \frac{1}{2}\left[\likPar + \emKer[\Naugment]{\fwd}(\Par)\right]\right)\right] 
&= \Gaussian\left(\obs \big| \emMean[\Ndesign]{\fwd}(\Par), \frac{1}{2} \left[\likPar + \emKer[\Naugment]{\fwd}(\Par)\right] + \left[\emKer[\Ndesign]{\fwd}(\Par) - \emKer[\Naugment]{\fwd}(\Par)\right] \right) \\
&= \Gaussian\left(\obs \big| \emMean[\Ndesign]{\fwd}(\Par), \left[\frac{1}{2}\likPar + \emKer[\Ndesign]{\fwd}(\Par)\right] - \frac{1}{2} \emKer[\Naugment]{\fwd}(\Par)\right),
\end{align*}
which completes the derivation of \Cref{fwd_evar1}. To obtain \Cref{fwd_evar2} we rearrange the covariances of the above expressions to obtain 
\begin{align*}
\frac{1}{2}\likPar + \emKer[\Ndesign]{\fwd}(\Par) &= 
\left[\likPar +  \emKer[\Ndesign]{\fwd}(\Par) \right] - \frac{1}{2}\likPar 
= \CovComb(\Par) - \frac{1}{2}\likPar \\
\left[\frac{1}{2}\likPar + \emKer[\Ndesign]{\fwd}(\Par)\right] - \frac{1}{2} \emKer[\Naugment]{\fwd}(\Par)
&= \left[\likPar + \emKer[\Ndesign]{\fwd}(\Par) \right] - \frac{1}{2}\left[\likPar + \emKer[\Naugment]{\fwd}(\Par) \right] 
= \CovComb(\Par) - \frac{1}{2} \CovComb[\Naugment](\Par). 
\end{align*}

\end{proof}


% Questions and TODOs
\section{Questions and TODOs}
\subsection{Questions}
\begin{enumerate}
\item How to reliably use a log-normal emulator for Bayesian inference? 
	\begin{enumerate}
	\item Improve GP calibration (e.g., quadratic mean) 
	\item Use more robust statistics (e.g., interquartile range)
	\item Truncate proposal or prior. 
	\end{enumerate}
\item How to deal with highly concentrated/correlated posteriors? 
	\begin{enumerate}
	\item MALA or other samplers. 
	\end{enumerate}
\end{enumerate}

\subsection{Need to add}
\begin{enumerate}
\item Summary of results from noisy MCMC literature.
\item Try working out results that compare the ratio of the approx density at two points across different approximations; 
alternatively could consider deriving these results for the normalized densities. 
\item Include result that sample and marginal approx agree at the design points.
\item Include existence results (check existence result from that new paper)
\item Viewing noisy MCMC approaches as approximations to the sample-based posterior.
\item Different views of noisy MCMC approaches, including extending the state space. How does this alg compare to the 
marginal and mcwmh-ind algs?
\item Add some sort of theoretical result that demonstrates that the marginal approximation is extremely sensitive to the GP 
variance. Based on numerical experiments, seems like this result should be given with respect to the dynamic range of the 
log-likelihood. Also of course depends on how fast the GP variance grows away from the design points, so perhaps should 
consider fill distance or something like this as well.
\item Numerical experiment that considers the different ways to weight the integrated uncertainty criteria (i.e., targeting 
the unnormalized posterior density vs. using the approx posterior samples as weights).
\item Posterior consistency results for the noisy MCMC emulators; combine the noisy MCMC results with GP approximation 
results.
\item Evaluating calibration of GP-approximated posteriors relative to calibration of the underlying GP emulator.
\item Constrained GPs
\item Pathwise sampling approach to approximate the sample-based approximation.
\item Compare noisy MCMC vs. deterministic version that considers integrating over the acceptance prob. 
\item Analyze effect of incorporating GP covariance structure; does it result in posteriors closer to the sample-based posterior? 
\item Compare marginal and sample-based approx.
\item Compare marginal approx in log-likelihood vs. forward model setting. 
\item Analyze distribution of likelihood under forward model emulation [I think this is the exponential of a folded Gaussian random variable]. 
How does its tail compare to the lognormal tail? 
\end{enumerate}

\subsection{Emulator Ideas}
\begin{enumerate}
\item Sum of quadratic kernel, Gaussian kernel, and some sort of flat/linear kernel (i.e. something with very long lengthscales) to capture the 
part of the response surface that "flattens" out. 
\end{enumerate}

\subsection{Notation}
\begin{enumerate}
\item How to clean up notation for all of the different approximations being considered here? 
\end{enumerate}

\subsection{Numerical experiments:}
My plan is to have emulation in dynamical settings (ODEs) as the unifying theme here. VSEM can provide the core example but could also consider 
others, such as Lorenz-63 (see Hwanwoo Kim, Daniel Sanz-Alonso paper for the ODEs they consider). When introducing the dynamical setting,
cite Stuart/Schneider Earth System modeling 2.0 paper. Provide various examples of observation operators: time-averages (moments) of state 
variables, identity operator, many shorter time-averages (e.g., weekly/monthly averages), multi-objective settings of calibrating to multiple state 
variables. I should probably include Lorenz-63 to have a more familiar example to many audiences. 

\begin{enumerate}
\item 1D example with 1D output for basic illustration. 
	\begin{enumerate}
	\item VSEM with single varied parameter. 
	\item For 1D output, consider long time average of of a single state variable. This will allow us to compare forward model and log-likelihood emulation directly.
	\item Gaussian likelihood. 
	\item Compare emulator distributions, log-likelihood emulator distributions, and likelihood emulator distributions, and various posterior approximations. 
	\item Validation metrics: RMSE, MAE, CRPS, Log-Score, Coverage. 
	\end{enumerate}
\item 2D examples for basic illustration and consideration of different posterior characteristics: Gaussian, banana, unidentifiable, concentration level, bimodal. 
\item Extension of 2D densities to 6-10 dims (see Vehtari paper numerical experiments) 
\item Sequential design performance at different levels of posterior concentration. 
\item Integrated uncertainty criterion: incorporating the current posterior via the integrand or the measure?
\item Large batch, few iteration sequential design experiment. 
(4 different combinations we could consider) 
\end{enumerate}

\begin{enumerate}
\item 1D example for basic illustration. 
\item 2D examples for basic illustration and consideration of different posterior characteristics: Gaussian, banana, unidentifiable, concentration level, bimodal. 
\item Extension of 2D densities to 6-10 dims (see Vehtari paper numerical experiments) 
\item Sequential design performance at different levels of posterior concentration. 
\item Integrated uncertainty criterion: incorporating the current posterior via the integrand or the measure?
\item Large batch, few iteration sequential design experiment. 
(4 different combinations we could consider) 
\end{enumerate}

\subsection{Potential examples:}
\begin{enumerate}
\item Banana, unimodal, bimodal, unidentifiable
\item Heat equation (see Sinsbeck and Nowak) 
\item VSEM
\end{enumerate}

\subsection{Things to consider trying}
\begin{enumerate}
\item Perhaps give some context by discussing connections to Bayesian optimization and to log-likelihood approximation used in 
simulation-based inference. 
\item Hyperparameter marginalization: need to look into opportunities for closed-form hyperparameter marginalization during 
sequential design phase. 
\item Developing a design criterion that better aligns with the MHWMC procedure; e.g., something that targets the likelihood ratio. 
\item Implementing Higdon basis function approach for comparison. 
\item Nonnegative constrained GPs (may be able to do this by modifying the kergp optimization code and using nloptr's option to add constraints) 
\item GP-accelerated MALA 
\end{enumerate}

\subsection{Limitations of existing literature}
\begin{enumerate}
\item Very little discussion of case where likelihood parameters are unknown. 
\item Lack of emphasis on batch design (with some exceptions).
\item Little guidance on which approximation/design criterion to choose.
\item Vehtari fixes the marginal approx, and focuses instead on varying the design criterion, but notes that sampling from the marginal approx is problematic. 
\end{enumerate}

\subsection{Conjectures}
\begin{enumerate}
\item The MCWMH algorithms will perform better than sampling from the marginal approx in the log-likelihood emulation setting, especially when the GP is very uncertain. 
\end{enumerate}

\subsection{Consideration}
\begin{enumerate}
\item Literature typically focuses on convergence of the approx posterior. But in cases with very expensive computer models, one might have to stop pre-convergence. 
In these settings the comparison between the approximate posteriors becomes even more important. 
\end{enumerate}

\end{comment}

\bibliography{../shared/surrogates} 
\end{document}







